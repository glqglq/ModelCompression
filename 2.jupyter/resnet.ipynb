{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 0.导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.python.slim.nets import resnet_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_height = 32  \n",
    "fixed_width = 32\n",
    "\n",
    "train_samples_per_epoch = 50000  \n",
    "test_samples_per_epoch = 10000  \n",
    "data_dir='1.data/Cifar10/' # 定义数据集所在文件夹路径  \n",
    "batch_size = 256 #定义每次参数更新时，所使用的batch的大小  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cifar10(filename_queue):  \n",
    "    # 定义一个空的类对象\n",
    "    class Image(object):  \n",
    "        pass  \n",
    "    image = Image()\n",
    "    # 基本参数\n",
    "    image.height=32  \n",
    "    image.width=32  \n",
    "    image.depth=3  \n",
    "    label_bytes = 1  \n",
    "    image_bytes = image.height*image.width*image.depth  \n",
    "    \n",
    "    # 读取数据\n",
    "    Bytes_to_read = label_bytes + image_bytes  \n",
    "    # 定义一个Reader，它每次能从文件中读取固定字节数  \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = Bytes_to_read)   \n",
    "    # 返回从filename_queue中读取的(key, value)对，key和value都是字符串类型的tensor，并且当队列中的某一个文件读完成时，该文件名会dequeue  \n",
    "    image.key, value_str = reader.read(filename_queue)   \n",
    "    # 解码操作可以看作读二进制文件，把字符串中的字节转换为数值向量,每一个数值占用一个字节,在[0, 255]区间内，因此out_type要取uint8类型  \n",
    "    value = tf.decode_raw(bytes=value_str, out_type=tf.uint8)   \n",
    "    # 从一维tensor对象中截取一个slice,类似于从一维向量中筛选子向量，因为value中包含了label和feature，故要对向量类型tensor进行'parse'操作      \n",
    "    image.label = tf.slice(input_=value, begin=[0], size=[label_bytes])# begin和size分别表示待截取片段的起点和长度  \n",
    "    data_mat = tf.slice(input_=value, begin=[label_bytes], size=[image_bytes])  \n",
    "    data_mat = tf.reshape(data_mat, (image.depth, image.height, image.width)) #这里的维度顺序，是依据cifar二进制文件的格式而定的  \n",
    "    transposed_value = tf.transpose(data_mat, perm=[1, 2, 0]) #对data_mat的维度进行重新排列，返回值的第i个维度对应着data_mat的第perm[i]维  \n",
    "    image.mat = transposed_value      \n",
    "    return image      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_samples(img_obj, min_samples_in_queue, batch_size, shuffle_flag):  \n",
    "    ''''' \n",
    "    tf.train.shuffle_batch()函数用于随机地shuffling 队列中的tensors来创建batches(也即每次可以读取多个data文件中的样例构成一个batch)。这个函数向当前Graph中添加了下列对象： \n",
    "    *创建了一个shuffling queue，用于把‘tensors’中的tensors压入该队列； \n",
    "    *一个dequeue_many操作，用于根据队列中的数据创建一个batch； \n",
    "    *创建了一个QueueRunner对象，用于启动一个进程压数据到队列 \n",
    "    capacity参数用于控制shuffling queue的最大长度；min_after_dequeue参数表示进行一次dequeue操作后队列中元素的最小数量，可以用于确保batch中 \n",
    "    元素的随机性；num_threads参数用于指定多少个threads负责压tensors到队列；enqueue_many参数用于表征是否tensors中的每一个tensor都代表一个样例 \n",
    "    tf.train.batch()与之类似，只不过顺序地出队列（也即每次只能从一个data文件中读取batch），少了随机性。 \n",
    "    '''\n",
    "    if shuffle_flag == False:  \n",
    "        image_batch, label_batch = tf.train.batch(tensors=img_obj,   \n",
    "                                                  batch_size=batch_size,   \n",
    "                                                  num_threads=4,   \n",
    "                                                  capacity=min_samples_in_queue+3*batch_size)  \n",
    "    else:  \n",
    "        image_batch, label_batch = tf.train.shuffle_batch(tensors=img_obj,   \n",
    "                                                          batch_size=batch_size,   \n",
    "                                                          num_threads=4,   \n",
    "                                                          min_after_dequeue=min_samples_in_queue,  \n",
    "                                                          capacity=min_samples_in_queue+3*batch_size)                                                      \n",
    "    tf.contrib.deprecated.image_summary('input_image', image_batch, max_images=6) #输出预处理后图像的summary缓存对象，用于在session中写入到事件文件中                                                      \n",
    "    return image_batch, tf.reshape(label_batch, shape=[batch_size])       \n",
    "                                         \n",
    "def preprocess_input_data():  \n",
    "    '''''这部分程序用于对训练数据集进行‘数据增强’操作，通过增加训练集的大小来防止过拟合'''  \n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)]  \n",
    "    #filenames =[os.path.join(data_dir, 'test_batch.bin')]  \n",
    "    for f in filenames: #检验训练数据集文件是否存在  \n",
    "        if not tf.gfile.Exists(f):  \n",
    "            raise ValueError('fail to find file:'+f)      \n",
    "    filename_queue = tf.train.string_input_producer(string_tensor=filenames) # 把文件名输出到队列中，作为整个data pipe的第一阶段  \n",
    "    image = read_cifar10(filename_queue) #从文件名队列中读取一个tensor类型的图像  \n",
    "    new_img = tf.cast(image.mat, tf.float32)  \n",
    "    tf.contrib.deprecated.image_summary('raw_input_image', tf.reshape(new_img, [1, 32, 32, 3]))#输出预处理前图像的summary缓存对象  \n",
    "    new_img = tf.random_crop(new_img, size=(fixed_height, fixed_width, 3)) #从原图像中切割出子图像  \n",
    "    new_img = tf.image.random_brightness(new_img, max_delta=63) #随机调节图像的亮度  \n",
    "    new_img = tf.image.random_flip_left_right(new_img) #随机地左右翻转图像  \n",
    "    new_img = tf.image.random_contrast(new_img, lower=0.2, upper=1.8) #随机地调整图像对比度  \n",
    "    final_img = tf.image.per_image_standardization(new_img) #对图像进行whiten操作，目的是降低输入图像的冗余性，尽量去除输入特征间的相关性  \n",
    "      \n",
    "    min_samples_ratio_in_queue = 0.4  #用于确保读取到的batch中样例的随机性，使其覆盖到更多的类别、更多的数据文件！！！  \n",
    "    min_samples_in_queue = int(min_samples_ratio_in_queue*train_samples_per_epoch)   \n",
    "    return get_batch_samples([final_img, image.label], min_samples_in_queue, batch_size, shuffle_flag=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1tensorflow库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py:210: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py:210: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "def ResBlock(name,input,branch):\n",
    "    '''\n",
    "        @input:\n",
    "        @filter\n",
    "    '''\n",
    "    with tf.name_scope(name):\n",
    "        # 第一层&conv层\n",
    "        inchannels = input.get_shape()[3].value\n",
    "        if(branch == 0): # 第一个\n",
    "            conv1 = tf.layers.conv2d(input,inchannels/2,[1,1],strides = 2)\n",
    "            conv = tf.layers.conv2d(input,inchannels/2,[1,1],strides = 2)\n",
    "            bn = tf.nn.batch_normalization(conv)\n",
    "            relu = tf.nn.relu(bn)\n",
    "            inchannels = inchannels / 2\n",
    "\n",
    "        else: # 非第一个\n",
    "            conv1 = tf.layers.conv2d(input,inchannels/2,[1,1],strides = 1)\n",
    "            conv = input\n",
    "\n",
    "        bn1 = tf.nn.batch_normalization(conv1)\n",
    "        # scale\n",
    "        relu1 = tf.nn.relu(bn1)\n",
    "\n",
    "        # 第二层\n",
    "        conv2 = tf.layers.conv2d(relu1,tf.constant([3,3,inchannels,inchannels]),strides = 1)\n",
    "        bn2 = tf.nn.batch_normalization(conv2)\n",
    "        # scale\n",
    "        relu2 = tf.nn.relu(bn2)\n",
    "\n",
    "        # 第三层\n",
    "        if(branch == 0):\n",
    "            conv3 = tf.layers.conv2d(relu2,tf.constant([1,1,inchannels * 4,inchannels * 4]),strides = 1)\n",
    "            bn3 = tf.layers.conv2d(conv3)\n",
    "            # scale\n",
    "        else:\n",
    "            conv3 = tf.layers.conv2d(relu2,tf.constant([1,1,inchannels,inchannels]),strides = 1)\n",
    "            bn3 = tf.layers.conv2d(conv3)\n",
    "            # scale\n",
    "    \n",
    "        return tf.nn.relu(tf.add(bn3,conv))\n",
    "\n",
    "def ResNet(input):\n",
    "    last = tf.layers.conv2d(input,tf.constant([7,7,3,64],strides = 2)\n",
    "    last = tf.nn.batch_normalization(last)\n",
    "    # scale\n",
    "    last = tf.nn.relu(last)\n",
    "    last = tf.nn.max_pool(last,ksize = 3,strides = 2)\n",
    "                        \n",
    "    for i in range(3):\n",
    "        last = ResBlock('conv2_' + str(i),last,i)\n",
    "    for i in range(8):\n",
    "        last = ResBlock('conv3_' + str(i),last,i)\n",
    "    for i in range(36):\n",
    "        last = ResBlock('conv4_' + str(i),last,i)\n",
    "    for i in range(3):\n",
    "        last = ResBlock('conv5_' + str(i),last,i)\n",
    "    last = tf.nn.avg_pool(last,ksize = 7,strides = 1)\n",
    "    last = tf.layers.dense(last)\n",
    "    tf.nn.softmax(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'resnet_v1_152_1/logits/BiasAdd:0' shape=(256, 1, 1, 10) dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n\t [[Node: resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma)]]\n\nCaused by op 'resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-58-38b53f4c976c>\", line 8, in <module>\n    scope='resnet_v1_152')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 326, in resnet_v1_152\n    scope=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 207, in resnet_v1\n    net = resnet_utils.stack_blocks_dense(net, blocks, output_stride)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py\", line 215, in stack_blocks_dense\n    net = block.unit_fn(net, rate=1, **unit)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 114, in bottleneck\n    scope='shortcut')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1058, in convolution\n    outputs = normalizer_fn(outputs, **normalizer_params)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 650, in batch_norm\n    outputs = layer.apply(inputs, training=is_training)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/normalization.py\", line 284, in build\n    trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\n    return custom_getter(**custom_getter_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1720, in wrapped_custom_getter\n    *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1611, in layer_variable_getter\n    return _model_variable_getter(getter, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1602, in _model_variable_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1611, in layer_variable_getter\n    return _model_variable_getter(getter, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1602, in _model_variable_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3187, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n\t [[Node: resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n\t [[Node: resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2fd89852c238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n\t [[Node: resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma)]]\n\nCaused by op 'resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-58-38b53f4c976c>\", line 8, in <module>\n    scope='resnet_v1_152')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 326, in resnet_v1_152\n    scope=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 207, in resnet_v1\n    net = resnet_utils.stack_blocks_dense(net, blocks, output_stride)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py\", line 215, in stack_blocks_dense\n    net = block.unit_fn(net, rate=1, **unit)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 114, in bottleneck\n    scope='shortcut')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1058, in convolution\n    outputs = normalizer_fn(outputs, **normalizer_params)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 650, in batch_norm\n    outputs = layer.apply(inputs, training=is_training)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/normalization.py\", line 284, in build\n    trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\n    return custom_getter(**custom_getter_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1720, in wrapped_custom_getter\n    *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1611, in layer_variable_getter\n    return _model_variable_getter(getter, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1602, in _model_variable_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1611, in layer_variable_getter\n    return _model_variable_getter(getter, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1602, in _model_variable_getter\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3187, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n\t [[Node: resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](resnet_v1_152/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma)]]\n"
     ]
    }
   ],
   "source": [
    "sess.run([net, end_points])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
