{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理**\n",
    "\n",
    "jupyter实现远程连接\n",
    "```\n",
    "nohup jupyter notebook --ip=10.5.0.22 &\n",
    "\n",
    "```\n",
    "[剪枝量化代码](https://github.com/nephashi/DeepCompression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def reorg_cifar10_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio):\n",
    "    # 读取训练数据标签。\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        # 跳过文件头行（栏名称）。\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((int(idx), label) for idx, label in tokens))\n",
    "    labels = set(idx_label.values())\n",
    "\n",
    "    num_train = len(os.listdir(os.path.join(data_dir, train_dir)))\n",
    "    num_train_tuning = int(num_train * (1 - valid_ratio))\n",
    "    assert 0 < num_train_tuning < num_train\n",
    "    num_train_tuning_per_label = num_train_tuning // len(labels)\n",
    "    label_count = dict()\n",
    "\n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "\n",
    "    # 整理训练和验证集。\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = int(train_file.split('.')[0])\n",
    "        label = idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < num_train_tuning_per_label:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "\n",
    "    # 整理测试集。\n",
    "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepocess = False\n",
    "if prepocess:\n",
    "    demo = False\n",
    "    if demo:\n",
    "        # 注意：此处使用小训练集为便于网页编译。Kaggle的完整数据集应包括5万训练样本。\n",
    "        train_dir = 'train_tiny'\n",
    "        # 注意：此处使用小测试集为便于网页编译。Kaggle的完整数据集应包括30万测试样本。\n",
    "        test_dir = 'test_tiny'\n",
    "        # 注意：此处相应使用小批量。对Kaggle的完整数据集可设较大的整数，例如128。\n",
    "        batch_size = 1\n",
    "    else:\n",
    "        train_dir = 'train'\n",
    "        test_dir = 'test'\n",
    "        batch_size = 128\n",
    "\n",
    "    data_dir = '/home/dragon/code/gluon/cifar10/'\n",
    "    label_file = 'trainLabels.csv'\n",
    "    input_dir = 'train_valid_test'\n",
    "    valid_ratio = 0.1\n",
    "    reorg_cifar10_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用新的数据和训练方式来做\n",
    "\n",
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "from mxnet import init\n",
    "class Residual(nn.HybridBlock):\n",
    "    def __init__(self, channels, same_shape=True):\n",
    "        super(Residual, self).__init__()\n",
    "        self.same_shape = same_shape\n",
    "        strides = 1 if same_shape else 2\n",
    "        bn1 = nn.BatchNorm()\n",
    "        conv1 = nn.Conv2D(channels , 3, padding=1, strides=strides,use_bias=False)\n",
    "        bn2 = nn.BatchNorm()\n",
    "        rl1 = nn.Activation(activation='relu')\n",
    "        conv2 = nn.Conv2D(channels,kernel_size=3,strides=1,padding=1,use_bias=False)\n",
    "        bn3 = nn.BatchNorm()\n",
    "        self.net = nn.HybridSequential()\n",
    "        self.net.add(bn1,conv1,bn2,rl1,conv2,bn3)\n",
    "        if not same_shape:\n",
    "            conv3 = nn.Conv2D(channels,kernel_size=1,strides=strides)\n",
    "            self.net.add(conv3)\n",
    "\n",
    "    def hybrid_forward(self,F,x):\n",
    "        out = x\n",
    "        for l in self.net[:-1]:\n",
    "            out = l(out)\n",
    "        if not self.same_shape:\n",
    "            x=self.net[-1](x)\n",
    "        else:\n",
    "            out = self.net[-1](out)\n",
    "        return F.relu(out+x)\n",
    "        #return mx.sym.relu(out+x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resnet_tea(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False):\n",
    "        super(Resnet_tea, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            b1 = nn.HybridSequential()\n",
    "            b1.add(\n",
    "                nn.BatchNorm(),\n",
    "                nn.Conv2D(32,kernel_size=3,strides=1,use_bias=False)\n",
    "            )\n",
    "            num_res = 5\n",
    "            b2 = nn.HybridSequential()\n",
    "            #b2.add(Residual(64,same_shape=False))\n",
    "            for i in range(num_res+1):\n",
    "                b2.add(Residual(32))\n",
    "            b3 = nn.HybridSequential()\n",
    "            b3.add(\n",
    "                Residual(64,same_shape=False)\n",
    "            )\n",
    "            for i in range(num_res):\n",
    "                b3.add(Residual(64))\n",
    "            b4 = nn.HybridSequential()\n",
    "            b4.add(\n",
    "                Residual(128,same_shape=False)\n",
    "            )\n",
    "            for i in range(num_res):\n",
    "                b4.add(Residual(128))\n",
    "            b5 = nn.HybridSequential()\n",
    "            b5.add(\n",
    "                nn.BatchNorm(),\n",
    "                nn.Activation('relu'),\n",
    "                nn.AvgPool2D(pool_size=8),\n",
    "                nn.Dense(num_classes)\n",
    "            )\n",
    "            self.net = nn.HybridSequential()\n",
    "            self.net.add(b1,b2,b3,b4,b5)   \n",
    "    def hybrid_forward(self, F, x):\n",
    "        out = x\n",
    "        for i, b in enumerate(self.net):\n",
    "            out = b(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d output: %s' % (i + 1, out.shape))\n",
    "        return out        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#writer = SummaryWriter()\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 120\n",
    "import matplotlib.pyplot as plt\n",
    "def get_acc(output, label):\n",
    "    pred = output.argmax(1, keepdims=True)\n",
    "    correct = (pred == label).sum()\n",
    "    return correct.asscalar()\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "    print(\"Start training on \", ctx)\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    losses_all = []\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        if epoch == 60 or epoch == 120:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            bs = data.shape[0]\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(bs)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            correct += get_acc(output, label)\n",
    "            total += bs\n",
    "        #writer.add_scalars('loss', {'train': train_loss / len(train_data)}, epoch)\n",
    "        #writer.add_scalars('acc', {'train': correct / total}, epoch)\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_correct = 0\n",
    "            valid_total = 0\n",
    "            valid_loss = 0\n",
    "            for data, label in valid_data:\n",
    "                bs = data.shape[0]\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "                valid_loss += nd.mean(loss).asscalar()\n",
    "                valid_correct += get_acc(output, label)\n",
    "                valid_total += bs\n",
    "            valid_acc = valid_correct / valid_total\n",
    "            #writer.add_scalars('loss', {'valid': valid_loss / len(valid_data)}, epoch)\n",
    "            #writer.add_scalars('acc', {'valid': valid_acc}, epoch)\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train acc %f, Valid Loss: %f, Valid acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            correct / total, valid_loss / len(valid_data), valid_acc))\n",
    "            train_accs.append(correct / total)\n",
    "            test_accs.append(valid_acc)\n",
    "            losses_all.append(train_loss / len(train_data))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            correct / total))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "        show = True\n",
    "    if show==True:\n",
    "        plt.plot(losses_all)\n",
    "        plt.plot(train_accs)\n",
    "        plt.plot(test_accs)\n",
    "        plt.legend(['loss','train','test'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net, valid_data):\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "    for data, label in valid_data:\n",
    "        bs = data.shape[0]\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        valid_loss += nd.mean(loss).asscalar()\n",
    "        valid_correct += get_acc(output, label)\n",
    "        valid_total += bs\n",
    "    valid_acc = valid_correct / valid_total\n",
    "    cur_time = datetime.datetime.now()\n",
    "    h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "    m, s = divmod(remainder, 60)\n",
    "    test_str = \"Valid Loss: %f, Valid acc %f\" % (valid_loss / len(valid_data), valid_acc) \n",
    "    time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "    print(test_str+time_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet import nd, gluon, autograd, init\n",
    "from mxnet.gluon.data.vision import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "import shutil\n",
    "def transform_train(data, label):\n",
    "    im = data.asnumpy()\n",
    "    im = np.pad(im, ((4, 4), (4, 4), (0, 0)), mode='constant', constant_values=0)\n",
    "    im = nd.array(im, dtype='float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, rand_mirror=True,\n",
    "                                    rand_crop=True,\n",
    "                                   mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1)) # channel x width x height\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "def transform_test(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu()\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = ImageFolderDataset('/home/dragon/code/gluon/cifar10/train_valid_test/train/', transform=transform_train)\n",
    "valid_ds = ImageFolderDataset('/home/dragon/code/gluon/cifar10/train_valid_test/valid/', transform=transform_test)\n",
    "train_data = DataLoader(train_ds, batch_size=batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = DataLoader(valid_ds, batch_size=batch_size, shuffle=True, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Resnet_tea(10)\n",
    "ctx = try_gpu()\n",
    "model.initialize(ctx=ctx, init=mx.initializer.Xavier())\n",
    "model.hybridize()\n",
    "criterion = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Train Loss: 1.626062, Train acc 0.395667, Valid Loss: 1.410667, Valid acc 0.498600, Time 00:03:14, lr 0.1\n",
      "Epoch 1. Train Loss: 1.142722, Train acc 0.586556, Valid Loss: 1.087941, Valid acc 0.621400, Time 00:01:21, lr 0.1\n",
      "Epoch 2. Train Loss: 0.871716, Train acc 0.692200, Valid Loss: 0.941418, Valid acc 0.678400, Time 00:01:24, lr 0.1\n",
      "Epoch 3. Train Loss: 0.720427, Train acc 0.747689, Valid Loss: 0.785860, Valid acc 0.728000, Time 00:01:36, lr 0.1\n",
      "Epoch 4. Train Loss: 0.631289, Train acc 0.778467, Valid Loss: 0.727280, Valid acc 0.761800, Time 00:01:37, lr 0.1\n",
      "Epoch 5. Train Loss: 0.554566, Train acc 0.808244, Valid Loss: 0.592960, Valid acc 0.796600, Time 00:01:41, lr 0.1\n",
      "Epoch 6. Train Loss: 0.504634, Train acc 0.825644, Valid Loss: 0.532167, Valid acc 0.820000, Time 00:01:41, lr 0.1\n",
      "Epoch 7. Train Loss: 0.468367, Train acc 0.835978, Valid Loss: 0.539077, Valid acc 0.816800, Time 00:01:42, lr 0.1\n",
      "Epoch 8. Train Loss: 0.434438, Train acc 0.848356, Valid Loss: 0.614645, Valid acc 0.801000, Time 00:01:45, lr 0.1\n",
      "Epoch 9. Train Loss: 0.400314, Train acc 0.862267, Valid Loss: 0.473029, Valid acc 0.846600, Time 00:01:43, lr 0.1\n",
      "Epoch 10. Train Loss: 0.381762, Train acc 0.867511, Valid Loss: 0.478007, Valid acc 0.843800, Time 00:01:50, lr 0.1\n",
      "Epoch 11. Train Loss: 0.358096, Train acc 0.874289, Valid Loss: 0.460677, Valid acc 0.852000, Time 00:01:50, lr 0.1\n",
      "Epoch 12. Train Loss: 0.343236, Train acc 0.880556, Valid Loss: 0.459283, Valid acc 0.849000, Time 00:01:48, lr 0.1\n",
      "Epoch 13. Train Loss: 0.318453, Train acc 0.889822, Valid Loss: 0.433319, Valid acc 0.859200, Time 00:01:43, lr 0.1\n",
      "Epoch 14. Train Loss: 0.301399, Train acc 0.893844, Valid Loss: 0.440934, Valid acc 0.866600, Time 00:01:43, lr 0.1\n",
      "Epoch 15. Train Loss: 0.291242, Train acc 0.897600, Valid Loss: 0.458202, Valid acc 0.854200, Time 00:01:46, lr 0.1\n",
      "Epoch 16. Train Loss: 0.281099, Train acc 0.901844, Valid Loss: 0.440567, Valid acc 0.859000, Time 00:01:47, lr 0.1\n",
      "Epoch 17. Train Loss: 0.262847, Train acc 0.906378, Valid Loss: 0.444016, Valid acc 0.852400, Time 00:01:46, lr 0.1\n",
      "Epoch 18. Train Loss: 0.253129, Train acc 0.911911, Valid Loss: 0.422230, Valid acc 0.865800, Time 00:01:45, lr 0.1\n",
      "Epoch 19. Train Loss: 0.245435, Train acc 0.914444, Valid Loss: 0.371872, Valid acc 0.882600, Time 00:01:50, lr 0.1\n",
      "Epoch 20. Train Loss: 0.233361, Train acc 0.918622, Valid Loss: 0.354616, Valid acc 0.887600, Time 00:01:49, lr 0.1\n",
      "Epoch 21. Train Loss: 0.222377, Train acc 0.922067, Valid Loss: 0.384303, Valid acc 0.874800, Time 00:01:49, lr 0.1\n",
      "Epoch 22. Train Loss: 0.211551, Train acc 0.925222, Valid Loss: 0.385440, Valid acc 0.880600, Time 00:01:47, lr 0.1\n",
      "Epoch 23. Train Loss: 0.206120, Train acc 0.926133, Valid Loss: 0.402403, Valid acc 0.873000, Time 00:01:44, lr 0.1\n",
      "Epoch 24. Train Loss: 0.199652, Train acc 0.929178, Valid Loss: 0.380771, Valid acc 0.881600, Time 00:01:46, lr 0.1\n",
      "Epoch 25. Train Loss: 0.196499, Train acc 0.931578, Valid Loss: 0.386998, Valid acc 0.875000, Time 00:01:49, lr 0.1\n",
      "Epoch 26. Train Loss: 0.186245, Train acc 0.933711, Valid Loss: 0.417876, Valid acc 0.870600, Time 00:01:49, lr 0.1\n",
      "Epoch 27. Train Loss: 0.179871, Train acc 0.936444, Valid Loss: 0.364519, Valid acc 0.887400, Time 00:01:48, lr 0.1\n",
      "Epoch 28. Train Loss: 0.176699, Train acc 0.936756, Valid Loss: 0.375873, Valid acc 0.885000, Time 00:01:49, lr 0.1\n",
      "Epoch 29. Train Loss: 0.168750, Train acc 0.940733, Valid Loss: 0.374836, Valid acc 0.886600, Time 00:01:45, lr 0.1\n",
      "Epoch 30. Train Loss: 0.161950, Train acc 0.942889, Valid Loss: 0.352344, Valid acc 0.893000, Time 00:01:46, lr 0.1\n",
      "Epoch 31. Train Loss: 0.161849, Train acc 0.943689, Valid Loss: 0.455282, Valid acc 0.870600, Time 00:01:50, lr 0.1\n",
      "Epoch 32. Train Loss: 0.159755, Train acc 0.943956, Valid Loss: 0.366129, Valid acc 0.890000, Time 00:01:50, lr 0.1\n",
      "Epoch 33. Train Loss: 0.155378, Train acc 0.945733, Valid Loss: 0.429773, Valid acc 0.879600, Time 00:01:48, lr 0.1\n",
      "Epoch 34. Train Loss: 0.147791, Train acc 0.947756, Valid Loss: 0.387149, Valid acc 0.889200, Time 00:01:50, lr 0.1\n",
      "Epoch 35. Train Loss: 0.147034, Train acc 0.948133, Valid Loss: 0.337402, Valid acc 0.896400, Time 00:01:52, lr 0.1\n",
      "Epoch 36. Train Loss: 0.143522, Train acc 0.949556, Valid Loss: 0.370142, Valid acc 0.893400, Time 00:01:51, lr 0.1\n",
      "Epoch 37. Train Loss: 0.136110, Train acc 0.952044, Valid Loss: 0.429178, Valid acc 0.877200, Time 00:01:53, lr 0.1\n",
      "Epoch 38. Train Loss: 0.133193, Train acc 0.953311, Valid Loss: 0.383991, Valid acc 0.894000, Time 00:01:50, lr 0.1\n",
      "Epoch 39. Train Loss: 0.135198, Train acc 0.951844, Valid Loss: 0.349192, Valid acc 0.896200, Time 00:01:47, lr 0.1\n",
      "Epoch 40. Train Loss: 0.129903, Train acc 0.954178, Valid Loss: 0.366153, Valid acc 0.895400, Time 00:01:52, lr 0.1\n",
      "Epoch 41. Train Loss: 0.126730, Train acc 0.955444, Valid Loss: 0.394758, Valid acc 0.886800, Time 00:01:47, lr 0.1\n",
      "Epoch 42. Train Loss: 0.132000, Train acc 0.953267, Valid Loss: 0.332795, Valid acc 0.899400, Time 00:01:47, lr 0.1\n",
      "Epoch 43. Train Loss: 0.122817, Train acc 0.956267, Valid Loss: 0.381931, Valid acc 0.887000, Time 00:01:43, lr 0.1\n",
      "Epoch 44. Train Loss: 0.123600, Train acc 0.955733, Valid Loss: 0.354607, Valid acc 0.899400, Time 00:01:47, lr 0.1\n",
      "Epoch 45. Train Loss: 0.116523, Train acc 0.959600, Valid Loss: 0.336457, Valid acc 0.906000, Time 00:01:47, lr 0.1\n",
      "Epoch 46. Train Loss: 0.115562, Train acc 0.959667, Valid Loss: 0.428789, Valid acc 0.889000, Time 00:01:46, lr 0.1\n",
      "Epoch 47. Train Loss: 0.120178, Train acc 0.956089, Valid Loss: 0.338477, Valid acc 0.904400, Time 00:01:47, lr 0.1\n",
      "Epoch 48. Train Loss: 0.117375, Train acc 0.958511, Valid Loss: 0.366379, Valid acc 0.896200, Time 00:01:46, lr 0.1\n",
      "Epoch 49. Train Loss: 0.115042, Train acc 0.959044, Valid Loss: 0.370475, Valid acc 0.895600, Time 00:01:45, lr 0.1\n",
      "Epoch 50. Train Loss: 0.110302, Train acc 0.960778, Valid Loss: 0.378898, Valid acc 0.894000, Time 00:01:46, lr 0.1\n",
      "Epoch 51. Train Loss: 0.106618, Train acc 0.962511, Valid Loss: 0.359557, Valid acc 0.900800, Time 00:01:43, lr 0.1\n",
      "Epoch 52. Train Loss: 0.111150, Train acc 0.961400, Valid Loss: 0.371694, Valid acc 0.896600, Time 00:01:41, lr 0.1\n",
      "Epoch 53. Train Loss: 0.105197, Train acc 0.962311, Valid Loss: 0.358752, Valid acc 0.901600, Time 00:01:42, lr 0.1\n",
      "Epoch 54. Train Loss: 0.108505, Train acc 0.961511, Valid Loss: 0.357803, Valid acc 0.902800, Time 00:01:44, lr 0.1\n",
      "Epoch 55. Train Loss: 0.101357, Train acc 0.963644, Valid Loss: 0.388200, Valid acc 0.897000, Time 00:01:45, lr 0.1\n",
      "Epoch 56. Train Loss: 0.105672, Train acc 0.962356, Valid Loss: 0.358213, Valid acc 0.898200, Time 00:01:52, lr 0.1\n",
      "Epoch 57. Train Loss: 0.100064, Train acc 0.964378, Valid Loss: 0.402483, Valid acc 0.893000, Time 00:01:50, lr 0.1\n",
      "Epoch 58. Train Loss: 0.102211, Train acc 0.965178, Valid Loss: 0.351060, Valid acc 0.899800, Time 00:01:44, lr 0.1\n",
      "Epoch 59. Train Loss: 0.096914, Train acc 0.965111, Valid Loss: 0.366568, Valid acc 0.897800, Time 00:01:47, lr 0.1\n",
      "Epoch 60. Train Loss: 0.069626, Train acc 0.975889, Valid Loss: 0.263859, Valid acc 0.928600, Time 00:01:50, lr 0.01\n",
      "Epoch 61. Train Loss: 0.035160, Train acc 0.988867, Valid Loss: 0.259576, Valid acc 0.929400, Time 00:01:46, lr 0.01\n",
      "Epoch 62. Train Loss: 0.027865, Train acc 0.991556, Valid Loss: 0.261496, Valid acc 0.929800, Time 00:01:45, lr 0.01\n",
      "Epoch 63. Train Loss: 0.024203, Train acc 0.992444, Valid Loss: 0.263195, Valid acc 0.928200, Time 00:01:47, lr 0.01\n",
      "Epoch 64. Train Loss: 0.020089, Train acc 0.994356, Valid Loss: 0.266632, Valid acc 0.933000, Time 00:01:46, lr 0.01\n",
      "Epoch 65. Train Loss: 0.017388, Train acc 0.995689, Valid Loss: 0.270815, Valid acc 0.932200, Time 00:01:49, lr 0.01\n",
      "Epoch 66. Train Loss: 0.016392, Train acc 0.995289, Valid Loss: 0.282199, Valid acc 0.932000, Time 00:01:49, lr 0.01\n",
      "Epoch 67. Train Loss: 0.015059, Train acc 0.995600, Valid Loss: 0.281541, Valid acc 0.932800, Time 00:01:49, lr 0.01\n",
      "Epoch 68. Train Loss: 0.013662, Train acc 0.996133, Valid Loss: 0.283141, Valid acc 0.935800, Time 00:01:46, lr 0.01\n",
      "Epoch 69. Train Loss: 0.013626, Train acc 0.995956, Valid Loss: 0.281874, Valid acc 0.935800, Time 00:01:47, lr 0.01\n",
      "Epoch 70. Train Loss: 0.011311, Train acc 0.997156, Valid Loss: 0.287288, Valid acc 0.936200, Time 00:01:52, lr 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71. Train Loss: 0.011284, Train acc 0.997022, Valid Loss: 0.292264, Valid acc 0.935200, Time 00:01:47, lr 0.01\n",
      "Epoch 72. Train Loss: 0.010205, Train acc 0.997089, Valid Loss: 0.295241, Valid acc 0.935800, Time 00:01:42, lr 0.01\n",
      "Epoch 73. Train Loss: 0.010481, Train acc 0.997133, Valid Loss: 0.293889, Valid acc 0.935400, Time 00:01:43, lr 0.01\n",
      "Epoch 74. Train Loss: 0.008698, Train acc 0.997889, Valid Loss: 0.296788, Valid acc 0.934400, Time 00:01:46, lr 0.01\n",
      "Epoch 75. Train Loss: 0.007873, Train acc 0.998133, Valid Loss: 0.312929, Valid acc 0.933200, Time 00:01:45, lr 0.01\n",
      "Epoch 76. Train Loss: 0.008595, Train acc 0.997622, Valid Loss: 0.306996, Valid acc 0.936000, Time 00:01:46, lr 0.01\n",
      "Epoch 77. Train Loss: 0.008040, Train acc 0.997800, Valid Loss: 0.311892, Valid acc 0.934800, Time 00:01:47, lr 0.01\n",
      "Epoch 78. Train Loss: 0.007253, Train acc 0.998133, Valid Loss: 0.314595, Valid acc 0.932800, Time 00:01:45, lr 0.01\n",
      "Epoch 79. Train Loss: 0.007637, Train acc 0.998000, Valid Loss: 0.325030, Valid acc 0.935000, Time 00:01:43, lr 0.01\n",
      "Epoch 80. Train Loss: 0.007608, Train acc 0.997889, Valid Loss: 0.319990, Valid acc 0.934200, Time 00:01:42, lr 0.01\n",
      "Epoch 81. Train Loss: 0.006691, Train acc 0.998444, Valid Loss: 0.316813, Valid acc 0.932800, Time 00:01:44, lr 0.01\n",
      "Epoch 82. Train Loss: 0.006332, Train acc 0.998200, Valid Loss: 0.323769, Valid acc 0.934600, Time 00:01:45, lr 0.01\n",
      "Epoch 83. Train Loss: 0.005815, Train acc 0.998622, Valid Loss: 0.328455, Valid acc 0.932600, Time 00:01:40, lr 0.01\n",
      "Epoch 84. Train Loss: 0.006062, Train acc 0.998467, Valid Loss: 0.325979, Valid acc 0.933000, Time 00:01:41, lr 0.01\n",
      "Epoch 85. Train Loss: 0.005816, Train acc 0.998533, Valid Loss: 0.327649, Valid acc 0.935000, Time 00:01:43, lr 0.01\n",
      "Epoch 86. Train Loss: 0.005582, Train acc 0.998644, Valid Loss: 0.322953, Valid acc 0.934200, Time 00:01:43, lr 0.01\n",
      "Epoch 87. Train Loss: 0.005054, Train acc 0.998822, Valid Loss: 0.328319, Valid acc 0.935800, Time 00:01:44, lr 0.01\n",
      "Epoch 88. Train Loss: 0.005079, Train acc 0.998778, Valid Loss: 0.328985, Valid acc 0.933600, Time 00:01:41, lr 0.01\n",
      "Epoch 89. Train Loss: 0.005456, Train acc 0.998644, Valid Loss: 0.328241, Valid acc 0.934800, Time 00:01:39, lr 0.01\n",
      "Epoch 90. Train Loss: 0.005219, Train acc 0.998867, Valid Loss: 0.325334, Valid acc 0.933800, Time 00:01:39, lr 0.01\n",
      "Epoch 91. Train Loss: 0.004681, Train acc 0.999156, Valid Loss: 0.329943, Valid acc 0.934000, Time 00:01:42, lr 0.01\n",
      "Epoch 92. Train Loss: 0.004053, Train acc 0.999133, Valid Loss: 0.338002, Valid acc 0.933000, Time 00:01:41, lr 0.01\n",
      "Epoch 93. Train Loss: 0.005223, Train acc 0.998667, Valid Loss: 0.333307, Valid acc 0.933600, Time 00:01:45, lr 0.01\n",
      "Epoch 94. Train Loss: 0.004182, Train acc 0.998956, Valid Loss: 0.342936, Valid acc 0.934000, Time 00:01:40, lr 0.01\n",
      "Epoch 95. Train Loss: 0.004486, Train acc 0.998867, Valid Loss: 0.340817, Valid acc 0.934200, Time 00:01:41, lr 0.01\n",
      "Epoch 96. Train Loss: 0.003901, Train acc 0.999156, Valid Loss: 0.334879, Valid acc 0.934200, Time 00:01:41, lr 0.01\n",
      "Epoch 97. Train Loss: 0.003966, Train acc 0.998978, Valid Loss: 0.343019, Valid acc 0.935000, Time 00:01:38, lr 0.01\n",
      "Epoch 98. Train Loss: 0.003655, Train acc 0.999156, Valid Loss: 0.345798, Valid acc 0.933800, Time 00:01:40, lr 0.01\n",
      "Epoch 99. Train Loss: 0.003435, Train acc 0.999222, Valid Loss: 0.339348, Valid acc 0.935400, Time 00:01:39, lr 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAGjCAYAAAB69PLaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGUOUvImIiIiMIf8fK6xdqqc/zVsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f375e2e2810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.1\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1\n",
    "criterion = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "Train = True\n",
    "if Train:\n",
    "    train(model, train_data, valid_data, num_epochs, lr, wd, ctx, lr_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存训练后的教师网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_params('./model_compression/tea_rs38_93.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_params('./model_compression/tea_rs38_93.params',ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: 初始化月份字符串出错\r\n",
      "-rw-rw-r-- 1 dragon 9053143 3鏈�20 20:00 ./model_compression/tea_rs38_93.params\r\n"
     ]
    }
   ],
   "source": [
    "ll ./model_compression/tea_rs38_93.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.340523, Valid acc 0.935400Time 00:00:03\n"
     ]
    }
   ],
   "source": [
    "test(model,valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面是测试代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test = False\n",
    "if Test:\n",
    "    x = nd.random.uniform(shape=((4,3,32,32)))\n",
    "    rstea = Resnet_tea(10)\n",
    "    rstea.initialize(init.Xavier())\n",
    "    rstea.hybridize()\n",
    "    rstea(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学生网络设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Residual_stu(nn.HybridBlock):\n",
    "    def __init__(self, channels, same_shape=True):\n",
    "        super(Residual_stu, self).__init__()\n",
    "        self.same_shape = same_shape\n",
    "        strides = 1 if same_shape else 2\n",
    "        bn1 = nn.BatchNorm()\n",
    "        conv1 = nn.Conv2D(channels , 1,  strides=strides,use_bias=False)\n",
    "        bn2 = nn.BatchNorm()\n",
    "        rl1 = nn.Activation(activation='relu')\n",
    "        conv2 = nn.Conv2D(channels,kernel_size=3,strides=1,padding=1,use_bias=False)\n",
    "        bn3 = nn.BatchNorm()\n",
    "        self.net = nn.HybridSequential()\n",
    "        self.net.add(bn1,conv1,bn2,rl1,conv2,bn3)\n",
    "        if not same_shape:\n",
    "            conv3 = nn.Conv2D(channels,kernel_size=1,strides=strides)\n",
    "            self.net.add(conv3)\n",
    "\n",
    "    def hybrid_forward(self,F,x):\n",
    "        out = x\n",
    "        for l in self.net[:-1]:\n",
    "            out = l(out)\n",
    "        if not self.same_shape:\n",
    "            x=self.net[-1](x)\n",
    "        else:\n",
    "            out = self.net[-1](out)\n",
    "        return F.relu(out+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resnet8(nn.HybridBlock):\n",
    "    def __init__(self,num_classes,verbose=False,**kwargs):\n",
    "        super(Resnet8,self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            b1 = nn.HybridSequential()\n",
    "            b1.add(\n",
    "                nn.BatchNorm(),\n",
    "                nn.Conv2D(32,kernel_size=3,strides=1,use_bias=False),\n",
    "\n",
    "            )\n",
    "            b2 = nn.HybridSequential()\n",
    "            b2.add(\n",
    "                #nn.MaxPool2D(pool_size=3,strides=2),\n",
    "                Residual(32)#,Residual(64)\n",
    "            )\n",
    "            b3 = nn.HybridSequential()\n",
    "            b3.add(\n",
    "                Residual(64,same_shape=False)#,Residual(128)\n",
    "            )\n",
    "            b4 = nn.HybridSequential()\n",
    "            b4.add(\n",
    "                Residual(128,same_shape=False)#,Residual(256)\n",
    "            )\n",
    "            b5 = nn.HybridSequential()\n",
    "            b5.add(\n",
    "                nn.BatchNorm(),\n",
    "                nn.Activation('relu'),\n",
    "                nn.AvgPool2D(pool_size=8),\n",
    "                nn.Dense(num_classes)\n",
    "            )\n",
    "            self.net = nn.HybridSequential()\n",
    "            self.net.add(b1,b2,b3,b4,b5)\n",
    "            self.net1 = nn.HybridSequential()\n",
    "            self.net1.add(b1,b2)\n",
    "            self.net2 = nn.HybridSequential()\n",
    "            self.net2.add(b1,b2,b3)\n",
    "            self.net3 = nn.HybridSequential()\n",
    "            self.net3.add(b1,b2,b3,b4)\n",
    "    def hybrid_forward(self,F,x):\n",
    "        out = x\n",
    "        for i,block in enumerate(self.net):\n",
    "            out = block(out)\n",
    "            if self.verbose:\n",
    "                print(\"%d layer output shape is %s\"%(i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer output shape is (4L, 32L, 30L, 30L)\n",
      "2 layer output shape is (4L, 32L, 30L, 30L)\n",
      "3 layer output shape is (4L, 64L, 15L, 15L)\n",
      "4 layer output shape is (4L, 128L, 8L, 8L)\n",
      "5 layer output shape is (4L, 10L)\n"
     ]
    }
   ],
   "source": [
    "Test = True\n",
    "if Test:\n",
    "    x = nd.random.uniform(shape=((4,3,32,32)))\n",
    "    rs8 = Resnet8(10,True)\n",
    "    rs8.initialize(init.Xavier())\n",
    "    #rs8.hybridize()\n",
    "    rs8(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**从数据训练学生网络**\n",
    "\n",
    "准确率91.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs8 = Resnet8(10)\n",
    "ctx = try_gpu()\n",
    "rs8.initialize(ctx=ctx, init=mx.initializer.Xavier())\n",
    "rs8.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.1\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1\n",
    "criterion = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Train Loss: 1.736319, Train acc 0.359956, Valid Loss: 1.588645, Valid acc 0.425400, Time 00:00:42, lr 0.1\n",
      "Epoch 1. Train Loss: 1.333458, Train acc 0.518000, Valid Loss: 1.434378, Valid acc 0.494000, Time 00:00:45, lr 0.1\n",
      "Epoch 2. Train Loss: 1.129563, Train acc 0.595978, Valid Loss: 1.067887, Valid acc 0.623600, Time 00:00:47, lr 0.1\n",
      "Epoch 3. Train Loss: 0.996510, Train acc 0.645089, Valid Loss: 1.064298, Valid acc 0.625000, Time 00:00:47, lr 0.1\n",
      "Epoch 4. Train Loss: 0.902941, Train acc 0.679333, Valid Loss: 0.868640, Valid acc 0.693800, Time 00:00:46, lr 0.1\n",
      "Epoch 5. Train Loss: 0.827369, Train acc 0.707133, Valid Loss: 0.877616, Valid acc 0.694400, Time 00:00:47, lr 0.1\n",
      "Epoch 6. Train Loss: 0.759468, Train acc 0.734489, Valid Loss: 0.757018, Valid acc 0.734400, Time 00:00:48, lr 0.1\n",
      "Epoch 10. Train Loss: 0.570235, Train acc 0.802844, Valid Loss: 0.651992, Valid acc 0.777600, Time 00:00:47, lr 0.1\n",
      "Epoch 11. Train Loss: 0.546889, Train acc 0.811444, Valid Loss: 0.580373, Valid acc 0.801200, Time 00:00:48, lr 0.1\n",
      "Epoch 12. Train Loss: 0.514755, Train acc 0.822889, Valid Loss: 0.666595, Valid acc 0.779800, Time 00:00:46, lr 0.1\n",
      "Epoch 13. Train Loss: 0.496923, Train acc 0.831378, Valid Loss: 0.601117, Valid acc 0.798800, Time 00:00:47, lr 0.1\n",
      "Epoch 14. Train Loss: 0.470616, Train acc 0.837689, Valid Loss: 0.519848, Valid acc 0.820400, Time 00:00:46, lr 0.1\n",
      "Epoch 15. Train Loss: 0.447074, Train acc 0.846044, Valid Loss: 0.554122, Valid acc 0.819600, Time 00:00:45, lr 0.1\n",
      "Epoch 16. Train Loss: 0.430774, Train acc 0.851200, Valid Loss: 0.577825, Valid acc 0.808600, Time 00:00:46, lr 0.1\n",
      "Epoch 21. Train Loss: 0.366972, Train acc 0.873578, Valid Loss: 0.514450, Valid acc 0.829400, Time 00:00:46, lr 0.1\n",
      "Epoch 22. Train Loss: 0.355202, Train acc 0.878311, Valid Loss: 0.538287, Valid acc 0.829000, Time 00:00:47, lr 0.1\n",
      "Epoch 23. Train Loss: 0.337663, Train acc 0.885111, Valid Loss: 0.603071, Valid acc 0.817600, Time 00:00:46, lr 0.1\n",
      "Epoch 24. Train Loss: 0.336178, Train acc 0.884622, Valid Loss: 0.464446, Valid acc 0.847800, Time 00:00:45, lr 0.1\n",
      "Epoch 25. Train Loss: 0.326158, Train acc 0.887956, Valid Loss: 0.484001, Valid acc 0.843200, Time 00:00:47, lr 0.1\n",
      "Epoch 26. Train Loss: 0.311514, Train acc 0.893267, Valid Loss: 0.449237, Valid acc 0.853400, Time 00:00:47, lr 0.1\n",
      "Epoch 27. Train Loss: 0.300320, Train acc 0.896978, Valid Loss: 0.535481, Valid acc 0.834000, Time 00:00:47, lr 0.1\n",
      "Epoch 28. Train Loss: 0.294236, Train acc 0.899578, Valid Loss: 0.480459, Valid acc 0.848800, Time 00:00:47, lr 0.1\n",
      "Epoch 29. Train Loss: 0.288355, Train acc 0.900400, Valid Loss: 0.507292, Valid acc 0.837000, Time 00:00:47, lr 0.1\n",
      "Epoch 30. Train Loss: 0.284373, Train acc 0.901978, Valid Loss: 0.519500, Valid acc 0.836800, Time 00:00:47, lr 0.1\n",
      "Epoch 31. Train Loss: 0.270784, Train acc 0.906378, Valid Loss: 0.478934, Valid acc 0.852200, Time 00:00:47, lr 0.1\n",
      "Epoch 32. Train Loss: 0.264931, Train acc 0.908956, Valid Loss: 0.499825, Valid acc 0.837600, Time 00:00:48, lr 0.1\n",
      "Epoch 33. Train Loss: 0.256418, Train acc 0.911867, Valid Loss: 0.494369, Valid acc 0.848200, Time 00:00:49, lr 0.1\n",
      "Epoch 34. Train Loss: 0.257646, Train acc 0.911444, Valid Loss: 0.504564, Valid acc 0.842000, Time 00:00:46, lr 0.1\n",
      "Epoch 35. Train Loss: 0.250781, Train acc 0.913911, Valid Loss: 0.459596, Valid acc 0.851200, Time 00:00:46, lr 0.1\n",
      "Epoch 36. Train Loss: 0.243402, Train acc 0.917333, Valid Loss: 0.558522, Valid acc 0.828600, Time 00:00:46, lr 0.1\n",
      "Epoch 37. Train Loss: 0.229543, Train acc 0.923067, Valid Loss: 0.522834, Valid acc 0.834200, Time 00:00:46, lr 0.1\n",
      "Epoch 38. Train Loss: 0.229995, Train acc 0.919756, Valid Loss: 0.418878, Valid acc 0.865400, Time 00:00:46, lr 0.1\n",
      "Epoch 39. Train Loss: 0.228583, Train acc 0.920644, Valid Loss: 0.464870, Valid acc 0.858200, Time 00:00:47, lr 0.1\n",
      "Epoch 40. Train Loss: 0.224607, Train acc 0.922444, Valid Loss: 0.467997, Valid acc 0.855600, Time 00:00:47, lr 0.1\n",
      "Epoch 41. Train Loss: 0.213066, Train acc 0.927667, Valid Loss: 0.597024, Valid acc 0.833200, Time 00:00:46, lr 0.1\n",
      "Epoch 42. Train Loss: 0.212624, Train acc 0.925889, Valid Loss: 0.460645, Valid acc 0.856600, Time 00:00:47, lr 0.1\n",
      "Epoch 43. Train Loss: 0.207703, Train acc 0.928378, Valid Loss: 0.467947, Valid acc 0.859800, Time 00:00:47, lr 0.1\n",
      "Epoch 48. Train Loss: 0.181494, Train acc 0.937556, Valid Loss: 0.429791, Valid acc 0.869800, Time 00:00:48, lr 0.1\n",
      "Epoch 49. Train Loss: 0.184216, Train acc 0.937044, Valid Loss: 0.450305, Valid acc 0.867400, Time 00:00:48, lr 0.1\n",
      "Epoch 50. Train Loss: 0.178839, Train acc 0.938244, Valid Loss: 0.488682, Valid acc 0.854200, Time 00:00:47, lr 0.1\n",
      "Epoch 51. Train Loss: 0.176803, Train acc 0.939444, Valid Loss: 0.479074, Valid acc 0.859200, Time 00:00:47, lr 0.1\n",
      "Epoch 52. Train Loss: 0.172040, Train acc 0.941156, Valid Loss: 0.549289, Valid acc 0.846200, Time 00:00:46, lr 0.1\n",
      "Epoch 53. Train Loss: 0.173222, Train acc 0.940756, Valid Loss: 0.457417, Valid acc 0.864000, Time 00:00:46, lr 0.1\n",
      "Epoch 54. Train Loss: 0.165717, Train acc 0.943600, Valid Loss: 0.441511, Valid acc 0.871000, Time 00:00:46, lr 0.1\n",
      "Epoch 55. Train Loss: 0.160007, Train acc 0.946067, Valid Loss: 0.449087, Valid acc 0.865000, Time 00:00:47, lr 0.1\n",
      "Epoch 56. Train Loss: 0.160570, Train acc 0.946156, Valid Loss: 0.444576, Valid acc 0.865400, Time 00:00:47, lr 0.1\n",
      "Epoch 57. Train Loss: 0.156250, Train acc 0.946622, Valid Loss: 0.460281, Valid acc 0.865400, Time 00:00:48, lr 0.1\n",
      "Epoch 58. Train Loss: 0.156373, Train acc 0.947400, Valid Loss: 0.470690, Valid acc 0.857800, Time 00:00:47, lr 0.1\n",
      "Epoch 59. Train Loss: 0.151329, Train acc 0.948311, Valid Loss: 0.497954, Valid acc 0.862800, Time 00:00:46, lr 0.1\n",
      "Epoch 60. Train Loss: 0.141678, Train acc 0.952244, Valid Loss: 0.429877, Valid acc 0.870200, Time 00:00:46, lr 0.1\n",
      "Epoch 61. Train Loss: 0.141388, Train acc 0.951733, Valid Loss: 0.441362, Valid acc 0.870400, Time 00:00:45, lr 0.1\n",
      "Epoch 62. Train Loss: 0.139345, Train acc 0.953333, Valid Loss: 0.467728, Valid acc 0.867400, Time 00:00:48, lr 0.1\n",
      "Epoch 63. Train Loss: 0.136300, Train acc 0.953844, Valid Loss: 0.458015, Valid acc 0.869200, Time 00:00:46, lr 0.1\n",
      "Epoch 64. Train Loss: 0.134885, Train acc 0.955022, Valid Loss: 0.506244, Valid acc 0.855000, Time 00:00:46, lr 0.1\n",
      "Epoch 65. Train Loss: 0.135232, Train acc 0.954889, Valid Loss: 0.495107, Valid acc 0.866200, Time 00:00:45, lr 0.1\n",
      "Epoch 66. Train Loss: 0.132793, Train acc 0.955911, Valid Loss: 0.444242, Valid acc 0.865600, Time 00:00:48, lr 0.1\n",
      "Epoch 67. Train Loss: 0.130375, Train acc 0.956267, Valid Loss: 0.475291, Valid acc 0.864800, Time 00:00:45, lr 0.1\n",
      "Epoch 68. Train Loss: 0.130041, Train acc 0.955711, Valid Loss: 0.468225, Valid acc 0.871200, Time 00:00:47, lr 0.1\n",
      "Epoch 69. Train Loss: 0.124444, Train acc 0.958667, Valid Loss: 0.466618, Valid acc 0.871000, Time 00:00:48, lr 0.1\n",
      "Epoch 70. Train Loss: 0.122520, Train acc 0.958178, Valid Loss: 0.433319, Valid acc 0.878400, Time 00:00:46, lr 0.1\n",
      "Epoch 71. Train Loss: 0.126542, Train acc 0.956911, Valid Loss: 0.456804, Valid acc 0.874200, Time 00:00:47, lr 0.1\n",
      "Epoch 72. Train Loss: 0.119339, Train acc 0.960533, Valid Loss: 0.473397, Valid acc 0.873400, Time 00:00:47, lr 0.1\n",
      "Epoch 73. Train Loss: 0.122482, Train acc 0.958422, Valid Loss: 0.428758, Valid acc 0.877400, Time 00:00:48, lr 0.1\n",
      "Epoch 74. Train Loss: 0.115266, Train acc 0.961711, Valid Loss: 0.450174, Valid acc 0.872600, Time 00:00:47, lr 0.1\n",
      "Epoch 75. Train Loss: 0.118199, Train acc 0.960178, Valid Loss: 0.482989, Valid acc 0.862000, Time 00:00:47, lr 0.1\n",
      "Epoch 76. Train Loss: 0.115473, Train acc 0.960911, Valid Loss: 0.511496, Valid acc 0.860200, Time 00:00:48, lr 0.1\n",
      "Epoch 77. Train Loss: 0.109060, Train acc 0.964267, Valid Loss: 0.447989, Valid acc 0.880000, Time 00:00:48, lr 0.1\n",
      "Epoch 78. Train Loss: 0.106970, Train acc 0.964822, Valid Loss: 0.495256, Valid acc 0.860200, Time 00:00:47, lr 0.1\n",
      "Epoch 79. Train Loss: 0.107096, Train acc 0.964622, Valid Loss: 0.444386, Valid acc 0.873400, Time 00:00:48, lr 0.1\n",
      "Epoch 80. Train Loss: 0.127147, Train acc 0.957156, Valid Loss: 0.375248, Valid acc 0.895000, Time 00:00:48, lr 0.01\n",
      "Epoch 81. Train Loss: 0.076020, Train acc 0.977933, Valid Loss: 0.362646, Valid acc 0.898000, Time 00:00:47, lr 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82. Train Loss: 0.065714, Train acc 0.982489, Valid Loss: 0.353881, Valid acc 0.899200, Time 00:00:47, lr 0.01\n",
      "Epoch 83. Train Loss: 0.064713, Train acc 0.981844, Valid Loss: 0.354129, Valid acc 0.900000, Time 00:00:44, lr 0.01\n",
      "Epoch 84. Train Loss: 0.059287, Train acc 0.984756, Valid Loss: 0.349798, Valid acc 0.902400, Time 00:00:44, lr 0.01\n",
      "Epoch 85. Train Loss: 0.057414, Train acc 0.985378, Valid Loss: 0.344734, Valid acc 0.902600, Time 00:00:46, lr 0.01\n",
      "Epoch 86. Train Loss: 0.056280, Train acc 0.985622, Valid Loss: 0.348048, Valid acc 0.902800, Time 00:00:47, lr 0.01\n",
      "Epoch 87. Train Loss: 0.057245, Train acc 0.985289, Valid Loss: 0.351459, Valid acc 0.902800, Time 00:00:46, lr 0.01\n",
      "Epoch 88. Train Loss: 0.053648, Train acc 0.986844, Valid Loss: 0.345808, Valid acc 0.903000, Time 00:00:46, lr 0.01\n",
      "Epoch 89. Train Loss: 0.053150, Train acc 0.987178, Valid Loss: 0.348213, Valid acc 0.902400, Time 00:00:47, lr 0.01\n",
      "Epoch 90. Train Loss: 0.053445, Train acc 0.986778, Valid Loss: 0.351416, Valid acc 0.902600, Time 00:00:45, lr 0.01\n",
      "Epoch 91. Train Loss: 0.050949, Train acc 0.988200, Valid Loss: 0.349176, Valid acc 0.904000, Time 00:00:48, lr 0.01\n",
      "Epoch 92. Train Loss: 0.051640, Train acc 0.988067, Valid Loss: 0.350296, Valid acc 0.902800, Time 00:00:45, lr 0.01\n",
      "Epoch 97. Train Loss: 0.047917, Train acc 0.989222, Valid Loss: 0.349401, Valid acc 0.903800, Time 00:00:46, lr 0.01\n",
      "Epoch 98. Train Loss: 0.046460, Train acc 0.989356, Valid Loss: 0.351645, Valid acc 0.903400, Time 00:00:47, lr 0.01\n",
      "Epoch 99. Train Loss: 0.046458, Train acc 0.989067, Valid Loss: 0.348201, Valid acc 0.903000, Time 00:00:46, lr 0.01\n",
      "Epoch 100. Train Loss: 0.046332, Train acc 0.990267, Valid Loss: 0.350569, Valid acc 0.903600, Time 00:00:46, lr 0.01\n",
      "Epoch 101. Train Loss: 0.044348, Train acc 0.990422, Valid Loss: 0.349084, Valid acc 0.903800, Time 00:00:47, lr 0.01\n",
      "Epoch 102. Train Loss: 0.044797, Train acc 0.990400, Valid Loss: 0.353895, Valid acc 0.901600, Time 00:00:48, lr 0.01\n",
      "Epoch 103. Train Loss: 0.044894, Train acc 0.990044, Valid Loss: 0.355868, Valid acc 0.902000, Time 00:00:47, lr 0.01\n",
      "Epoch 104. Train Loss: 0.045671, Train acc 0.990267, Valid Loss: 0.353714, Valid acc 0.903000, Time 00:00:48, lr 0.01\n",
      "Epoch 105. Train Loss: 0.043589, Train acc 0.990822, Valid Loss: 0.353514, Valid acc 0.905200, Time 00:00:45, lr 0.01\n",
      "Epoch 106. Train Loss: 0.042777, Train acc 0.991378, Valid Loss: 0.350323, Valid acc 0.903000, Time 00:00:44, lr 0.01\n",
      "Epoch 107. Train Loss: 0.042467, Train acc 0.991267, Valid Loss: 0.351768, Valid acc 0.905400, Time 00:00:44, lr 0.01\n",
      "Epoch 108. Train Loss: 0.042823, Train acc 0.991533, Valid Loss: 0.352795, Valid acc 0.902400, Time 00:00:48, lr 0.01\n",
      "Epoch 109. Train Loss: 0.042983, Train acc 0.990978, Valid Loss: 0.355620, Valid acc 0.902800, Time 00:00:48, lr 0.01\n",
      "Epoch 110. Train Loss: 0.041778, Train acc 0.990733, Valid Loss: 0.350054, Valid acc 0.901800, Time 00:00:49, lr 0.01\n",
      "Epoch 111. Train Loss: 0.041658, Train acc 0.991533, Valid Loss: 0.356045, Valid acc 0.903000, Time 00:00:45, lr 0.01\n",
      "Epoch 112. Train Loss: 0.042469, Train acc 0.991044, Valid Loss: 0.351732, Valid acc 0.902400, Time 00:00:46, lr 0.01\n",
      "Epoch 113. Train Loss: 0.040272, Train acc 0.992422, Valid Loss: 0.355001, Valid acc 0.903600, Time 00:00:48, lr 0.01\n",
      "Epoch 114. Train Loss: 0.041404, Train acc 0.991111, Valid Loss: 0.355981, Valid acc 0.903200, Time 00:00:47, lr 0.01\n",
      "Epoch 117. Train Loss: 0.039688, Train acc 0.992156, Valid Loss: 0.354527, Valid acc 0.904600, Time 00:00:48, lr 0.01\n",
      "Epoch 118. Train Loss: 0.039425, Train acc 0.992511, Valid Loss: 0.358736, Valid acc 0.902800, Time 00:00:48, lr 0.01\n",
      "Epoch 119. Train Loss: 0.039662, Train acc 0.992422, Valid Loss: 0.354130, Valid acc 0.904600, Time 00:00:43, lr 0.01\n",
      "Epoch 120. Train Loss: 0.039969, Train acc 0.991911, Valid Loss: 0.356730, Valid acc 0.906600, Time 00:00:43, lr 0.001\n",
      "Epoch 121. Train Loss: 0.038704, Train acc 0.992178, Valid Loss: 0.355710, Valid acc 0.904800, Time 00:00:47, lr 0.001\n",
      "Epoch 122. Train Loss: 0.038210, Train acc 0.992511, Valid Loss: 0.355074, Valid acc 0.905600, Time 00:00:46, lr 0.001\n",
      "Epoch 123. Train Loss: 0.037752, Train acc 0.992867, Valid Loss: 0.354030, Valid acc 0.903800, Time 00:00:48, lr 0.001\n",
      "Epoch 124. Train Loss: 0.037926, Train acc 0.992733, Valid Loss: 0.355199, Valid acc 0.904000, Time 00:00:47, lr 0.001\n",
      "Epoch 125. Train Loss: 0.037779, Train acc 0.992689, Valid Loss: 0.355216, Valid acc 0.905200, Time 00:00:49, lr 0.001\n",
      "Epoch 126. Train Loss: 0.038345, Train acc 0.992756, Valid Loss: 0.352748, Valid acc 0.904600, Time 00:00:47, lr 0.001\n",
      "Epoch 127. Train Loss: 0.037253, Train acc 0.992933, Valid Loss: 0.353681, Valid acc 0.904000, Time 00:00:48, lr 0.001\n",
      "Epoch 128. Train Loss: 0.038235, Train acc 0.992711, Valid Loss: 0.354127, Valid acc 0.904600, Time 00:00:47, lr 0.001\n",
      "Epoch 129. Train Loss: 0.037289, Train acc 0.992800, Valid Loss: 0.353874, Valid acc 0.905000, Time 00:00:47, lr 0.001\n",
      "Epoch 130. Train Loss: 0.037742, Train acc 0.993133, Valid Loss: 0.354249, Valid acc 0.904800, Time 00:00:47, lr 0.001\n",
      "Epoch 131. Train Loss: 0.037673, Train acc 0.992756, Valid Loss: 0.353234, Valid acc 0.905800, Time 00:00:49, lr 0.001\n",
      "Epoch 132. Train Loss: 0.037393, Train acc 0.993022, Valid Loss: 0.354946, Valid acc 0.905000, Time 00:00:46, lr 0.001\n",
      "Epoch 133. Train Loss: 0.037015, Train acc 0.993111, Valid Loss: 0.355044, Valid acc 0.906600, Time 00:00:47, lr 0.001\n",
      "Epoch 134. Train Loss: 0.037093, Train acc 0.992622, Valid Loss: 0.356360, Valid acc 0.906000, Time 00:00:48, lr 0.001\n",
      "Epoch 135. Train Loss: 0.038429, Train acc 0.992556, Valid Loss: 0.354761, Valid acc 0.903000, Time 00:00:48, lr 0.001\n",
      "Epoch 136. Train Loss: 0.037112, Train acc 0.992933, Valid Loss: 0.354006, Valid acc 0.904000, Time 00:00:47, lr 0.001\n",
      "Epoch 137. Train Loss: 0.037100, Train acc 0.992800, Valid Loss: 0.355702, Valid acc 0.905400, Time 00:00:48, lr 0.001\n",
      "Epoch 138. Train Loss: 0.037970, Train acc 0.993067, Valid Loss: 0.355932, Valid acc 0.905400, Time 00:00:48, lr 0.001\n",
      "Epoch 139. Train Loss: 0.037312, Train acc 0.992844, Valid Loss: 0.353278, Valid acc 0.905600, Time 00:00:47, lr 0.001\n",
      "Epoch 140. Train Loss: 0.038008, Train acc 0.993000, Valid Loss: 0.352887, Valid acc 0.904800, Time 00:00:47, lr 0.001\n",
      "Epoch 141. Train Loss: 0.036200, Train acc 0.993578, Valid Loss: 0.352097, Valid acc 0.905800, Time 00:00:47, lr 0.001\n",
      "Epoch 142. Train Loss: 0.037240, Train acc 0.992978, Valid Loss: 0.352447, Valid acc 0.905200, Time 00:00:44, lr 0.001\n",
      "Epoch 143. Train Loss: 0.037010, Train acc 0.993044, Valid Loss: 0.355520, Valid acc 0.905400, Time 00:00:46, lr 0.001\n",
      "Epoch 144. Train Loss: 0.036149, Train acc 0.993378, Valid Loss: 0.354142, Valid acc 0.905400, Time 00:00:44, lr 0.001\n",
      "Epoch 145. Train Loss: 0.037670, Train acc 0.993200, Valid Loss: 0.353571, Valid acc 0.904000, Time 00:00:44, lr 0.001\n",
      "Epoch 146. Train Loss: 0.037112, Train acc 0.993378, Valid Loss: 0.352901, Valid acc 0.906000, Time 00:00:44, lr 0.001\n",
      "Epoch 147. Train Loss: 0.036808, Train acc 0.992867, Valid Loss: 0.351959, Valid acc 0.905600, Time 00:00:47, lr 0.001\n",
      "Epoch 148. Train Loss: 0.038348, Train acc 0.992778, Valid Loss: 0.351708, Valid acc 0.905000, Time 00:00:47, lr 0.001\n",
      "Epoch 149. Train Loss: 0.037298, Train acc 0.993089, Valid Loss: 0.352567, Valid acc 0.905600, Time 00:00:48, lr 0.001\n",
      "Epoch 150. Train Loss: 0.036429, Train acc 0.993156, Valid Loss: 0.354052, Valid acc 0.906000, Time 00:00:48, lr 0.001\n",
      "Epoch 151. Train Loss: 0.036719, Train acc 0.993222, Valid Loss: 0.353426, Valid acc 0.906000, Time 00:00:46, lr 0.001\n",
      "Epoch 152. Train Loss: 0.036338, Train acc 0.993578, Valid Loss: 0.353471, Valid acc 0.906400, Time 00:00:49, lr 0.001\n",
      "Epoch 153. Train Loss: 0.037075, Train acc 0.993422, Valid Loss: 0.353997, Valid acc 0.905600, Time 00:00:48, lr 0.001\n",
      "Epoch 157. Train Loss: 0.036315, Train acc 0.993244, Valid Loss: 0.355099, Valid acc 0.905400, Time 00:00:47, lr 0.001\n",
      "Epoch 158. Train Loss: 0.036099, Train acc 0.993711, Valid Loss: 0.357128, Valid acc 0.905800, Time 00:00:44, lr 0.001\n",
      "Epoch 159. Train Loss: 0.036797, Train acc 0.993156, Valid Loss: 0.354765, Valid acc 0.904800, Time 00:00:44, lr 0.001\n",
      "Epoch 160. Train Loss: 0.036066, Train acc 0.993400, Valid Loss: 0.355532, Valid acc 0.906200, Time 00:00:46, lr 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161. Train Loss: 0.035324, Train acc 0.993800, Valid Loss: 0.352813, Valid acc 0.905000, Time 00:00:46, lr 0.001\n",
      "Epoch 162. Train Loss: 0.036138, Train acc 0.993333, Valid Loss: 0.352304, Valid acc 0.907000, Time 00:00:47, lr 0.001\n",
      "Epoch 163. Train Loss: 0.036117, Train acc 0.993756, Valid Loss: 0.355048, Valid acc 0.904800, Time 00:00:46, lr 0.001\n",
      "Epoch 164. Train Loss: 0.036066, Train acc 0.993378, Valid Loss: 0.354443, Valid acc 0.905400, Time 00:00:46, lr 0.001\n",
      "Epoch 165. Train Loss: 0.036342, Train acc 0.993289, Valid Loss: 0.356173, Valid acc 0.904400, Time 00:00:46, lr 0.001\n",
      "Epoch 166. Train Loss: 0.036578, Train acc 0.992978, Valid Loss: 0.355369, Valid acc 0.905400, Time 00:00:47, lr 0.001\n",
      "Epoch 167. Train Loss: 0.036572, Train acc 0.993578, Valid Loss: 0.355195, Valid acc 0.904600, Time 00:00:43, lr 0.001\n",
      "Epoch 168. Train Loss: 0.036870, Train acc 0.993467, Valid Loss: 0.354339, Valid acc 0.905200, Time 00:00:44, lr 0.001\n",
      "Epoch 169. Train Loss: 0.036916, Train acc 0.993311, Valid Loss: 0.355596, Valid acc 0.905400, Time 00:00:42, lr 0.001\n",
      "Epoch 170. Train Loss: 0.035424, Train acc 0.994067, Valid Loss: 0.356592, Valid acc 0.905400, Time 00:00:44, lr 0.001\n",
      "Epoch 171. Train Loss: 0.036904, Train acc 0.992889, Valid Loss: 0.355377, Valid acc 0.906200, Time 00:00:43, lr 0.001\n",
      "Epoch 172. Train Loss: 0.035462, Train acc 0.993311, Valid Loss: 0.356676, Valid acc 0.906400, Time 00:00:44, lr 0.001\n",
      "Epoch 173. Train Loss: 0.036508, Train acc 0.993800, Valid Loss: 0.354861, Valid acc 0.905000, Time 00:00:42, lr 0.001\n",
      "Epoch 174. Train Loss: 0.037045, Train acc 0.993089, Valid Loss: 0.354140, Valid acc 0.905600, Time 00:00:44, lr 0.001\n",
      "Epoch 175. Train Loss: 0.036464, Train acc 0.993733, Valid Loss: 0.355192, Valid acc 0.906200, Time 00:00:46, lr 0.001\n",
      "Epoch 176. Train Loss: 0.036057, Train acc 0.993378, Valid Loss: 0.354126, Valid acc 0.905400, Time 00:00:47, lr 0.001\n",
      "Epoch 177. Train Loss: 0.035742, Train acc 0.993689, Valid Loss: 0.355961, Valid acc 0.904600, Time 00:00:48, lr 0.001\n",
      "Epoch 178. Train Loss: 0.035469, Train acc 0.993822, Valid Loss: 0.355826, Valid acc 0.904400, Time 00:00:46, lr 0.001\n",
      "Epoch 179. Train Loss: 0.036230, Train acc 0.993800, Valid Loss: 0.356059, Valid acc 0.904400, Time 00:00:46, lr 0.001\n",
      "Epoch 180. Train Loss: 0.036461, Train acc 0.993311, Valid Loss: 0.355418, Valid acc 0.906600, Time 00:00:46, lr 0.001\n",
      "Epoch 181. Train Loss: 0.035705, Train acc 0.993511, Valid Loss: 0.355093, Valid acc 0.904800, Time 00:00:46, lr 0.001\n",
      "Epoch 182. Train Loss: 0.035352, Train acc 0.993978, Valid Loss: 0.353415, Valid acc 0.905800, Time 00:00:47, lr 0.001\n",
      "Epoch 183. Train Loss: 0.035825, Train acc 0.993756, Valid Loss: 0.354347, Valid acc 0.905000, Time 00:00:48, lr 0.001\n",
      "Epoch 184. Train Loss: 0.036074, Train acc 0.993511, Valid Loss: 0.356853, Valid acc 0.904800, Time 00:00:48, lr 0.001\n",
      "Epoch 185. Train Loss: 0.035603, Train acc 0.993556, Valid Loss: 0.356665, Valid acc 0.905000, Time 00:00:46, lr 0.001\n",
      "Epoch 186. Train Loss: 0.034635, Train acc 0.994600, Valid Loss: 0.355994, Valid acc 0.904800, Time 00:00:48, lr 0.001\n",
      "Epoch 187. Train Loss: 0.035399, Train acc 0.993600, Valid Loss: 0.355093, Valid acc 0.904800, Time 00:00:46, lr 0.001\n",
      "Epoch 188. Train Loss: 0.036345, Train acc 0.993000, Valid Loss: 0.354070, Valid acc 0.906000, Time 00:00:47, lr 0.001\n",
      "Epoch 189. Train Loss: 0.036267, Train acc 0.993022, Valid Loss: 0.355533, Valid acc 0.904600, Time 00:00:46, lr 0.001\n",
      "Epoch 190. Train Loss: 0.035499, Train acc 0.994444, Valid Loss: 0.355960, Valid acc 0.905200, Time 00:00:47, lr 0.001\n",
      "Epoch 197. Train Loss: 0.036016, Train acc 0.993533, Valid Loss: 0.354294, Valid acc 0.904400, Time 00:00:46, lr 0.001\n",
      "Epoch 198. Train Loss: 0.035735, Train acc 0.993867, Valid Loss: 0.358239, Valid acc 0.903600, Time 00:00:45, lr 0.001\n",
      "Epoch 199. Train Loss: 0.035946, Train acc 0.993356, Valid Loss: 0.357938, Valid acc 0.905600, Time 00:00:44, lr 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAGjCAYAAAC7c7h2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAASdAAAEnQB3mYfeAAAIABJREFUeJzs3Xl8lOW9///XNftkDyEhYV9kURYVxX1pFXdFD661tOI5\n1l9PD1pr29NqqYpa7aJYa78ea9Uu6rFq61K1IlppPUpt3QVUUCDIHkLInkxmuX5/3DOTSUggCzMT\n4P18POYxM/d93fd93ZPAfPK5NmOtRURERET2Pa5sV0BERERE0kOBnoiIiMg+SoGeiIiIyD5KgZ6I\niIjIPkqBnoiIiMg+SoGeiIiIyD5KgZ6IiIjIPkqBnoiIiMg+SoGeiIiIyD5KgZ6IiIjIPkqBnoiI\niMg+SoGeiIiIyD5KgZ6IiIjIPsqT7QpkmjGmEDgRWA+0Zbk6IiIiIrviA0YAf7fW1vX24P0u0MMJ\n8p7NdiVEREREeuFc4M+9PWh/DPTWAzzzzDMccMAB2a6LiIiISLc+++wzzjvvPIjHL721PwZ6bQAH\nHHAAkydPznZdRERERHqiT93NNBhDREREZB+lQE9ERERkH6VAT0RERGQfpUBPREREZB+1Pw7GEBER\n2e9FIhF27NhBY2Mj1tpsV2e/YowhLy+P4uJiPJ70hmJ9zugZY/KMMQuMMYuMMTXGGGuMmdvDY/8W\nL9/VI9zDsov6WncREZH9mbWWDRs2UF1dTTgc3v0BskeFw2Gqq6vZuHFj2oPs/oSRg4EbgM+BD4Av\n9OLYHwEPdNqWC9wHLO6i/Abguk7bNvXieiIiIhLX0NBAS0sLhYWFVFRUYIzJdpX2K9ZaNm/eTF1d\nHQ0NDRQUFKTtWv0J9DYDFdbaLcaYw4G3enqgtfblztuMMXPiLx/t4pA6a+0jfaumiIiIpKqvrweg\nrKxMQV4WGGMoKyujrq6O+vr6tAZ6fW66tdaGrLVb9mBdLgWa6GZ5MmOMxxiTtwevJyIisl8Kh8N4\nPJ609w+T7iU+/3Q3nQ+IUbfGmFLgFOAZa21TF0Um4ASBDcaYLcaYW4wx3oxWUkREZB9hrcXlGhAh\nwH7N5XIN6D56e9LFOHXpqtl2NbAEWIbTj+8CYD5O8Hfxrk5qjCkDSjttHtffyoqIiOzt1GSbfZn4\nGQyUQO9SYBuwU989a+1/dNr0sDHmfuBrxpi7rLVv7uK83wBu3HPVFBEREdl7ZD1va4wZCxwNPG6t\njfTwsDvjzzN3U+5eYEqnx7l9qWdPba1v5bS7XuMLP1vCCx9uTuelREREpAu//e1vMcZQWVmZ7apk\n3UDI6F0af+6q2bY76+PPg3ZVyFpbBVSlbkt3mtQAK7c2ALCjuS2t1xIRERHZlaxn9HACvdW7aYLt\nbGz8eVsa6tMvfq87+bo1HM1iTURERGR/l/ZAzxhTYYyZ1NUoWWPMocCBwP92c2yBMcbfaZvBGYwB\n8NKerm9/+T3tH2koEstiTURERGR/169AzxgzzxgzH/j3+KZzjDHz44/C+LbbgY+BYV2c4svx5+6a\nbacDlcaYhcaYbxhjvg38H85o2/utte/2p/7poEBPRERk4Ln33nuZPHkyfr+foUOH8l//9V/U1tZ2\nKPPpp59y/vnnU15eTiAQYPjw4VxyySXU1dUly7z88sscd9xxFBUVkZeXx8SJE7n++uszfTs91t8+\net8BRqW8nx1/ADwC1O10RJwxxgVcArxrrV3ZTbF1OIHdvwHlQAwnaPw6cH+/ap4mxhj8HhehSIyQ\nmm5FRESy7qabbmLBggXMnDmT//zP/2TlypX8z//8D2+99RZvvPEGXq+XtrY2TjvtNEKhEFdddRXl\n5eVs3LiR559/ntraWgoLC1mxYgVnn30206ZN4+abb8bv9/PZZ5/xxhtvZPsWu9WvQM9aO7oHZeYC\nc7vYHgOG7+bYtcBFfatd9iQDPWX0REREsmrbtm3cfvvtnHrqqbz44ovJiaInTZrEvHnzeOSRR7j8\n8sv56KOPWLt2LU8++SQXXHBB8vgbbrgh+frll1+mra2NF198kcGDB2f8XvpiIIy63ef4vW5ojRCK\nKKMnIiJ7jwXPreCjTfXZrkbSQUMLuPGcyf06xyuvvEJbWxvXXHNNh9VAvva1r3H99dfzwgsvcPnl\nl1NY6PQ4e+mllzjzzDPJycnZ6VxFRUUAPPvss1x++eV7xeoiCvTSIOB1fvCtYWX0RERk7/HRpnr+\nubYm29XYo9atWwfAxIkTO2z3+XyMHTs2uX/MmDFce+21LFy4kEcffZTjjz+eWbNmMWfOnGQQePHF\nF/PAAw9wxRVX8P3vf5+TTz6Z2bNnc8EFFwzYoE+BXhr4Pc4UK8roiYjI3uSgoQXZrkIHma7PnXfe\nydy5c3n22WdZvHgxV199Nbfffjtvvvkmw4cPJxgM8tprr7FkyRJeeOEFFi1axOOPP85JJ53E4sWL\ncbvdu79IhinQSwNl9EREZG/U32bSgWjUKGfM6MqVKxk7dmxye1tbG2vXrmXmzI6LbE2dOpWpU6cy\nf/58li5dyrHHHst9993HrbfeCoDL5eLkk0/m5JNPZuHChdx222384Ac/YMmSJTudayAYmHnGvZwy\neiIiIgPDzJkz8fl8/OIXv8Bam9z+4IMPUldXx1lnnQVAfX09kUjHlVinTp2Ky+UiFAoBUFOzc7P2\nIYccApAsM9Aoo5cGibn0QsroiYiIZFVpaSnXXXcdCxYs4PTTT2fWrFmsXLmSe++9lxkzZjBnzhwA\nXn31VebNm8eFF17IhAkTiEQiPPzww7jdbs4//3wAbr75Zl577TXOOussRo0aRVVVFffeey/Dhw/n\nuOOOy+ZtdkuBXhoE4sugtSqjJyIiknU33XQTpaWl/PKXv+Rb3/oWgwYN4sorr+S2227D63UW7jr4\n4IM57bTTeO6559i4cSM5OTkcfPDBvPjiixx11FEAzJo1i8rKSh566CGqq6sZPHgwJ554IgsWLEgO\n2BhoTGoac39gjJkMLF++fDmTJ6enL8J/PvIOLy7fwviyPF6+9sS0XENERKSv1qxZA9Chz5pkXk9+\nDitWrGDKlCkAU6y1K3p7DfXRS4Nk060mTBYREZEsUqCXBsmmWy2BJiIiIlmkQC8NlNETERGRgUCB\nXhoooyciIiIDgQK9NEjN6O1vg11ERERk4FCglwZ+b/sSKG1RNd+KiIhIdijQS4NERg+0DJqIiIhk\njwK9NEjN6GkZNBEREckWBXppEEjJ6GkZNBEREckWBXppoIyeiIiIDAQK9NJAffRERERkIFCglwaB\nDhk9BXoiIiKSHQr00sDfoY+emm5FRET2FaNHj2bu3LnZrkaPKdBLgw6BnjJ6IiIiGbV06VJuuukm\namtrs12VrPNkuwL7otSmWy2DJiIikllLly5lwYIFzJ07l6Kioj167pUrV+Jy7T15sr2npnsRZfRE\nREQGvlgsRmtra6+O8fv9eL3eNNVoz1OglwYBTa8iIiKSFTfddBPf/e53ARgzZgzGGIwxVFZWYoxh\n3rx5PProo0yePBm/38+iRYsAuOOOOzjmmGMoKSkhGAxy2GGH8cc//nGn83fuo/fb3/4WYwxvvPEG\n1157LaWlpeTm5vJv//ZvbNu2LSP3vCtquk0DTa8iIiKSHbNnz2bVqlU89thj3HXXXQwePBiA0tJS\nAF599VWeeOIJ5s2bx+DBgxk9ejQAd999N7NmzeLLX/4ybW1t/OEPf+DCCy/k+eef56yzztrtda+6\n6iqKi4u58cYbqays5Oc//znz5s3j8ccfT9u99oQCvTTQhMkiIrJXevH7sGVZtmvRrnwqnPHjXh0y\nbdo0pk+fzmOPPcZ5552XDOQSVq5cybJlyzjooIM6bF+1ahXBYDD5ft68eUyfPp2FCxf2KNArKSlh\n8eLFGGMAp1n4F7/4BXV1dRQWFvbqHvYkBXppoCXQRERkr7RlGax7Pdu1SKsTTzxxpyAP6BDk7dix\ng2g0yvHHH89jjz3Wo/NeeeWVySAP4Pjjj+euu+5i3bp1TJs2rf8V7yMFemngcbtwuwzRmKVVGT0R\nEdlblE/Ndg06SkN9xowZ0+X2559/nltvvZX333+fUCiU3J4avO3KyJEjO7wvLi4GnKAxmxTopYnf\n46K5LaqMnoiI7D162Uy6N0rN3CX83//9H7NmzeKEE07g3nvvpaKiAq/Xy29+8xv+93//t0fndbvd\nXW631varvv2lQC9NAl43zW1RZfREREQyrKdZuIQ//elPBAIBXnrpJfx+f3L7b37zmz1dtYzT9Cpp\nkhh5q4yeiIhIZuXm5gL0eGUMt9uNMYZotD05U1lZyTPPPJOW+mWSAr00ScylpwmTRUREMuuwww4D\n4Ac/+AEPP/wwf/jDH2hqauq2/FlnnUVzczOnn3469913HzfffDNHHnkkBxxwQKaqnDZquk2TREZP\nS6CJiIhk1owZM7jlllu47777WLRoEbFYjLVr13Zb/qSTTuLBBx/kxz/+Mddccw1jxozhJz/5CZWV\nlXz44YcZrPmeZ7LdSTDTjDGTgeXLly9n8uTJabvOub98nQ821HHihFJ+9+9HpO06IiIivbVmzRoA\nxo4dm+Wa7N968nNYsWIFU6ZMAZhirV3R22v0uenWGJNnjFlgjFlkjKkxxlhjzNweHjs3Xr6rR3kX\n5Y8xxrxujGk2xmwxxvzCGJPX17pngj/ZdKuMnoiIiGRHf5puBwM3AJ8DHwBf6MM5bgA651I79Jw0\nxhwC/BX4GLgWGA58BxgPnNGHa2ZEe9Ot+uiJiIhIdvQn0NsMVFhrtxhjDgfe6sM5XrTWvr2bMrcB\nO4AvWGvrAYwxlcCvjTGnWmsX9+G6aef3aDCGiIiIZFefm26ttSFr7Zb+VsAYk2+M6XKWQWNMAXAK\n8EgiyIv7PdAIXNTf66dLwBufXkVNtyIiIpIl2R51uwTIA9qMMS8B37bWfpqyfypOHTtk/ay1bcaY\n94FDd3VyY0wZUNpp87h+17oHkhk9Nd2KiIhIlmQr0GsGfosT6NUDh+H0v1tqjJlurV0fL1cRf97c\nxTk2A8fv5jrfAG7sd237QBk9ERERybasBHrW2ieAJ1I2PRPP6L0G/AD4enx7YkG6EDtrTdnfnXuB\nJzttGwc826sK90Eio6fBGCIiIpIt2W66TbLWvm6M+ScwM2VzS/zZ38UhgZT93Z2zCqhK3dbb9e/6\nyq+MnoiIiGTZQFsCbT0wKOV9osm2oouyFcCmtNeojwLxjF44aonG9q9JqUVERGRgGGiB3lhgW8r7\n5UAEODy1kDHGBxwCvJ+5qvVOIqMHyuqJiIhIdqQ90DPGVBhjJhljvCnbOo+ExRhzJs6gjEWJbdba\nOuAVYI4xJj+l+FdwRut27n83YCQmTAaNvBUREZHs6FcfPWPMPKAIGBrfdI4xZnj89T3xQO124DJg\nDFAZ37fUGPMezrQpdcB04N9xmm5v63SZHwBLgb8bY+7HWRnj28Bia+0iBqiAt31qQE2aLCIiItnQ\n38EY3wFGpbyfHX8APIITxHXlceAs4FQgB6cv3q+BBdbarakFrbXvGmNmAj8B7gIagAeB6/pZ97RK\nzei1htV0KyIikilLly5l8eLFXHPNNRQVFaXlGrfddhsHHXQQ5513XlrOv6f0q+nWWjvaWmu6eVTG\ny8xNfR/fNt9ae6i1tsha67PWjrLWfqNzkJdS/nVr7bHW2qC1tsxaO89a29CfuqebMnoiIiLZsXTp\nUhYsWEBtbW3arnHbbbfxzDPPpO38e8pAG4yxz1BGT0RERLJNgV6aJCZMBmX0REREMuWmm27iu9/9\nLgBjxozBGIMxhsrKSgAeeeQRDjvsMILBIIMGDeKSSy5h/fr1Hc7x6aefcv7551NeXk4gEGD48OFc\ncskl1NU5PdKMMTQ1NfG73/0uef65c+dm8jZ7bMBMmLyvCWh6FRERkYybPXs2q1at4rHHHuOuu+5i\n8ODBAJSWlvKjH/2IH/7wh1x00UVcccUVbNu2jXvuuYcTTjiB9957j6KiItra2jjttNMIhUJcddVV\nlJeXs3HjRp5//nlqa2spLCzk4Ycf5oorruCII47gyiuvBGDcuHHZvO1uKdBLk9SMnpZBExERyYxp\n06Yxffp0HnvsMc477zxGjx4NwLp167jxxhu59dZbuf7665PlZ8+ezaGHHsq9997L9ddfz0cffcTa\ntWt58sknueCCC5LlbrjhhuTrOXPm8PWvf52xY8cyZ86cjN1bXyjQSxNNmCwiInubn/zrJ3xS80m2\nq5E0adAkvnfE9/bIuZ566ilisRgXXXQR1dXVye3l5eWMHz+eJUuWcP3111NYWAjASy+9xJlnnklO\nTs4euX62KNBLk0BqHz1l9EREZC/wSc0nvL317WxXIy0+/fRTrLWMHz++y/1er7Ouw5gxY7j22mtZ\nuHAhjz76KMcffzyzZs1izpw5ySBwb6JAL01SM3qtyuiJiMheYNKgSdmuQgd7sj6xWAxjDC+++CJu\nt3un/Xl5ecnXd955J3PnzuXZZ59l8eLFXH311dx+++28+eabDB8+fKdjBzIFemmijJ6IiOxt9lQz\nabYZY3baNm7cOKy1jBkzhgkTJuz2HFOnTmXq1KnMnz+fpUuXcuyxx3Lfffdx6623dnuNgUjTq6RJ\nxz56CvREREQyJTc3F6DDhMmzZ8/G7XazYMECrLUdyltr2b59OwD19fVEIpEO+6dOnYrL5SIUCnW4\nRjonZN5TlNFLE59bEyaLiIhkw2GHHQbAD37wAy655BK8Xi/nnHMOt956K9dddx2VlZWcd9555Ofn\ns3btWp5++mmuvPJKvvOd7/Dqq68yb948LrzwQiZMmEAkEuHhhx/G7XZz/vnnd7jGK6+8wsKFCxk6\ndChjxozhyCOPzNYtd0uBXpq4XAafx0VbJKaMnoiISAbNmDGDW265hfvuu49FixYRi8VYu3Yt3//+\n95kwYQJ33XUXCxYsAGDEiBGceuqpzJo1C4CDDz6Y0047jeeee46NGzeSk5PDwQcfzIsvvshRRx2V\nvMbChQu58sormT9/Pi0tLVx22WUDMtAzndOX+zpjzGRg+fLly5k8eXJarzX1ppdoaI0w95jR3DQr\nvdcSERHpqTVr1gAwduzYLNdk/9aTn8OKFSuYMmUKwBRr7YreXkN99NIoMWmyMnoiIiKSDQr00iix\nDJomTBYREZFsUKCXRn5PPNDT9CoiIiKSBQr00ijgTTTdKqMnIiIimadAL42SGT310RMREZEsUKCX\nRonBGJpHT0REBpr9bdaNgSgTPwMFemnUPhhDGT0RERk4XC4X0WhUwV4WWWuJRqO4XOkNxRTopZEy\neiIiMhD5/X6i0ShVVVUK9rLAWktVVRXRaBS/35/Wa2lljDRSRk9ERAaiIUOGEAqFqKmpoa6uDrfb\njTEm29XaLyQyedFolGAwyJAhQ9J6PQV6aZScMFnTq4iIyADicrkYOXIkW7duJRQKEYvpeypTjDH4\nfD78fj9DhgxJe9OtAr008sczeq2aXkVERAYYl8tFRUVFtqshaaY+emkUjM+j19KmQE9EREQyT4Fe\nGuUHnIRpKBLTpMkiIiKScQr00qgw6E2+rm+JZLEmIiIisj9SoJdGBSmBXl1LOIs1ERERkf2RAr00\nUqAnIiIi2aRAL406NN22KtATERGRzFKgl0YFgdQ+egr0REREJLMU6KVRx8EYCvREREQksxTopVFB\nsH0+avXRExERkUxToJdGfo87ud5tfaumVxEREZHMUqCXZol+enXNyuiJiIhIZvU50DPG5BljFhhj\nFhljaowx1hgzt4fHnmyMecgYs8oY02yMWWOMecAYs9Oie8aYv8XP3fmxqK91z6REPz2NuhUREZFM\n8+y+SLcGAzcAnwMfAF/oxbE/AQYBTwKfAmOBecDZxphDrLVbOpXfAFzXadumPtQ54xJz6amPnoiI\niGRafwK9zUCFtXaLMeZw4K1eHHst8Lq1NpbYEM/Q/R0n4JvfqXydtfaRftQ1a5TRExERkWzpc9Ot\ntTbUReatp8e+lhrkJbYBNcCBXR1jjPEYY/L6cr1sKgg4sbQyeiIiIpJpA2YwRjyIywOqu9g9AWgC\nGowxW4wxtxhjvF2UG3CSGb0WjboVERGRzOpP0+2edg3gAx7vtH01sARYBuQCF+A07U4ALt7VCY0x\nZUBpp83j9kRle6ogpek2FrO4XCaTlxcREZH92IAI9IwxJwA3Ak9Ya19N3Wet/Y9OxR82xtwPfM0Y\nc5e19s1dnPob8fNmTSKjZy00tkU6LIsmIiIikk5Zb7o1xkwCngaWA1f08LA7488zd1PuXmBKp8e5\nfahmn6UGdppLT0RERDIpqxk9Y8wIYDFQB5xprW3o4aHr48+DdlXIWlsFVHW6Zm+r2S8FKevd1rWE\nGZHRq4uIiMj+LGuBnjGmBCfI8wMnW2s39+LwsfHnbXu8YntY6nq3mmJFREREMintTbfGmApjzKTU\nUbLGmFzgL8AwnEzep90cW2CM8XfaZmifZ++lNFV7jylMyejVa4oVERERyaB+ZfSMMfOAImBofNM5\nxpjh8df3WGvrgNuBy4AxQGV836PAEcBDwIHGmNS58xqttc/EX08HHjPGPAZ8BgSBfwOOBe631r7b\nn/pnQmofPU2xIiIiIpnU36bb7wCjUt7Pjj8AHsHpe9eVQ+LP/x5/pFoHPJPy+v9wgrtyIAZ8DHwd\nuL8/Fc+UwpyOffREREREMqVfgZ61dnQPyswF5vb2uHi5tcBFva/ZwJHn82CMM72K+uiJiIhIJmV9\nepV9nctlks23yuiJiIhIJinQy4DEyFsNxhAREZFMUqCXAYmRt8roiYiISCYp0MuAwuR6txp1KyIi\nIpmjQC8D1EdPREREskGBXgYkM3oK9ERERCSDFOhlQIH66ImIiEgWKNDLgERGLxSJ0RqOZrk2IiIi\nsr9QoJcBBYH2eak1abKIiIhkigK9DEg03YL66YmIiEjmKNDLgNRAr65FU6yIiIhIZijQy4BCZfRE\nREQkCxToZUBiHj1QHz0RERHJHAV6GVDYoelWgZ6IiIhkhgK9DCgIto+6rWtWoCciIiKZoUAvA/we\nN3l+J9jb3tSW5dqIiIjI/kKBXoaUFfgB2FrfmuWaiIiIyP5CgV6GlOU7gV5VQyjLNREREZH9hQK9\nDCnLDwBQ1aCMnoiIiGSGAr0MGZJsug1hrc1ybURERGR/oEAvQxIZvbZIjHqtjiEiIiIZoEAvQxKD\nMUDNtyIiIpIZCvQyJJHRAw3IEBERkcxQoJchqRk9TbEiIiIimaBAL0MS06uAMnoiIiKSGQr0MiTP\n7yHH5wagql6BnoiIiKSfAr0MMcYks3pbNRhDREREMkCBXgYlBmRsU0ZPREREMkCBXgYlBmRoehUR\nERHJBAV6GZTI6Gl1DBEREckEBXoZlFgGrSUcpTGk1TFEREQkvRToZVDH1THUT09ERETSS4FeBqWu\njqFJk0VERCTdFOhl0JCUjN42ZfREREQkzRToZVBp6nq3mmJFRERE0qzPgZ4xJs8Ys8AYs8gYU2OM\nscaYub04vsgYc78xZpsxpskYs8QYM72bsscYY143xjQbY7YYY35hjMnra92zpSDgwe9xPnI13YqI\niEi69SejNxi4ATgQ+KA3BxpjXMALwKXAL4H/BsqAvxljxncqewjwVyAHuBZ4ALgSeLIfdc8KYwxD\nCpysngZjiIiISLp5+nHsZqDCWrvFGHM48FYvjr0AOAa40Fr7RwBjzBPAKmABTgCYcBuwA/iCtbY+\nXrYS+LUx5lRr7eJ+3EPGleX7+bymWZMmi4iISNr1OaNnrQ1Za7f08fALgK3AUynn2wY8AZxrjPED\nGGMKgFOARxJBXtzvgUbgoj5eP2uSq2Ooj56IiIikWX8yev1xKPCutTbWafu/cJplJwDLgKk4dXw7\ntZC1ts0Y8378PN0yxpQBpZ02j+tHvfstMcWKmm5FRAYYa52Hq5/jFK2FWBRiEedhDBg3GJfzcLmd\nbYmy0TBEWpwy3qBTJhqGcLPz2pfrHNP5/Dba6TnmPIwL3F5w+8Dl3fl+rIVIa3tZ447XyQWREIQa\nINwEgSIIFHasa6QVwi3Oe3++cx1roa0Jom3ONT3xGSaSdepUP2udMt4guDzt92Bjne7Hxj87A5h4\nXQ201kPzdufz8ec7dfQXgC+v471Gw9CwBZqrnf25pU6Z5Dlpr2dbo3MPxuXUzbidzyIaiv9cAk5d\no2Hn4fI42zzB/v++pFm2Ar0K4LUutm+OPw/FCfQqOm3vXPb43VznG8CNfalguiQyeo2hCI2hCHn+\nbP0IRPZjiS8QgEib86UWSfnjK9IKbc0QCztfDIFC5wu7td75QjDxL53El4+NOV8mjduc/Ym/YRNf\naqlfvLGI84UYaXWuGQk5X1jhZqcuxsS/dN0dn1NfY5zrtNY75/IGnS+npmpo2Ox8EecNgfwhzrXD\nLc4j8SUdi8SDmhhg2+vZ4T272N+bsl0d2+l9IjhwuePBUUoAYy24Pe1Bi9vrfMkmAoNk0JPIG6Qs\nL5m4TmqA0eF9tOP7VJ0//w5BWvy9jabUN+XZRnv2e2jc7Z9Rxx0d7wOc+08EQp337fY6rvbPDuP8\nvu90zW64/U5AEwk5vz877fc5gU9v65QOxuX8e018fqEGdl+vLj7r3pp4Fnzpf/t3jjTKVpQRBLpK\nabWm7E997q5ssIvtqe5l50Eb44Bne1DHtBhRnJN8/fn2Zg4aWpCtqojsPaJh2Loctq9uD1gSj2g4\nHkT5obUW6jbEg51WJwgC8MT/Gm+qgvrN0NaAE6SZnn/hSfpEWrr+Xz4hnLGatLNRiPYwYOvPNbre\nsfOmxO9yn64TczJT0T60JO3uuP7Ua0+zMQjV775cx4P6f133wE7YZKt2LYC/i+2BlP2pz92Vbeli\ne5K1tgqoSt1mUtO1WTC6JDf5et32JgV6Iqmaa+Dj52DFU1D9GfhynExP9WdOMLBHxbNJA4EnGL/X\nQDxDFenY3JXanBWLALY90+jytAe9wWLIH+pk+BqroHGrE8x6AvGsX6C9uSzRDJaamezyfaLZrDdl\ne3Nu4k2acK/lAAAgAElEQVSXIefeXJ54BtMTz3jhZFaj4ZTnaEp2rdO5oWOzXGqTafJh6JihS9kH\nOzeLdtVUamPxunraP8/U98n7cHeRSYylZOdobwK00XhzYZvze+8JOuXCzc4fOKkZxUTzb1eZx1g0\n5bOKpHx28d8db47z+2bcKU2r8We3z/m98gSgZYfzx1EktPPvEECo0fmjye1zfh89/ni2Oh78uVzt\nn3+HjDTtWfNE83GibOd7gZ0/N38+5Ax27iHUCK11ziNU77xP8OdDwVDIHRxv7q12Pkdraf/3b53r\n+fOcJnIbc+ofizj36vE5n2ck5HyGbp/zh2Us5ecyuMNkIQNOtgK9zbQ3y6ZKbNuUUo5dlN3UxfYB\nbWRJe0avcntzFmsiMsB8/Bz88T/6lnVIMC4n0CmocL7MPH7nP/NoyPmSyxkEBcMgWNT+peEJOv/B\ne/zxDJ9t/zJze50vjlC988XjL3TKJjKBieZAgJwSp7nUn98eTKRmDaNtzpeFy9P+BeIJOF8cvf0D\nNLXpWURkF7IV6L0PHG+McXUakHEk0IwzzQrAciACHI4zIhcAY4wPOCR1296iMOhlUK6PmqY21m1v\nynZ1RAaGxip4dl57kJc3BEYf7/xVHW6GwhEw4ggon+b85e0JtD/c3ngH6ZATtA3wZpQ9QkGeiPRQ\n2v9HNMZUAIXAamttoqfFH3GmWJkdf40xZjBwIfCctTYEYK2tM8a8AswxxtxirW2IH/8VII+9cNJk\ngFElOdQ0tVGpQE/2dbEYbPsYNn/gZMbCTU4ziMvjZMYmngGFw2HR953+dQCzfgmHXNpxlOHueHzO\nQ0REOuhXoGeMmQcU4YySBTjHGDM8/voea20dcDtwGTAGqIzv+yPwJvAbY8xBQDXOCFk3O4+S/QGw\nFPi7MeZ+YDjwbWCxtXZRf+qfLaNLcnnv81rWqelWBppoGLaucKYu8AadR85gJ8PWUgOrl8D6N52p\nCkonOgMg1r0B6//lBGaFIyC3xOl701oHm95z+sV0Z/F8OOhcWP4n5/2B58D0r2TmXkVE9gP9zeh9\nBxiV8n52/AHwCFDX1UHW2qgx5kzgZ8DVOKNn3wLmWmtXdir7rjFmJvAT4C6gAXgQuK6fdc+aUfF+\nepvrWmkNRwl4e5G5EAGnj1Yk1N6vrLUOatc7HafDLU6g1bwdmrY5+xKdttsanQEPrbXt03sk5umy\nMdiyzGkq7astH/aufKQVPnzcee0vgDN+2vdri4jITvoV6FlrR/egzFxgbhfbdwBXxB+7O8frwLG9\nruAAlTry9vOaZiYMyc9ibWRAi4ScQK2l1nmuWw+fvgyfLo5nyowT7HU1v1W6+PKc68UizntPEEbM\ncAYV1G1wAkl/nlOuZJzT127UMe2j5IzbGd23+QN46Xon6wcw80ZnhJyIiOwx+0Gv5YFnVOrI2+om\nBXr7o4YtToCz6T3Y9D7UrI4P6Q87ozOjEWdwwW4DOLvrMsblTJWQmN7BlwvBQc40HB6/84hFnSxe\nNAxDDoLhR0Dx6Pj0B01OVrBxq9M0O+ZEGDrduW7NGmf/kCl96x836hi44lX49CXnng+c1ftziIjI\nLinQy4KOc+mpn95eq60JatbGl8IJOtm3hs3Oo35TyuvNzqhScAKiUCM09nWZaJxpQ8Z+EYYe0r7C\nQs5gKBoB+fFpRbw5zlQiwUHpW56ndGL/z+FyOQMyREQkLRToZUFRjpeCgIf61ohG3g50bU3xiTOD\nTv+21a86AxI2vg3Vq/bMqgolB0DZQU5Tp9sTX6ooPilnoDD+KHLmfgsWw5DJ7ROWioiI7IICvSww\nxjB6cC4fbqhTRi8bomHY+K4TLA0a4wRV2z+Dqo+dx7ZPnKW26jdBqMvxRD3jy3cm7s2vgPzy+CLZ\nrU4GsHwqDD0UKqY5gZyIiEgaKNDLklElTqCnjN4eVL/JmeZj8HgoPbBjk2XLDqdP2cfPw/uPOn3O\nEhKL0veUNxdGHuU0nZYd1L5ovMvtBHUFQ53Azq++lyIikl0K9LJkdHxAxqbaFkKRKH6Ppljpk2gE\nNvwL3noAPnq2fSRocBAUjYyPWK1xnrvTIcgzTpZv8ERnIt+CCmeuuEgrYGHEkTDiKE3OKyIiewUF\nelkyKj4gI2Zhw44WxpXmZblGA1jDVqj93Amu3D7Ysc6Z723j21D5hrOodmctNc6jKyOOhEO/4oxA\n3bHW6Yc3eCKUTYLBE9T/TURE9hkK9LJkdMoUK+u2NynQS2hrgg1vOX3oNr3rPNdv3P1xLg9Mng2H\nfAl2VDoBYGtt+yCGwhFOpm7IFGduN5H9SEukhdrWWspzyzE9WCc3HAuzqXETURtlWN4w/G4/ANZa\ngB6do7cisQhRG01eKxwNs6V5C41tjQQ8AXI8OQwODsbdg6XxrLVYnLq6jKvD9tZoK16XF4+rZ19/\n0ViU+rZ6fG4fAXegy+tHYhFaI62EoiGMMbhw4XK5cBs3BoPb5caFy3mO1ydmY2xt2kpDuIEhOUMo\n8BV0+FyjsSihaAif25esa8zGqA3VErMxiv3FuF1uGtoaWFe/jnAszNjCsRT690yf38Rn1dDWQCgS\nImIjWGspChRR7C9O1jUai9ISaaEl0kLURsn15pLrze3wuXf3uW5s3EjMxhiaNxSf25f8LFN/D3oj\nHA3THGkm35e/2+vvKc3hZkLREMWB4oxcry8U6GXJqJQpViqr99MBGdY6fefq1sO2lfDxn53JgHs6\n+W/RSBh1HIw5AcadBPlD2vcd/u/pqbNkRXVLNatqVrGxaSOxWIyojRKzHZ+ttcn3FkvAHSDoCeJx\neYjaKG3RNra3bGdr81ZC0RBF/iIK/YUU+4sp9BfSGm3l/ar3+aTmEypyKzhl1CkcXn446xvWs2rH\nKqpbqmlsa6Ql0oLH5cHv9uNz+/C7/XhdXsKxMKFoiLZoG23RNsKxMBW5FYwrGkd5bnlyf32ontpQ\nLVuatrC6djVr69eS683lgKIDKAmUsLZuLZ/WfkrQE+Tg0oOZXDIZt8tNW7QNt3FTHCgmz5tHfVs9\n21u3E4qEyPHm4Hf7aWhroLqlmuZIM363H4Phk5pPWL59OZFYhEJ/IYeUHkKOJ4ftrdtpDDdSnlPO\n8PzhRG2UdfXr+Lz+czY2biRqowAYDIODg4nEIjS0NWCMYXj+cIbnDcfn9iW/6Le3bqemtQaDIceb\nQ9ATJMeTQ443Jxk0tEZaaYm00BptJWZjeIwHYwz1oXoawk5m3uvykuPNoT5UnwzWEvK8eUwrncbY\nwrHO/bdsp7qlmu2t26kL1RGzseTPPyHoCZLvzcdi2RHaQSTevcPv9uNz+YgRP8Zap04uD6U5pQwO\nDqa2tZbPGz4nHAsnz+d1eQm4A3jdXtqibbRGWonYSI9+jw2GPG8eOd4calprOpw315uLz+VL/g6l\nnjPfm0/QG6SmtSZZ/8S5Ep9bwqDAIFzGRUukhZiNUegvpNBXSCgaoi5UR0ukhVxvLvm+fIwxtEXb\nCEVDhKIhwtFw8uee+HfVFa/LS543L/mz7O4+83x55HpzcRsnwE0EwaFYiM/rPycUDSXLlwZLaYm0\nJO/H5/KR58vDYzxgnDIu48JgkkFm4rW1lvq2eurb6gHwuDyUBcvwuX1OIBYL4Xf5yfE6CZbmiBOc\nBdwB8n35+Ny+5L/bUDSU/LkMCgyiJFCCy7gIRUPEbIxcXy753nx2tO5gbf1aqpqruHjixcw/an6P\nfgeywST+QttfGGMmA8uXL1/O5MmTs1YPay1TbnyJprYoXzlqFLecNyVrdUm7SAjW/9PJ1G163xnV\n2rLD6TcXbev+uMIRzsjUYYc5c7bFok4QmFfmjFoNDty/oKR3qluqeb/qfVZsX8H2lu3sCO2gLlRH\nbaiWmtYa6voz+llEJI2OqjiKX5/667Sdf8WKFUyZMgVgirV2RW+PV0YvS4wxHFCWxwcb6li1tYs+\nZnu7SAg++rOzWP3a1yDcg9HF/gKYeCYceLbTjy6vLP31lKxqjbTy7b9/m9c2vJaR63ldXspyygi4\nA9S11VHbWtshc1LkL+KgkoNYWbOS7a3bOxwb9ATJ9+WT48khHAsn//pPZO+8Lm8yw+dz+zAYtjRt\n6TbbE3AHGFM4hrFFY2lqa+Kz2s/Y3rqd0QWjGV88nvq2ej6o+oAdoR29usc8r5NFSdRxeP5wDh9y\nOMPyhrFi+wqWVS/DWktJsISgJ8imxk1sbNyIx+VhRP4IRhWMYmT+SEYVjMLtcrOhYQObmzbjc/nI\n9+UTjoXZ0LCBTU2biMQieFwefG4fJYESBgUGYYyhJdJCc7iZ5kgzLeEWjDEEPAEC7gABTwC/24/b\nuJOZ2HxfPkX+IjwuDw3hBpramigOFDM0b6iTbY20Ut9Wz8fbP+a9qvfY3LSZ4kAxJYESSoIllARK\nKAoU4TEeXMaVzB5Za2kKNyUzkUX+IvJ9+URiEZojzYSj4fam1vgxoWiIquYqqluqKfAVMLpgNOW5\n5URiEVqiLbRGnMxkW6ytw/0EPcFk82PMxojGoljas8wxGyMUDdHY1khjuJFifzEj8kdQ4C9ga9NW\nNjdtTjZZJn6HfG4foUiI2lAtjeFGSgIllOWU4TKuZBZzSM4QxhSOwePysLp2Nevq1+EyLoKeIMYY\n6kJ11IXq8Lv9FPmLCHqCNEWczwRIZqQT13Qbp2naGEOuN5cCXwEBT8DJrAE1rTVUNVfRHGkmxxPP\n3MYzuG7jpjHcSENbAw1tDTSGG2kKN7VnTOPZU5dxMTJ/JOOKxuFxedjQsIEtTVvI8eZQ7C/u8HsQ\ntc7nmDiHxbY/p2Ru87x5lARLyPXkUt1aTVVzFdFYlBxvTjJT2hxpxlpLrjcXv9vvZBDbGpI/S6/b\nm/z8ozZKTUsN21u3Y7H43X5cuGgMOz+/PG8eowtHM7pgNAeVHNSrf6OZpkAviyaW5ycDPWttWvq9\npF004oxadXsh1ACf/8OZUPjDx7seDFEw3Jk7Lm+IM39cTomzokPhSCif4izJJfuNXy/7dYcgz23c\nlARKKAy0N6kW+YsYVTCK8cXjGV0wGp/bh8u4ks1Bqc/GmOQXVWvUaSZMBCMel4c8b95Ofbaawk3J\nYGp43nCMMURjUd6tepe1dWsZVTCKCcUT+tQHJxwNU1lfSW2oNvllmu/LpzhQTI4nZ7f/5q21bG/d\njsc4wVQ4FqY2VEtDWwMFvgJKgiUE3IFkE1qeN4+AJ9DresZsrEOTmOydvjDiC9muggxACvSyKLHG\n7Y7mMNsaQpQV9P4/6Kxp2g5v3AVvPeRk64w7Pk1Jp64AwUHOElcHnAyjT4C80qxUVwaeyrpKfrP8\nNwBMGjSJ/57x30wumZzsR9NfQU+QoGfXI6iNMeT5nL5EqdwuNzPKZzCjfEa/6uB1exlfPL7Pxxvj\n9I9L1VVn+zxfHnn0fUBXpjqui0jmKdDLoknlBcnXn2xpGPiBnrXOtCYf/AHe/Z2zJFhyX0qnXeOC\nUcfCYXPhwHOUpdsLWWv56+d/5ZXPX6Eit4KZI2dyUMlByYxPdUs1r214jR2tOzh++PFMKJ7Q7bl+\n/s7P+d2K3/H9I77PxZMuTp7/R//8EeFYGIPhxqNvZMrgfbifqohIlijQy6IJ5e1/ga/a2sAJEwZg\ntqtmDaz5mzOI4vM3oXplx/0jj4EDToJwKxgDw2fAyKMhUNDl6fY1bdE2vC5vr5u8rLV8sO0DSnNK\nGZY3rNfXbYm0sLFhY7L/z8iCkeR6c3d/YDfqQnX8a8u/iMac8z2+8nHerXo3uf+BZQ84TY7+Yrwu\nL2vq1iT7x/z83Z8zsXgil02+jLPHnt3hs1i6cSkPLn8QgB+/9WOmD5nO+OLxvLD2Bd7c/CYAF028\nSEGeiEiaKNDLotI8P4NyfdQ0tfHJlgE0ICMWg7V/hzf/Bz59qesyo46D4691pjUZgP16EqM099Sc\nUqmisSh/2/A3fr/i97xb9S6F/kImFk/k6KFHc9nky/C6vLs8/p+b/8nd797NsupluIyLk0eezJcm\nfYkifxFRGyUaixKxEXwuHxOKJ3SYt6st2sZjnzzGrz78VbIzNThNb+OLxjMsbxibmjaxpWkLxww9\nhluPuxWvy4u1lne2vsOW5i3JzvqJ6RyeX/M8f1j5B5q6GDAT9ARpibQAJDtYd2XljpVc//r1vLP1\nHa4/8np8bh+NbY3c+I8bk2UisQg/fOOH/H/T/j9ueOMGwJm+4KpDr+r5hy8iIr2i6VWy7Ev3v8k/\n1mxn2vBC/jzvuOxWZutH8MH/wvKnoX5Dx32+fKg42MneTb3QmcNugNrcuJlLXriE2lAts8fP5hsH\nf4PSnN1nS7e3bKfAX7DLQG1t3Vq+ueSbrK1b2+X+mSNn8tMTf5o8R+ogm5iNMf/1+Ty35rke38vE\n4ol874jvMaF4An9Z+xce/uhh1jes7/HxZ4w5g5uPuZlb3ryFP6/+c4+P87g8XDrpUq6cdiUtkRZe\n/fxVVteupiHcQHO4mbFFYzlpxEkMCgziL2v/wh8++UNylOq00mmcOeZM3qt6j5cqnT8UDhx0IB/X\nfLzTNe7+4t2cMPyEHtdLRGR/09/pVRToZdlNf17Bb5dWEvC6WLHgdNyuLGTHmmvgrwvgnd/RYTCF\nJ+isNHH4v0PZZHDtHR22F769kN+s+E3yfdAT5Nihx3JgyYEcN+y4DkPhV1Sv4NGPH+Wdre+wqWkT\nowtGc8eJdzBx0MSdzru8ejnfeOUbyRGa+d58zhp7Fq3RVt7a8hYbG50VPE4eeTKTBk3iz6v/THO4\nmZ+e8FOOqDiC3y7/LXe+c2eyTpdOupRtLdv4y9q/JCdB7Y7H5elQZnTBaC6fcjmFvkIiNpKcdmJH\naAdD84aytWkrn9V+BkBJoGSnqUI6O7j0YK6YegUj80cSsRHKgmUUBYp2eUyqquYqvrXkW3xY/eFO\n+44sP5JfnvxLLnr+omSA7HF5WHjiQr448os9voaIyP5IgV4vDbRA77F/fc51Ty0DYMl3vsCYwX3v\nZ9VjrfXw0bNQ9ZGzKkXl684Exgkjj4Eps2HK+ZAzqE+XiMai/HrZr1myfglXHXoVxw1rz1buaiqZ\nF9a8wOra1cydMpcCX/f9/CrrKvmw+kNOH316cu4qcPquzXxyJvVt9eR4cmiOdFx1xGVc3PWFuzhp\n5ElsbNzIuc+cm5ydPSHgDvDDo3/IOWPPwRhDJBbhxbUvcsubtySbMa+YegVfm/q15AjR+rZ6vv7y\n11lWvWynugbcAf7rkP/i7nfvJmIjDM8bzu/P+H0yy1jVXMV7Ve8ll0ryGA9ul5tl25bx0PKHOsw8\nPzR3KJdNvowLJ164y8xjbWstcxfNZXXd6uS2g0sPZv5R84nGosn5rZrCTYzIH8HBpQf3e2qNtmgb\nd7x9B8989kzycyrwFfDEOU8wLG8YH277kMsXXY7FcueJdyrIExHpAQV6vTTQAr131u3g/P9ZCsB9\ncw7j9Cnl6btY1cew9B5Y8TSEu1h2bdxJcPpPoLT7EZTdefrTp3lh7QscNuQwjht6HHe/dzf/3PxP\nwMl8PXXuU5TnlvP7Fb/nweUPcu64c/nm9G926H/2+CePc+s/bwVgetl0fnXKrwC44+07eGfrO8wa\nN4vzJ5zPU6ue4hfv/YJwLMzpo0/nZyf+rEM9bljq9P+648Q7KPIX8cTKJ1ixfUUy41aRW8Gz5z3L\nDW/cwKLKRQCcOPxEynLK+NOnfyJmYwCUBcs4vPxw3q96n01NmwBnyZ35R83nookX7fQZdA72Dig6\ngLV1azssI+RxeXjkjEeYPLhnv3tbmrZw/4f3E46FOXvs2cwon9HjqTC2Nm1l7qK5bGjcwBljzuCW\nY2/p0/qRvWWtpbqlmo2NGxmWN6xDs/mmxk0YDBV5FWmvh4jIvkCBXi8NtECvMRRhyo1OP6ZvzZzA\nN2f2fc6tboVb4bWfwRs/h9QmQk8QCodD8ShnKpRJZ/dpYEV1SzWn/vHUDus2dnbM0GM4bfRp3Li0\nvXP+KaNO4fbjb8fv9vP6xteZ99d5HYKiE4afQHVLNR9t/6i9ysaz00oDD532EDPKZ2Ct5aLnL+KT\nmk8oC5ax6IJFHbJeT6x8glvevAWAk0acxKvrXwWcfmw/PeGnAPxj0z/43mvf63I1gmJ/MTccfQMz\nR83s9j6bw8389fO/Mr54PJMGTeKlypf43mvfS97Xf8/4b75y0Fe6PX5Pa420sqFhA+OKxmkyXBGR\nvZCWQNvL5fk9DC8OsmFHy55fCi0ageV/hL//xJkmBZw57iadBdPnwrgvQkpGra+eWPlEl0HemWPO\nxBjDC2teYOmmpSzdtLTD/pfXvczq2tVU5FXw3tb3ksv/HFB0ACu2r+iwYkKeN4/GcGMyyBuRP4Lq\nlmpaIi38+F8/5vGzH2dZ9TI+qfkEoMumzfPHn88fV/2Rj2s+TgZ5PpePa6Zfkyxz9NCjefrcp3mp\n8iX+sekfvFP1DqXBUr584JeZNW7WblcdyPHmcM64c5LvTxt9mtMf7e2FHD/8eOYcOKcnH+keE/AE\nOKD4gIxeU0REBg4FegPAxCH5bNjRwidb6vfMCa11liBbchvUrmvfXnEwnPMLGHpIj07THG7m6iVX\n89mOz5hRPoPjhh3H8Pzh+Fw+ynPLKc0ppS3axuMrHwdgcslkbjvuNl5d/ypDc4dyxpgzaAw3OtN6\nNG0BnHUVF35hIQ8tf4h3tr7Dmro1rKlbk7zmbcfdxtFDj+byRZezcoczZ98lEy/huzO+yxsb3+DJ\nVU8yunA08w6Zx8MfPcwv3/8lq3as4nuvfY8Ptn0AOM2jF0y4YKf7cbvcXHfkdXz1xa8mt3118lcZ\nmje0Q7mSYAmXHngplx54aY8+p905eeTJnDzy5D1yLhERkd5QoDcATCzP56+fVFG5vZnWcJSAtx9Z\nth2V8Nw1sGZJ+7a8IXDct2DG18Ddsx+5tZYblt6Q7Ge3qHJRsj8bOIMavn7w16nIraCm1VnTds5B\ncxhbNJaxRWOT5fJ9+dx8zM18/ZWvA/DTE37KCcNP4MiKI/l/7/8/3tn6DrGY0yfu/Annc+roUwH4\n1Sm/4vcf/Z6pg6cmm0q/OPKLHTrwXzb5Mp7+7Gk2Nm5k8brFye3njz9/p2WjEg4tO5Szx57N82ue\npyRQwn9M+Y8efR4iIiJ7I/XRGwCefX8j3/zD+wA8f9VxTBnWx0l+VzwNz3yjfaBF3hCix3+bP+Xn\nsyPcQL4vnyG5Qzh+2PEdRqp2JXUqkBH5I5ILqXfmd/sJRUOUBkt56fyX8Lq7Hgm6ascqXLj2eDPi\nq5+/yjeXfBOAcYXjuPTAS5k9fjYeV/cBbSga4tnPnmVG+QzGFI7Zo/URERHZk9RHbx8weWj7NCIr\nNtX1PtCzFpb+Al6+oX3b9K/CKbfw4KdPcM9bt3coPnXwVO7+4t0dRkNaa3l769u8V/Uea+rW8OLa\nFwFnOo9Hz3yUfF8+K2tW0hB2Vke48+072di4MTk1ycUTL+42yAN2uRZqf5w08iQePuNhgB5PEeJ3\n+7scNSsiIrKvUaA3AIwZnEfQ66YlHGX5xnountGLg0MNsOg6eM8JdvDlw4W/gfGnsKFhA/d/eP9O\nhyyrXsaXXvgSNx1zExW5FWxq3MSvPvxVso9bgt/t564v3kVxoBigw5Qg08umc/WrV/Nh9YcEPUEu\nnHhhr+97TzmkrGd9DkVERPY3CvQGALfLcNDQAt5Zt4Plm+p6fuBnf4XnvulMegxQMAy+/CQMmYy1\nltv/dXsy4/bAqQ8wrmgc97x3D099+hRbm7fyn6/8Z5enLQ2WMrZoLF+b+rUOq0ikKgmW8MBpD/Ds\nZ88yadAkBgX6NrGyiIiIpI8CvQFicjzQ+3hzPdGY3f1SaH//GSxxJhd+oLCAj4oruO7MByktc7Ju\nS9YvSU5Pcu64czmy4kgAbjr6JsYVjuPOd+5MTgwMkOPJ4dIDL2XOgXMoCZb0qM5BT5BLJl3S21sV\nERGRDFGgN0BMGer0y2sNx1izrZHxQ/K7L/zaHckg7x/5Rdw9qABooW3Zr7jnpHtoCDdw+7+cfnkF\nvgKuPfza5KHGGL46+aucPOpkVteupjncjMVyVMVRySZaERER2Tco0BsgJg9rH5CxfFNd94HeG3fD\nq87qDtG8IdwxZgI0OHPl/X3D33l1/av8dd1fk/PWXXPYNV02qw7LG8awvGF7+C5ERERkIOnZopmS\nduPL8vG6nebaFRu7mTj5wyfbR9bmlvHnk65hVcO6DkXmvz6f59Y8B8Cxw47lgvE7TxwsIiIi+wcF\negOEz+NiYrmTxetyQMaGd+DZ/3JeB4po/vIT3PPZHwEoyynjezO+B0BjuBGAQn8hNx9zs9Y3FRER\n2Y8p0BtAJlc4/fRWbKqnw0TWdRvZ9sSXsNEQGDdc9Dvu2bCYbS3bAPjm9G9y6YGXMq10WvKQHx71\nQ8pyyjJafxERERlY+hzoGWP8xpifGGM2GWNajDH/NMac0oPj/maMsd08wj0su6i78+/NpsT76TW0\nRlhf0+JsjMV44KmLOanEzxXlZdSechMv0MQjHz8COOvLnj32bFzGxe3H3c5RFUcx75B5nDb6tGzd\nhoiIiAwQ/RmM8VvgAuDnwKfAXOAvxpgvWmtf38VxPwIe6LQtF7gPWLxzcTYA13XatqkP9R3wJqes\niLF8Ux0jS3LgnYd4IbINfD7+FQxwyea/sH3NdsAZUfuzE3+Gyzjx+siCkfz61F9npe4iIiIy8PQp\n0DPGHAFcAnzXWntHfNvvgeXAT4FjujvWWvtyF+ebE3/5aBeH1FlrH+lLPfc2B5YX4DIQs7B8Yx1n\njgjT9MqNrK5on/ZkY+NGAFzGxc9O/Bkj8kdkq7oiIiIywPW16fYCIAok19ey1rYCDwJHG2N6G31c\nCjQBz3a10xjjMcbk9bGue42gz824Uuc2P1xfC3++mo9MGBsfUHHssGOTZb81/VscM7TbeFpERESk\nzxkNLQ8AACAASURBVE23hwKrrLWd5wH5V/z5EGB9T05kjCkFTgEet9Y2dVFkAk4Q6DPGbAV+Ddxs\nrQ13UbbzucuA0k6bx/WkXtkyfWQxn1Y1csD6J8G1hOWF7fPp3XzMzWxr2UZ9qJ6jKo7KYi1FRERk\nb9DXQK8C2NzF9sS2ob0418XxenTVbLsaWAIsw+nHdwEwHyf4u7gH5/4GcGMv6pJ1R4wZxJvvvMV/\nm4cBWJZbBDhTqCQeIiIiIj3R10AvCIS62N6asr+nLgW2ATv13bPW/kenTQ8bY+4HvmaMucta++Zu\nzn0v8GSnbePopol4IDhiVCELvf9DjnE+3uUFgyC0g6mDp2a5ZiIiIrK36Wug1wL4u9geSNm/W8aY\nscDRwC+ttZEeXvtO4GvATGCXgZ61tgqo6nTNHl4mOz55ez6/G1bP1Tv8bPSfwubQhwBMGTwlyzUT\nERGRvU1fA73NQFcLpVbEn3s6/cml8eeumm27k+j7t/MCrnu5WHMNt216heqAn++WltG0YzLgBHrT\nBk/b9cEiIiIinfR11O37wARjTEGn7Uem7O+JS4HVPWiC/f/bu/P4uOp6/+Ovz2zZ1ybpXrqwtNCy\nFChScEHADa64IHoFFOTKVfCiP5erV73eRS+4XpWreMWdVQRFvIIgyE6hbC3Q0tI2dG/apEmzZzLb\n9/fHmaTTadIk00kmmbyfj8c8ZvI93+853zPnzMwn3+/5fk+q+cnnphGUmRBWPXkte/3eIWkJGD2V\n9wJgGMdOOTaXVRMREZEJKNNA7y7AD1zZl2BmBcDlwErn3PZk2nQzW2hmwfQVmNlJwCLgtoE2YGbl\nyXWmphneYAyABzKs+/gU6eLB+j8fkOQLeoOa51fMpzSU97PLiIiISJZl1HXrnFtpZncC1yWnMNkE\nfBSYC6QOoLgumT4P2JK2mouTz4N12y4Fbjez25PrLwLeC5wB3OicezGTuo9XiRd+w4Mh7/rBqkAJ\n+2L7Z5rR9XkiIiKSiYzvdQt8BO/2Z5cC1wNB4Hzn3ONDFTQzH96dNV50zr02SLatwBN4wd33gP/E\nG+zxieQjf8QivPzs/9AY8OLuq5ZeQylH9i/WiFsRERHJRMb3uk3eCeMLycdgeS7DuwduenoCmDXE\n+jcDF2Vavwnlpdt50LqBcgw4Z+7bWL+tgrsavgzOmFd6Yq5rKCIiIhPQ4bToSRbEomHan/pvHiwp\nBmBp3VJqimq4YNFyujd/iu4tV7N9T0mOaykiIiITkQK9HLr+xes5+bZlnFGRoCHZbfu2uW8HYMnM\nCoqZQ6J3Bivqm3NZTREREZmgFOjlSDwR5+ZXbyaB608r8hdy7hHnAhDw+zhtnjdV4NP1e3HODbge\nERERkcEo0MuRLe1bCMe9O8a9u6OTr9Wczu3n/5ba4tr+PKcvmALArrYwW5u7c1JPERERmbgyHowh\nh2ddy7r+15f0OBad/R0orDggz/IFNf2vV9Q3M7dG1+qJiIjI8KlFL0fW73gKgIBzHHniRw4K8gAW\nTiujqtiba3pF/d4xrZ+IiIhMfAr0cmT9Tu+ub0dGogRPvmzAPD6f9XffPl3frOv0REREZEQU6OWA\ni/ayLuzdqndhqAqq5w+a9/Rk921zV4QNezrHpH4iIiKSHxTo5UDD2jto93m3O1s468xD5l2ebNED\ndd+KiIjIyCjQy4F1r9ze/3rRovcdMu/8mhKmlhcA8NQmzacnIiIiw6dAb6y1N7C+5VUADDim7oRD\nZjczzkh2366o30s4Gh/tGoqIiEieUKA31tb+gfVBb1abOcVTKQkOPWXK2YumAtAdifPM62rVExER\nkeFRoDfWNv2NdQUhABbWnjisIm86uoag37um76F1e0ataiIiIpJfFOiNpVgv+7Y/zZ7kfW0XTlk4\nrGJlhUFOm+cNynh4XaOmWREREZFhUaA3RnZ07OA3T/8X36wo6k9bWD28QA/gnEV1gHc7tFcb2rNe\nPxEREck/CvTGgHOOKx64gu++fjf3le6/Jm8kgV7fdXoAD73amNX6iYiISH5SoDcG2iPt7OraBUBh\nIsERCR/XnHQNNUU1Q5Tcb3Z1MQunlQHwt/W6Tk9ERESGpkBvDDR272+B+/reFv486wI+fvzHR7ye\ns5Pdty/vaGNPezhr9RMREZH8pEBvDDR1N/W/ro3FYf5ZGa0ntfv2r6+qVU9EREQOTYHeGGjs2d+i\nV4cf5rwho/WcOKuSaeWFANz3ckNW6iYiIiL5S4HeGEht0auZcQoEiw6Re3A+n/HOJdMAWLm5mb2d\nvVmpn4iIiOQnBXpjoLF9OwBl8QRF8950WOs6b8l0ABIO7l+z+7DrJiIiIvlLgd4YaGrbDEBdPAZT\nlxzWupbOqervvr1X3bciIiJyCAr0xkBTl9fyVhuPQ93w584biLpvRUREZLgU6I2BPb2tANQlDCrm\nHPb61H0rIiIiw6FAb5QlXIK9cW/Ou9qCSvAd/lue2n37p9W7Dnt9IiIikp8U6I2ylnALcfNe15bO\nyMo6fT7j707wWvWe3dLCExubhighIiIik5ECvVHW1Lyh/3Vd5fysrffjb5pPScgPwDf+vI54wmVt\n3SIiIpIfFOiNsqbdq/tf19Uem7X11pUVctVZRwLw2p4O7nhue9bWLSIiIvlBgd4oa2xe3/+6btrS\nrK77ijPnMbPSm3z5vx98jY5wNKvrFxERkYlNgd4oa2rb2v+6pu7w5tBLVxj088V3etO17O2McPMz\nW4coISIiIpOJAr1R1ti1B4BqZwQDoayv/++On84xU8sAuG3lNl2rJyIiIv0U6I0m52iKeHPo1fqL\nR2UTZsYlb/Dm5tuxr4fHN2gEroiIiHgU6I2mzj00mtfCVltYPWqbec9JMylOjsC9Rd23IiIikpRx\noGdmBWb2LTPbZWY9ZrbSzM4dRrnLzMwN8pg2QP7lZvakmXWb2W4zu97MSjOt95hqXEeT3wvA6spm\njtpmygqDvOckb/0Pv9bIjn3do7YtERERmTgOp0Xv18BngVuBTwNx4D4zO3OY5b8GXJr2aE3NYGYn\nAn8DipPb+jlwJXDnYdR7zMQaX6XZ773FtZULRnVbl5x2BADOwe3PbhvVbYmIiMjEEMikkJktAz4E\nfME5991k2k3AGuDbwPJhrOYvzrnnh8hzLbAPeItzrj25nS3Az8zsbc65v2ZS/7HSvPc1nHm3xair\nnDeq2zp2RjlL51Ty4rZWblu5jY8un0tdWeGoblNERETGt0xb9C7Ea8G7sS/BORcGfgGcbmazh7MS\nMyszM/8gy8qBc4Fb+oK8pJuATuCiDOs+Zpq6d/e/ri2uG/XtffyN3p039nVH+ewdL5HQCFwREZFJ\nLdNA7yRgQ1oABvBs8vnEYazjEaAd6DazP5nZUWnLl+C1OB7Q6ueciwCrk3UY1xrDzf2v68Yg0HvH\n4mm8N3mt3pOb9vKTx+pHfZsiIiIyfmUa6E0HGgZI70ubcYiy3XjX910NvBevq/dsYEVaS+D0tHWm\nb+dQ2wDAzOrM7LjUBzC6F8ulaOpt639dW1w76tszM77+nsXMqykB4L8f3MCL2/aN+nZFRERkfMo0\n0CsCegdID6csH5Bz7nfOucudczc55/7onPtX4O3AFOAradvgENsZdBsprsK7bjD1cc8wymXFnlgX\n4L3J1aM4vUqq0oIAP/rwSYT8PuIJxzfvW49z6sIVERGZjDIN9HqAggHSC1OWD5tz7klgJXBO2jY4\nxHaGs40bgMVpjwtGUreMJRLU4917drq/hIAvo3EvGTluRgWXnzEXgGe3tLCivvnQBURERCQvZRro\nNbC/azVVX9quDNa5HUht9urrsh1sO0NuwznX6Jxbm/oAxubCtXAr60NBAI4tmjomm0x15ZvmUxT0\nxrn84KENatUTERGZhDIN9FYDRydHxqY6LWX5SM0HUu/ftQaIAaekZjKzEN5gj0y2MWbaWrewK+i1\n4i0smzPm259SWsBHlntz6z23ZZ9a9URERCahTAO9uwA/3uTFgHenDOByYKVzbnsybbqZLTSzYEq+\ng0YlmNm7gJOB+/vSnHNtwEPAJWZWlpL9UqCUcT5p8vrG/XHowsqjc1KHK9+4v1Xv+w+qVU9ERGSy\nyejCMefcSjO7E7jOzOqATcBHgbnAFSlZr0umzwO2JNNWmNkqvGlT2oClwMfwum6vTdvUV4AVwGNm\ndiMwC/gc8Ffn3P2MY+ua1/W/XlR3fE7q0Neq99PHXuf5rfv427pGzjl27LuRRUREJDcO5xZoHwF+\ngNfCdj0QBM53zj0+RLk7gKOALwP/A7wD+BlwqnNuT2pG59yLeAM0eoDv47Ug/gJvwuZxbV3HFgCm\nxOLUVqdPETh2PvGmBZQXevH8tX9ZRzSeyFldREREZGxlHOg558LOuS8456Y75wqdc8uccw+k5bnM\nOWfOuS0paV91zp3knKt0zoWcc0c4565KD/JS8j/pnDvDOVfknKtzzn3KOdeRab3HyvpubyzJwkgE\niqfkrB5VJSH+6a1eoPl6U5fugysiIjKJHE6LngyiJ9bDlqg3WfKiuEFgoBlixs5Hlh/BnOpiAH7w\n0Ebaw9Gc1kdERETGhgK9UbBh3wb6OkgX+opzWheAgoCfL71zIQAtXRGuu299jmskIiIiY0GB3ihY\n37w/kFoUGps7YgzlnYunsWyuV5fbn92mLlwREZFJQIHeKFjX4o24LUkkmFU8Pka5mhk//PsTqSkN\nAfC1e9bwwtaWHNdKRERERpMCvVGwvsVr0VvYG8FXetC0gTkzvaKIn1xyMkG/EY07LvvVc3z7/vXs\nbgsPXVhEREQmHAV6WRZNRNm4byMAiyIRKK7JcY0OdOrcav793ccB0BGOccOj9Zz5rYe5deXWHNdM\nREREsk2BXpa93vo6kUQEgIWRKJSMr0AP4OLTjuDGS09m6ZxKAGIJx7//aS1rdrbluGYiIiKSTQr0\nsmxayTS+ecJnuKy1nZPCvVAyfrpuU73tuGn84aozuOWK0wj4vK7c/3fHasLReK6rJiIiIlmiQC/L\nKgoqOK9qEZ/b18qcWCynkyUPx5lH1fRPqLyxsZPvPPBajmskIiIi2aJAbzR07d3/ehx23aa7+qwF\nnDDb68b9xZObeXxDU45rJCIiItmgQG80dKUESuO06zZVwO/j+xedQFHQD8D/u2M1e9o1EldERGSi\nU6A3Grqb978e5123febXlvKN9ywGoLkrwjW3ryIWTwxRSkRERMYzBXqjoa/rtqA85/e5HYn3nzyL\ni06ZBcDKzS1878ENOa6RiIiIHA4FeqOhr+t2Alyfl+4/3r2Yo6eWAvCTR+u55RnNryciIjJRKdAb\nDd3JFr1xNlnycBSF/Pz00lOoLtl/q7T71+zOca1EREQkEwr0RkNX8hq9CdiiBzCvpoRfXnYqRUE/\nCQfX/HYV333gNdp6ormumoiIiIyAAr3RMIG7bvucOLuSGy5Zit9nRGIJfvTIJt74rYe5beW2XFdN\nREREhkmBXrYlEvtH3U7ArttUZx1Tx23/cBonzKoAoD0c48t3v8J1960jkXA5rp2IiIgMRYFetoVb\nwSVvIzaBW/T6nDZ/Cn+8+gx+eunJ1JR6I4h/+vjrfPZ3q4nENP2KiIjIeKZAL9sOuCvG+J8seTjM\njLcfN427r1rOvJoSAP64ehf/de+rOa6ZiIiIHIoCvWybciR84XW4+lk46txc1yarZlcX8/tPLue4\nGeUA/Obprdz3SkOOayUiIiKDUaCXbT4flEyB2mOgqCrXtcm66pIQ/3vJyZQXBgD44l0vs7W5K8e1\nEhERkYEo0JMRm11dzPcuOhGAjt4YZ3/vMc745sNc+ouVvLB1X45rJyIiIn0U6ElGzj12Kh9/4zwA\nYgnHztYenti4lw/+9Gl+/sTrOKdRuSIiIrkWyHUFZOL68rsWsXROFS/taGNnaw/3r2kgGnd84951\nrNrWyg8+dCJBv/6XEBERyRUFepIxM+OdS6bzziXTAXhp+zyuuvVFdrb2cO8rDRQEfHzvohMwsxzX\nVEREZHJSc4tkzQmzK7n3mjP7J1j+w6qdfPP+9TmulYiIyOSlQE+yqrI4xC8vO7V/vr2fPvY6P3xo\no67ZExERyQEFepJ1U0oLuOljy6gt8+6k8f2HNvC5O1+iNxbPcc1EREQmFwV6MipmVxdz2z+cxqyq\nIgD+8OJOPnTjMzy1aa9a90RERMaIAj0ZNUdNLeOPV5/B0jmVAKza1srFP1/J+f/zJPes3kk0rnvl\nioiIjCYFejKqakoLuO3jb+BjZ8yjMOidbmt3tfPp367mzd9+hP99rJ4te3VnDRERkdFgk60bzcyO\nA9asWbOG4447LtfVmVT2dUW4+Zmt/GbFFpq7IgcsW1BbwmfOOZq/O2FGjmonIiIy/qxdu5bFixcD\nLHbOrR1pebXoyZipKglxzdlH8dSX3sp171vCgtqS/mX1TV1c89tV/P6FHTmsoYiISH7RhMky5gqD\nfv5+2Rw+dOpsNuzp5KF1e/jJo/V09sb4wl0vEQr41LInIiKSBRm36JlZgZl9y8x2mVmPma00s3OH\nUe5sM/ulmW0ws24ze93Mfm5m0wfI+6iZuQEe92dabxk/zIxjppVx9VlH8qvLT6U45Cfh4DN3rOYz\nv13Fmp1tua6iiIjIhHY4LXq/Bi4EfgBsBC4D7jOzs5xzTx6i3LeAauDOZLn5wKeA883sROfc7rT8\nO4B/SUvbdRj1lnHo1LnV/Pyjp3D5r56jN5bgj6t38cfVuzjrmFq+/p7FzKoqznUVRUREJpyMBmOY\n2TJgJfAF59x3k2mFwBqg0Tm3/BBl3wQ86ZxLpKU9BvyXc+6rKemPAjXOucUjruTg29dgjHFs/e52\nbniknntfaSCe8M7N4pCfT755AYVBP81dEY6dUc55S6bj9+keuiIikt8OdzBGpi16FwJx4Ma+BOdc\n2Mx+AVxrZrOdc9sHKuice3ygNDNrARYNVMbMAkChc64zw/rKBLFwWjnX//1JfOmdC/n+gxu484Ud\ndEfifO/BDQfku+GRTXzxHQt5yzG1mCngExERGUim1+idBGxwzrWnpT+bfD5xJCszs1KgFNg7wOKj\ngS6gw8x2m9nXzSw4zPXWmdlxqQ9gwUjqJrkxo7KI73zgBG654jRmVxcdtHz97g4u//VzfOjGZ1i1\nbV8OaigiIjL+ZdqiNx1oGCC9L22kQyY/A4SAO9LS64FHgFeAEryWxK/iBX8fHMZ6rwL+bYR1kXHk\nzKNqePTzZ7FzXw8VxUFCfh+/fGoz//toPR29MVZubuG9N6zgvSfN5JvvX0JBwJ/rKouIiIwbmQZ6\nRUDvAOnhlOXDkrw+79+A3znnHk5d5py7Ii37zWZ2I/BxM/u+c+6ZIVZ/A96gj1QLgHuGWz/JPb/P\nmDNl/2CMq886kg8vm8OPH9nETU9vJRJPcPeqnXT2xrjh4qUE/ZoeUkREBDLvuu0BCgZIL0xZPiQz\nWwjcjTeI4x+Gue3vJZ/PGSqjc67RObc29YHXSigTXFVJiK+efywPf/7NnHJEFQAPvrqHz9/5Ehv3\ndPDKjjY27OmgrSfKZLv7i4iISJ9MW/QagJkDpPfNhTfk9CdmNhv4K9AGvMs51zHMbfcN8qgeZn7J\nY7Oqivnl5ady8c9W8srONu5ZvYt7Vh94+pWE/Jw8t5pzFtXxtmOnMa2icJC1iYiI5JdMW/RWA0eb\nWXla+mkpywdlZlPwgrwC4O3OuYGu9xvM/ORz0wjKSB4rLwxy08eWcczUsgGXd0XiPL6hia/ds5Y3\nfvth7nx+wAHhIiIieSfTFr27gM8DVwJ98+gVAJcDK/umVkne7aICqHfORZNpJcB9eC2CZznnNg60\ngWQQ2euc601JM7zBGAAPZFh3yUNVJSHu+dQZPPpaE9F4gsKgn55onN1tPdQ3dvHohkb2tPcSjTu+\ncNfL7Gzt4dNnH6WpWUREJK9lFOg551aa2Z3AdWZWB2wCPgrMBVIHUFyXTJ8HbEmm3QosA34JLDKz\n1LnzOp1zf0y+Xgrcbma3J9dfBLwXOAO40Tn3YiZ1l/xVGPTzjsXTBlzmnOOJjXu55reraO2O8oOH\nNnLT01spCvqpKQ3xriXTee9JM6krV7euiIjkj8O5BdpHgK8DlwJVwMvA+QNNiJymb469jyUfqbYC\nf0x5/QRecDcNSADrgE+QMlGzyHCYGW86upbff3I5l/3qWba39NDSFQFgZ2sPL+1o41v3r+fUudWc\neWQNZxxVw/EzKwhoBK+IiExgGd0CbSLTLdCkubOXW57Zxp6OMOFonJe2t1Lf1HVQvrKCAG9YMIUT\nZ1cyp7qY+bUlHDu9XN29IiIyZnJ1CzSRCWtKaQGfPueo/r+dc6ze3so9q3fxxMam/qCvozfGg6/u\n4cFX9/TnXb5gCt96//HMri4+aL0iIiLjjQI9mfTMjJPmVHHSHG8+voa2Hp7a1MxTm/ayon4ve9r3\nzw2+or6Zt//gcf7lXYu4eNkcfD617omIyPilQE8kzfSKIi48eRYXnjwLgM7eGNuau7n5ma3c/uw2\nuiNx/vWPa7jv5Qa+feHxlBcFWbuzjVDAx9I5VQr+RERk3NA1eiIj8MTGJr70+1fY2erd/CXoN6Lx\n/Z+hI6YU8+FlczjzqBrm15RSFNK9d0VEJHOHe42eAj2REersjXHdfeu4deW2IfPOrynhvOOnc8GJ\nM6kpDbG3s5eQ33/AvXtFREQGo0BvhBToSbasqN/LvS83UFNawPGzKtjW0s2tK7exqbFzyLJvXVjH\nV85bxILa0jGoqYiITFQadSuSI8sX1LB8Qc0BaZctn8v63R1sbOxkU2Mnj73WyEs72g4q+/D6Rh7f\n0MQHT53Nx86cp4BPRERGhVr0REZZfVMnD69rxAxqywp4ur6ZO57fTupHb9m8aoqSt22bWVnE24+b\nxluOqaUwqGv8REQmM7XoiYxzC2pLD2ixu+DEmVx6+hF894HXeOS1JgCe3dxyQJm7V+0k6DcKAn7i\nCceMykLet3QW7186i2kVuk2biIgMj1r0RHKovqmT36zYwnNb9hHyG6GAjzU72+mJxgfM7zO4+LQj\n+Mp5i9TaJyIyCahFT2QCW1Bbyn9esPiAtJ5InMc2NPH8lhYc4Jw38GP97g4SDm5+ZivPbm7h2xce\nz8yqIkIBH2UFAd2aTUREDqJAT2ScKQr5ecfiabxj8bT+NOccL+9o4+t/fpXnt+7jtT0dXPDjp/qX\nlxUEmF9bwlFTy1g6p4pT5lYxv6aEgN+Xi10QEZFxQoGeyARgZpwwu5LfXvkGfvi3jfzokU0HDObo\n6I3x0o42XtrRxl0v7AC8bt7asgKqikPEE45oPMGU0gIWTS/j2OkVLJpexjHTyigO6WtARCRf6Rte\nZAIJ+H187m3HcN7x03lxayuxRIKeSJxtLd3UN3Xy6q522sMxABIO9rT3HnCv3i3N3bywdV//32ZQ\nXRwiFPBRHPLz1oV1fOT0ucyuPnBC545wFICywmDW92lPe5ieSJy5NSVZX7eIyGSnQE9kAlo4rZyF\n08oPSk8kHBsbO1m1bR879vXQ0BamrSdKKGAEfD527Otm/e4OuiPeYA/noLkr0l++vmkzP39yM6fN\nq+aoujJqSgt45vVmnt3SQsI5Llw6i8++7WgqioKs3tZKbzzBGQtqCAUy6yLe1NjJe3/8FD3ROH/6\n1JkcO+PgfRIRkcwp0BPJIz6fccw0r0t2MImEY2tLN+sa2lnX0E5LV4RoPMHmvV08t2UfzsEzr7fw\nzOstB5W984Ud3PPSLhIJRyzh9R3PqS7mn99xDHOnlPDitn00tIU5emopx8+qZN6UEny+gQeJxBOO\nL/7+ZTp6vRbIv6xpUKAnIpJlCvREJhmfz5hXU8K8mhLetWT6AcvWNbRz68qtrNrWypa9XXRFvAmc\nzz12Kjv29fDQuj1EYokDymxr6eZTt60acFtzqov5xJsX8P6TZ1IQOHA6mJue3nJAN/KK+mY+l51d\nFBGRJAV6ItJv0fRyvvGeJYA30rejN3bA1C3Pbm7hrhe2U14Y5NR51exuC/PDv22kJaX7N9W2lm6+\nfPcrXP+3jSybV82RdaVMKQ0RjSX49v2vHZD3pe2tdPbGKC3Q15KISLboG1VEBmRmlKcNvlg2r5pl\n86oPSHvf0pn85ZXd+HzG0jmVzKwqYsPuTlZubuZXT21hZ2sPu9vD/OmlXQNu5+NvnMfPnthMLOF4\nbksLZx1TN2r7JCIy2SjQE5HDUlYY5KJTZx+QtmRWBUtmVfCR0+dy96od/PnlBjY1dtLQFj4g3z++\naT6feuuR/PKpLcQTjqfrmxXoiYhkkQI9ERk1oYCPD546hw+eOgeArt4YXb0xzLzbvVUUeS2GS2ZW\nsHp7Kyvq9+ayuiIieUfT5ovImCkpCFBXXkhtWUF/kAewfMEUANbuaqe1e+Dr/UREZOQU6IlIzi1f\nUAPQP7WLiIhkhwI9Ecm5k4+oIpS8L+/T6r4VEckaBXoiknNFIT8nzakE4A8v7uSR9Y05rpGISH5Q\noCci48LFbzgCgI7eGB/7zXNce986Hli7m+e2tNCVvHuGiIiMjEbdisi48O4TZuAz+Oe7XqY7EufG\nx1/vX1YS8vOek2byoVPnsHB6GUG//kcVERkOBXoiMm6cf/wMjplaxtW3vciGPZ396V2ROLeu3Mat\nK7fh9xkzK4uYXlFITWkBpQUBOnqjtHZHmVJawBuPrOH0BVOoLSugIODDzEgkHHHnFCCKyKSjQE9E\nxpWjppZx/6ffxK62Hlq7o2xr6ebO57fz6IYmnIN4wrGtpZttLd0Dlv+/lDtwmIHPjHjCATCzsohF\n08uZUVlIV2+cnmiMiqIQMyoKmV5ZxIzKQmZUFFFSECDoN/w+I+j3EfB5r/tuBSciMlEo0BORccfn\nM2ZVFTOrChbPrOBdS6azvaWbp19vZmtzF1uau2lq72VvZy8dvTHKCwOUFwV5vamLtp5o/3qc4yWm\nGgAAE2JJREFUg7hz/X/vbO1hZ2tPxvUK+IyCgI+68kKmlRdSXhTAMHw+MAwMygoCzKspYW5NCT4z\nemNxwtHEQc9+M+bWFLOgtpS6sgKKQn6KQwH8voGDSZfcDwWbIjISCvREZEKYXV3M7OriQ+aJJxxr\ndraxensrXZEY4UicuHOE/H7izlHf2MnaXW20dEUoKwxSGPSxrztKS9fwJmmOJRyxSJzNe7vYvLcr\nG7t1kFDAR1HQj88gFndEEwlicUcs4QgFfNSWFjClNETQ78NvRjSRoL0nSldvnKkVhRxdV0pdeQEt\nXVFaunoJ+H2UFwYpLwokn4MEfYbDC4QdLvmcTID+ZYVBH7VlBdSWFlJS4Kcw6Kco6D0XBHz970k8\n2TUejztiiYTXgmpQWRQilMwXiSXo6o1RWhjIuAvdOUdnb4zuSJzqktCA64nFEwAEUpZF4wl8ZoMG\n0SMViSVo7YlQXhikMOjPyjpFRosCPRHJG36fccLsSk6YXTmicj2ROA1tPTS0hWloC9MTjROLJ/oD\nrXjcEU04YvEEPdE4je297Grrobs3fkCglHCOfV0R9nVHh9zmYCKxBJFYYtBlh2qV3N0e5qXtrRlv\nezSUFQZwDjpTRk6XFQQoCPq8IDEZxMaTb6I/2U3u9xkBn+HrezZjX3eE7kgc8Lrlp5SEKAp5gVY8\n7mgPx/q3UxDwURTy0xOJ0xtLEPAZs6qKmFlVRE8kzr7uKD2ROH6fdzu+kgI/FUVBDKOhrYfdbWES\nDgqCPgoDfgqCPgoCPtp6ojR29PbFxBQEfFQVh6gs9oJo5xyRuOtfFvL76I7E6AjH6E0eV/MafzEz\nfAZBv7fuoN9HKPkc8BkBvxGJJejsjRGOJigK+SkrCFBWGKC0MEBxKNC/7p5InITzguGEc8nz0fvb\nOe/c9B5A8u+4cyQSrj9YTzhHcSjAjMpCppQU0NIVYVdbD4mEY1pFIXVlhURiCdrDUTrCMTrCUTp6\nY/jNDnif0p8DPh8Bv3cJRTgapyeaIByNE456x7Io6Kc45KcoFKA45Mfv8/a7N/lZiCSD99K+fS/w\nHsGAj/aeqPcIR2nridLZ663TZ977X1YYpLRgf6jjku+Bw+1/vxJey3/COUoLAlQUBSkpCGDeW0Vn\nOEZzV4SOcDR5/Lx/GPr+bThhdiVXnDkvWx+ZrFOgJyKTXlHIz/zaUubXlmZlffu6Imxr6cYMCoP+\ng374CgI+wtEEm/d2Ud/USVuPF3R0R+J0R70fbecg4LeUH30f4Wicpo5emrsixBMJEgkvT1lhgMKg\nnx37eti4p4O2nijVJSGqikPEE67/RzAad0NXPss6wgdPjdPRG6Ojd5AC8eGt1znY2zl4S2xvMlDo\nE0s4tjR3s6V54Gs7B9MTjQODB+69sQS728Psbg+PaL3j2ertB6e9tKNt7CsyQURiCQV6IiKTSVVJ\niKqS0CHzFIX8HDujnGNnlGd1230tOL60bkrnHL2xBG09UWIJl2xR8q4t7GthIu3v7kicxg7vWsie\nSDzZGuNdYxiOxpPdoeD37R+wEvB7rW9e66bXfezzGVXFIUoKAnSGY+zrjhCNJ5JlfP3rAK+lKRb3\nWlf6uoHjyVaniqIgU8sLKQn5aeqM0NQRpjfa10pm/d3TZl7deyJxikN+SgoCdEfibG3uYldbmJKQ\nn+qSEMUhP7GEIxp3dCaD4Xiy9Wp6RRFBv3kBYzRBOBanN5qgpCDAzMpCppQW0Nkbo7Xba8Ft7fZa\nlfqCcoBILE4klqA45LVAFQa99P3d5pBIOCLxBNG413rV9xxLeO9DX2tjYdBPdyROZ7LVsrM3Rldv\njOKQn/KiYLK73/oHIPnMe08O+hv68/W3nprXcuo3oz0cpaEtzN7OXmpKC5hWXojfZ+xuD9PU0Zts\nJfOuiS0rDFJWEMDhDroONfU9iyUc0VgCv9/6u/69h/d+9P+TE4nTE4klL7fwEQp4lwj0df939sbo\nDMeSwfd+Ib+P8qIgFUXe+4wZznmthx1hrwxprah9z957s79bv7M3Rns42t9iC17rYFVxiPKiYH8r\nXt9i5xy1ZQWH9ZkdbRkHemZWAPwncClQBbwMfNU59+AwylYC3wbeCxQDzwKfc869OEDe5cm8S4F2\n4HfAl51znel5RUQmu74f94HS+35gh2sKDHldpMhYi8UTdPXG6Y3FKS/K/nWSiYQjHIv3B+NFQX/W\nru/MhcNp0fs1cCHwA2AjcBlwn5md5Zx7crBCZuYD7gVOAL4D7AWuAh41s5OdcxtT8p4I/A1YB3wW\nmAV8HjgKeOdh1F1EREQmoIDfR0WxDwiOyvp9PqM4lD8dnhntiZktAz4EfME5991k2k3AGrzWt+WH\nKH5hcvkHnHN3Jcv+DtgA/Afw4ZS81wL7gLc459qTebcAPzOztznn/ppJ/UVEREQmg0ynib8Q75LZ\nG/sSnHNh4BfA6WY2e4iye4A/pJRtwuuSvSDZJYyZlQPnArf0BXlJNwGdwEUZ1l1ERERkUsg00DsJ\n2JAWgIF3rR3AiUOUfdE5lz5/wLN41+sdnfx7CV6L4/OpmZxzEWB1cj0iIiIiMohMO6GnAw0DpPel\nzRii7ONDlH0lmS81PT3vG4eqpJnVAbVpyQuGKiciIiKSDzIN9IqAgWZBCqcsP9yyfc+D5T3UNvpc\nBfzbMPKJiIiI5J1MA70eYKCJYwpTlh9u2b7nwfIO54aVNwB3pqUtAO4ZRlkRERGRCS3TQK8BmDlA\nel93664hyk4fID29bENaenreQ20DAOdcI9CYmqYbgouIiMhkkelgjNXA0cmRsalOS1l+qLJLk/Pp\npZftxptmBbypWmLAKamZzCyEN9jjUNsQERERmfQyDfTuAvzAlX0JyWlRLgdWOue2J9Omm9lCMwum\nlZ0KvC+lbA3wAeD/nHO9AM65NuAh4BIzK0spfylQysFdsiIiIiKSIqOuW+fcSjO7E7guObJ1E/BR\nYC5wRUrW65Lp84AtybS7gGeAX5nZsey/M4afgwdOfAVYATxmZjfi3Rnjc8BfnXP3Z1J3ERERkcki\n0xY9gI/g3f7sUuB6vHuRnO+cG2jqlH7OuTjwLuAO4Br23wbtrc6519Lyvgicgzfw4vt4LYi/wJt0\nWUREREQOwZxzua7DmDKz44A1a9as4bjjjst1dUREREQGtXbtWhYvXgyw2Dm3dqTl8+euvcMXAti0\naVOu6yEiIiJySCnxSiiT8pOxRe/daB49ERERmVgucM79aaSFJmOgVwG8GdgOREZpM32TMl8A1I/S\nNsYz7f/k3f/JvO+g/df+T979n8z7DqO7/yFgNvBYckaSEZl0XbfJN2nEEfFIpEzKXJ9Jf/pEp/2f\nvPs/mfcdtP/a/8m7/5N532FM9n9VpgUPZ9StiIiIiIxjCvRERERE8pQCPREREZE8pUBvdDQB/5F8\nnoy0/5N3/yfzvoP2X/s/efd/Mu87jOP9n3SjbkVEREQmC7XoiYiIiOQpBXoiIiIieUqBnoiIiEie\nUqAnIiIikqcU6ImIiIjkKQV6IiIiInlKgV4WmVmBmX3LzHaZWY+ZrTSzc3Ndr2wzs1PN7EdmttbM\nusxsm5n9zsyOTsv3azNzAzzW56ruh8vM3jLIPjkze0Na3kVmdr+ZdZpZi5ndbGa1uap7NhzimPY9\nZg6Rb8IcezMrNbP/SB7DlmT9Lxsk77CPtZldYWbrzCxsZhvN7J9GdUcyNJz9NzOfmV1mZn8ys+3J\n74M1ZvZVMyscYJ2DnTdfGrMdG4bhHvuRnuf5dOyT+Q71XfDgMPOOt2M/rN+3ZN4J8bkPjNWGJolf\nAxcCPwA2ApcB95nZWc65J3NYr2z7InAGcCfwMjAN+BTwopm9wTm3JiVvL/APaeXbxqSWo+t64Lm0\ntE19L8xsFvA43r5+GSgFPg8sMbNlzrnIWFU0y34KPJSWZsD/AluccztT0if6sa8BvgZsA14C3jJQ\nppEcazP7R7z36vfAfwNvBK43s2Ln3LdGb1cyMpz9LwZ+BTyDt1+NwOl4E8eebWZvdQdP1vogcFNa\nWsY3bB8lwzr2ScM6z/Pw2ANcOkDaKcCngb8OsGwiHPth/b5NqM+9c06PLDyAZYADPp+SVoj3478i\n1/XL8r4uB0JpaUcBYeCWlLRfA525rm+W9/0tyeN84RD5bgC6gTkpaecky16Z6/3I8ntyZnK/vpxP\nxx4oAKYlX5+S3MfLMj3WQBGwF/hzWvlbgE6gKtf7PNL9B0LA8gHKfi2Z/5y0dAf8KNf7lsVjP6zz\nPB+P/SHK/hxIALMm6LEf7u/bhPncq+s2ey4E4sCNfQnOuTDwC+B0M5udq4plm3NuhUtrkXLObQTW\nAovS85uZ38zKx6p+Y8XMysxssFbx9+N9sLf1JTjnHgI2ABeNRf3G0IfxvtxuS18wkY+9c67XObd7\nGFmHe6zPAqbg/UCk+jFQApx3eDXOruHsv3Mu4pxbMcCiu5PPB30fAJhZ0UBdu+PFCI49MKzzPO+O\n/UDMrADv8/CYc27HIHnG+7Ef7u/bhPncK9DLnpOADc659rT0Z5PPJ45xfcaUmRkwFe8/l1TFQDvQ\nlryG4cdmVjrmFcy+X+HtV9jMHjGzU/oWmHedWh3w/ADlnsU7V/KCmQXxvtRWOOe2pC3O12Pfb4TH\nuu91et4X8FpA8ua8wOvugoO/D8C7pKUL6DGzV83sw2NWq9ExnPN8shz7dwGVwK2DLL+MCXjs03/f\nJtrnXtfoZc90oGGA9L60GWNYl1y4GJiJ12XTpwH4NvAi3j8V7wCuAk4ws7c452JjXsvDF8G7zuI+\nvA/9sXjXZTxhZsudc6vwzgUY/HyoNrMC51zvWFR4lL0d77/V9C/2fDz2AxnJsZ4OxJ1zjamZnHMR\nM2smv74j/hkv+PlLWvoK4HfAZrz9vRq41cwqnHM/GdsqZsVwz/PJcuwvxrtm8a4Blk3kY5/++zah\nPvcK9LKnCO8ETxdOWZ6XzGwhXjP008Bv+tKdc/+SlvW3ZrYB+C+8ru7fjlklsyTZTZXaVfUnM7sL\n76Ld6/C+6PuO9VDnQz4Eeh8Gonhf4P3y8dgPYiTHugjvH4WBhMmT7wgz+zLetUpXOedaU5c5585I\ny/tLvJaNa83s1865nrGr6eEbwXme98c+2XV9HnBf+nGHiXvsB/l9m1Cfe3XdZk8P3gWs6QpTlucd\nM5sG3Is38uhC51x8iCLfx2uuPme06zZWnHObgHuAs8zMz/5jndfnQ7J76gLgAedc8zCK5N2xZ2TH\nugdv8MJACsmPc+KDwDeAXwynlSZ5LdSP8Lr7Th7l6o2Vgc7zvD/2eNesFTJ4t+0BJsKxP8Tv24T6\n3CvQy54G9jfnpupL2zWGdRkTZlaB1zVTCbzDOTfkPib/a2sGqke5emNtO96HuYT9zfmDnQ8tedJt\n+x6865OG+8Wej8d+JMe6AfCbWV1qJjML4XV/T+jvCPPmDL0J74fxEyMouj35nBfnxSDneV4f+6SL\n8QKiP4+gzLg99kP8vk2oz70CvexZDRw9wMir01KW543kqKn/A44GznfOvTrMcmV4czQ1jWL1cmE+\nXjN8p/PmkmvCm5Yg3TLy51y4GG96gD8NJ3M+HvsRHuu+1+l5T8H7Lp6w54WZnYY30vZ54KIRXoM5\nP/mcF+fFIOd53h57ADObjje69Pcj/Cd2XB77oX7fJtrnXoFe9twF+IEr+xKSQ80vB1Y657YPVnCi\nSXZP3oE3MeoHnHNPD5CnMPmFl+5f8SbYvX90azk6Bpr13MxOAN4N/NU5l0gm/x44P3VaHTM7G++L\n486xqOtoSr4P5wB3O+e605bl5bE/hOEe64eBFuCTaeU/iTcf172jXM9RYWaL8Oq+Be9HccCuqEE+\nO2XAZ/AGNr0witXMuhGe53l57FN8CC+eGLB1fyId++H8viVNmM+9BmNkiXNupZndCVyXbKLdBHwU\nmAtckcu6jYLv4QU2/4c3uuiS1IXOuVvwpldYZWa3A323A3o73vD7+/GuaZuI7jCzHrwBGY14o26v\nxPvApt7K51rgA8AjZvZDvFnTvwC8gjc1y0T3Qbzvj4G+2PPm2JvZp/C6bvpGxv1dckZ8gP9xzrUx\nzGPtnOsxs38Ffpz8rngAb4b8S4CvOOdaxmKfRmKo/ce7Fu0BoAr4DnCeNxNFv/qUH8qrzew9eN8b\n2/C6uD4GzAEuTZ+7LNeGse9VDPM8z8djnzz3+1yM1wX56CCrm0jHfji/bzCRPvejPSPzZHrgXVj5\nHbw++TDefDpvz3W9RmE/H8WbIHfARzJPJXAz3q3gupLvxxrgX4BgrvfhMPb9GmAl3jU4Ubwvt5uB\nIwfIexzeh7oL2Ic3E/rUXO9Dlt6Hp4E9gH+AZXlz7PFaqQY71+dmcqyBj+MFBr14/xB+BrBc72sm\n+598DPpdAPw6ZV3n4t0WqwFvFOK+5Hv21lzvZ4b7PuLzPJ+OfUq+Y5Jp3zvEuibMsWcYv28peSfE\n596SFRARERGRPKNr9ERERETylAI9ERERkTylQE9EREQkTynQExEREclTCvRERERE8pQCPREREZE8\npUBPREREJE8p0BMRERHJUwr0RERERPKUAj0RERGRPKVAT0RERCRPKdATERERyVMK9ERERETylAI9\nERERkTz1/wHc9J21vTlAnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9db0608290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_epochs = 100\n",
    "Train_stu = True\n",
    "if Train_stu:\n",
    "    train(rs8, train_data, valid_data, num_epochs, lr, wd, ctx, lr_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs8.save_params('./model_compression/stu_rs8_90.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**中间层训练学生网络**\n",
    "\n",
    "计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算批量归一化\n",
    "def batch_norm(X, gamma, beta , moving_mean, moving_variance,is_training = True,\n",
    "               eps = 1e-5, moving_momentum = 0.9):\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    # 全连接: batch_size x feature\n",
    "    if len(X.shape) == 2:\n",
    "        # 每个输入维度在样本上的平均和方差\n",
    "        mean = X.mean(axis=0)\n",
    "        variance = ((X - mean)**2).mean(axis=0)\n",
    "    # 2D卷积: batch_size x channel x height x width\n",
    "    else:\n",
    "        # 对每个通道算均值和方差，需要保持4D形状使得可以正确的广播\n",
    "        mean = X.mean(axis=(0,2,3), keepdims=True)\n",
    "        variance = ((X - mean)**2).mean(axis=(0,2,3), keepdims=True)\n",
    "        # 变形使得可以正确的广播\n",
    "        moving_mean = moving_mean.reshape(mean.shape)\n",
    "        moving_variance = moving_variance.reshape(mean.shape)\n",
    "\n",
    "    # 均一化\n",
    "    if is_training:\n",
    "        X_hat = (X - mean) / nd.sqrt(variance + eps)\n",
    "        #!!! 更新全局的均值和方差\n",
    "        moving_mean[:] = moving_momentum * moving_mean + (\n",
    "            1.0 - moving_momentum) * mean\n",
    "        moving_variance[:] = moving_momentum * moving_variance + (\n",
    "            1.0 - moving_momentum) * variance\n",
    "    else:\n",
    "        #!!! 测试阶段使用全局的均值和方差\n",
    "        X_hat = (X - moving_mean) / nd.sqrt(moving_variance + eps)\n",
    "\n",
    "    # 拉升和偏移\n",
    "    return gamma.reshape(mean.shape) * X_hat + beta.reshape(mean.shape)\n",
    "\n",
    "\n",
    "\n",
    "def cal_fsp(resnet,i,x):\n",
    "    pre_net = resnet[:i]\n",
    "    net = resnet[i]\n",
    "    out = x\n",
    "    for l in pre_net:\n",
    "        out = l(out)\n",
    "    \n",
    "    first = out\n",
    "    for _,b in enumerate(net[0].net[:4]):\n",
    "        first = b(first)\n",
    "    for i,b in enumerate(net):\n",
    "        out = b(out)\n",
    "    #print(out.shape)\n",
    "    (num,channel,h,w) = out.shape\n",
    "\n",
    "#     weight_scale = 1\n",
    "#     gamma = nd.random.normal(shape=channel, scale=weight_scale, ctx=ctx)\n",
    "#     beta = nd.random.normal(shape=channel, scale=weight_scale, ctx=ctx)\n",
    "#     moving_mean = nd.zeros(channel, ctx=ctx)\n",
    "#     moving_variance = nd.zeros(channel, ctx=ctx)\n",
    "\n",
    "    result = out - first\n",
    "    result = nd.sum(result,axis=[2,3])\n",
    "    #result = batch_norm(result,gamma,beta,moving_mean,moving_variance)\n",
    "    result = nd.sigmoid(result)*10\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train2(net_stu, net_tea, train_data,loss_stu, ctx,num_epochs, lr, layer):\n",
    "    trainer = gluon.Trainer(\n",
    "        net_stu.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "    print(\"Start training on \", ctx)\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    losses_all = []\n",
    "    criterion = gluon.loss.L2Loss()\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "#         if epoch == 25 or epoch == 60:\n",
    "#             trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            bs = data.shape[0]\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output_stu = loss_stu(net_stu,layer,data)\n",
    "                output_tea = loss_stu(net_tea,layer,data)\n",
    "                loss = criterion(output_stu, output_tea)\n",
    "            loss.backward()\n",
    "            trainer.step(bs)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "        #writer.add_scalars('loss', {'train': train_loss / len(train_data)}, epoch)\n",
    "        #writer.add_scalars('acc', {'train': correct / total}, epoch)\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "\n",
    "        epoch_str = (\"Epoch %d. Loss: %f, \"% (epoch, train_loss / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs8 = Resnet8(10)\n",
    "ctx = try_gpu()\n",
    "rs8.initialize(ctx=ctx, init=mx.initializer.Xavier())\n",
    "rs8.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training 0\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 3.064338, Time 00:00:53, lr 0.1\n",
      "Epoch 1. Loss: 2.802706, Time 00:00:58, lr 0.1\n",
      "Epoch 2. Loss: 2.852211, Time 00:01:12, lr 0.1\n",
      "Epoch 3. Loss: 2.719456, Time 00:01:17, lr 0.1\n",
      "Epoch 4. Loss: 2.637546, Time 00:01:22, lr 0.1\n",
      "Epoch 5. Loss: 2.569699, Time 00:01:24, lr 0.1\n",
      "Epoch 6. Loss: 2.586847, Time 00:01:23, lr 0.1\n",
      "Epoch 7. Loss: 2.585457, Time 00:01:27, lr 0.1\n",
      "Epoch 8. Loss: 2.579832, Time 00:01:29, lr 0.1\n",
      "Epoch 9. Loss: 2.576618, Time 00:01:31, lr 0.1\n",
      "Epoch 10. Loss: 2.602589, Time 00:01:27, lr 0.1\n",
      "Epoch 11. Loss: 2.584162, Time 00:01:25, lr 0.1\n",
      "Epoch 12. Loss: 2.567233, Time 00:01:31, lr 0.1\n",
      "Epoch 13. Loss: 2.589212, Time 00:01:28, lr 0.1\n",
      "Epoch 14. Loss: 2.658751, Time 00:01:27, lr 0.1\n",
      "Epoch 15. Loss: 2.674524, Time 00:01:29, lr 0.1\n",
      "Epoch 16. Loss: 2.673992, Time 00:01:29, lr 0.1\n",
      "Epoch 17. Loss: 2.647172, Time 00:01:28, lr 0.1\n",
      "Epoch 18. Loss: 2.683388, Time 00:01:26, lr 0.1\n",
      "Epoch 19. Loss: 2.647404, Time 00:01:27, lr 0.1\n",
      "Epoch 20. Loss: 2.671154, Time 00:01:27, lr 0.1\n",
      "Epoch 21. Loss: 2.709134, Time 00:01:27, lr 0.1\n",
      "Epoch 22. Loss: 2.561242, Time 00:01:27, lr 0.1\n",
      "Epoch 23. Loss: 2.540297, Time 00:01:23, lr 0.1\n",
      "Epoch 24. Loss: 2.595998, Time 00:01:27, lr 0.1\n",
      "Epoch 25. Loss: 2.668686, Time 00:01:28, lr 0.1\n",
      "Epoch 26. Loss: 2.623942, Time 00:01:29, lr 0.1\n",
      "Epoch 27. Loss: 2.652530, Time 00:01:30, lr 0.1\n",
      "Epoch 28. Loss: 2.562812, Time 00:01:32, lr 0.1\n",
      "Epoch 29. Loss: 2.536671, Time 00:01:31, lr 0.1\n",
      "Epoch 30. Loss: 2.582086, Time 00:01:27, lr 0.1\n",
      "Epoch 31. Loss: 2.622574, Time 00:01:27, lr 0.1\n",
      "Epoch 32. Loss: 2.568072, Time 00:01:27, lr 0.1\n",
      "Epoch 33. Loss: 2.697339, Time 00:01:26, lr 0.1\n",
      "Epoch 34. Loss: 2.581441, Time 00:01:29, lr 0.1\n",
      "Epoch 35. Loss: 2.580253, Time 00:01:26, lr 0.1\n",
      "Epoch 36. Loss: 2.528124, Time 00:01:27, lr 0.1\n",
      "Epoch 37. Loss: 2.483786, Time 00:01:29, lr 0.1\n",
      "Epoch 38. Loss: 2.510531, Time 00:01:33, lr 0.1\n",
      "Epoch 39. Loss: 2.424874, Time 00:01:28, lr 0.1\n",
      "Epoch 40. Loss: 2.364717, Time 00:01:27, lr 0.1\n",
      "Epoch 41. Loss: 2.398852, Time 00:01:24, lr 0.1\n",
      "Epoch 42. Loss: 2.525302, Time 00:01:27, lr 0.1\n",
      "Epoch 43. Loss: 2.644167, Time 00:01:32, lr 0.1\n",
      "Epoch 44. Loss: 2.609508, Time 00:01:26, lr 0.1\n",
      "Epoch 45. Loss: 2.541004, Time 00:01:27, lr 0.1\n",
      "Epoch 46. Loss: 2.472385, Time 00:01:25, lr 0.1\n",
      "Epoch 47. Loss: 2.474600, Time 00:01:26, lr 0.1\n",
      "Epoch 48. Loss: 2.453257, Time 00:01:24, lr 0.1\n",
      "Epoch 49. Loss: 2.474352, Time 00:01:27, lr 0.1\n",
      "Epoch 50. Loss: 2.425452, Time 00:01:24, lr 0.1\n",
      "Epoch 51. Loss: 2.339598, Time 00:01:28, lr 0.1\n",
      "Epoch 52. Loss: 2.387206, Time 00:01:26, lr 0.1\n",
      "Epoch 53. Loss: 2.351122, Time 00:01:27, lr 0.1\n",
      "Epoch 54. Loss: 2.292925, Time 00:01:23, lr 0.1\n",
      "Epoch 55. Loss: 2.293041, Time 00:01:22, lr 0.1\n",
      "Epoch 56. Loss: 2.348323, Time 00:01:22, lr 0.1\n",
      "Epoch 57. Loss: 2.507229, Time 00:01:25, lr 0.1\n",
      "Epoch 58. Loss: 2.437098, Time 00:01:28, lr 0.1\n",
      "Epoch 59. Loss: 2.368216, Time 00:01:27, lr 0.1\n",
      "end training 0\n",
      "begin training 1\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 3.426637, Time 00:01:31, lr 0.1\n",
      "Epoch 1. Loss: 2.789060, Time 00:01:30, lr 0.1\n",
      "Epoch 2. Loss: 2.783408, Time 00:01:30, lr 0.1\n",
      "Epoch 3. Loss: 2.786640, Time 00:01:33, lr 0.1\n",
      "Epoch 4. Loss: 2.788091, Time 00:01:33, lr 0.1\n",
      "Epoch 5. Loss: 2.762513, Time 00:01:36, lr 0.1\n",
      "Epoch 6. Loss: 2.764473, Time 00:01:35, lr 0.1\n",
      "Epoch 7. Loss: 2.754806, Time 00:01:32, lr 0.1\n",
      "Epoch 8. Loss: 2.755839, Time 00:01:31, lr 0.1\n",
      "Epoch 9. Loss: 2.748328, Time 00:01:33, lr 0.1\n",
      "Epoch 10. Loss: 2.790172, Time 00:01:32, lr 0.1\n",
      "Epoch 11. Loss: 2.745532, Time 00:01:31, lr 0.1\n",
      "Epoch 12. Loss: 2.758672, Time 00:01:34, lr 0.1\n",
      "Epoch 13. Loss: 2.750681, Time 00:01:35, lr 0.1\n",
      "Epoch 14. Loss: 2.748094, Time 00:01:32, lr 0.1\n",
      "Epoch 15. Loss: 2.745285, Time 00:01:32, lr 0.1\n",
      "Epoch 16. Loss: 2.763424, Time 00:01:33, lr 0.1\n",
      "Epoch 17. Loss: 2.740374, Time 00:01:32, lr 0.1\n",
      "Epoch 18. Loss: 2.751778, Time 00:01:35, lr 0.1\n",
      "Epoch 19. Loss: 2.744822, Time 00:01:31, lr 0.1\n",
      "Epoch 20. Loss: 2.746895, Time 00:01:31, lr 0.1\n",
      "Epoch 21. Loss: 2.741368, Time 00:01:33, lr 0.1\n",
      "Epoch 22. Loss: 2.744734, Time 00:01:33, lr 0.1\n",
      "Epoch 23. Loss: 2.743088, Time 00:01:37, lr 0.1\n",
      "Epoch 24. Loss: 2.738440, Time 00:01:35, lr 0.1\n",
      "Epoch 25. Loss: 2.745375, Time 00:01:33, lr 0.1\n",
      "Epoch 26. Loss: 2.738617, Time 00:01:35, lr 0.1\n",
      "Epoch 27. Loss: 2.739139, Time 00:01:36, lr 0.1\n",
      "Epoch 28. Loss: 2.742781, Time 00:01:36, lr 0.1\n",
      "Epoch 29. Loss: 2.746684, Time 00:01:35, lr 0.1\n",
      "Epoch 30. Loss: 2.734614, Time 00:01:35, lr 0.1\n",
      "Epoch 31. Loss: 2.739361, Time 00:01:36, lr 0.1\n",
      "Epoch 32. Loss: 2.742247, Time 00:01:34, lr 0.1\n",
      "Epoch 33. Loss: 2.741826, Time 00:01:35, lr 0.1\n",
      "Epoch 34. Loss: 2.745126, Time 00:01:34, lr 0.1\n",
      "Epoch 35. Loss: 2.740807, Time 00:01:40, lr 0.1\n",
      "Epoch 36. Loss: 2.735153, Time 00:01:38, lr 0.1\n",
      "Epoch 37. Loss: 2.742458, Time 00:01:36, lr 0.1\n",
      "Epoch 38. Loss: 2.744003, Time 00:01:42, lr 0.1\n",
      "Epoch 39. Loss: 2.743431, Time 00:01:39, lr 0.1\n",
      "Epoch 40. Loss: 2.733306, Time 00:01:35, lr 0.1\n",
      "Epoch 41. Loss: 2.746608, Time 00:01:35, lr 0.1\n",
      "Epoch 42. Loss: 2.735600, Time 00:01:32, lr 0.1\n",
      "Epoch 43. Loss: 2.744424, Time 00:01:32, lr 0.1\n",
      "Epoch 44. Loss: 2.734182, Time 00:01:37, lr 0.1\n",
      "Epoch 45. Loss: 2.741048, Time 00:01:34, lr 0.1\n",
      "Epoch 46. Loss: 2.737906, Time 00:01:36, lr 0.1\n",
      "Epoch 47. Loss: 2.741106, Time 00:01:37, lr 0.1\n",
      "Epoch 48. Loss: 2.738357, Time 00:01:34, lr 0.1\n",
      "Epoch 49. Loss: 2.735624, Time 00:01:36, lr 0.1\n",
      "Epoch 50. Loss: 2.725443, Time 00:01:37, lr 0.1\n",
      "Epoch 51. Loss: 2.735654, Time 00:01:33, lr 0.1\n",
      "Epoch 52. Loss: 2.739074, Time 00:01:37, lr 0.1\n",
      "Epoch 53. Loss: 2.732222, Time 00:01:38, lr 0.1\n",
      "Epoch 54. Loss: 2.732684, Time 00:01:38, lr 0.1\n",
      "Epoch 55. Loss: 2.727973, Time 00:01:35, lr 0.1\n",
      "Epoch 56. Loss: 2.731501, Time 00:01:35, lr 0.1\n",
      "Epoch 57. Loss: 2.731817, Time 00:01:32, lr 0.1\n",
      "Epoch 58. Loss: 2.729529, Time 00:01:35, lr 0.1\n",
      "Epoch 59. Loss: 2.734927, Time 00:01:30, lr 0.1\n",
      "end training 1\n",
      "begin training 2\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 12.766268, Time 00:01:37, lr 0.1\n",
      "Epoch 1. Loss: 11.798747, Time 00:01:32, lr 0.1\n",
      "Epoch 2. Loss: 11.660363, Time 00:01:40, lr 0.1\n",
      "Epoch 3. Loss: 11.621614, Time 00:01:35, lr 0.1\n",
      "Epoch 4. Loss: 11.551923, Time 00:01:38, lr 0.1\n",
      "Epoch 5. Loss: 11.465042, Time 00:01:39, lr 0.1\n",
      "Epoch 6. Loss: 11.444440, Time 00:01:41, lr 0.1\n",
      "Epoch 7. Loss: 11.398871, Time 00:01:41, lr 0.1\n",
      "Epoch 8. Loss: 11.362526, Time 00:01:38, lr 0.1\n",
      "Epoch 9. Loss: 11.301403, Time 00:01:39, lr 0.1\n",
      "Epoch 10. Loss: 11.197924, Time 00:01:43, lr 0.1\n",
      "Epoch 11. Loss: 11.153635, Time 00:01:41, lr 0.1\n",
      "Epoch 12. Loss: 10.985296, Time 00:01:40, lr 0.1\n",
      "Epoch 13. Loss: 10.733871, Time 00:01:42, lr 0.1\n",
      "Epoch 14. Loss: 10.380967, Time 00:01:37, lr 0.1\n",
      "Epoch 15. Loss: 10.054154, Time 00:01:41, lr 0.1\n",
      "Epoch 16. Loss: 9.893647, Time 00:01:38, lr 0.1\n",
      "Epoch 17. Loss: 9.755339, Time 00:01:34, lr 0.1\n",
      "Epoch 18. Loss: 9.404348, Time 00:01:36, lr 0.1\n",
      "Epoch 19. Loss: 9.068243, Time 00:01:37, lr 0.1\n",
      "Epoch 20. Loss: 8.820161, Time 00:01:37, lr 0.1\n",
      "Epoch 21. Loss: 8.329202, Time 00:01:36, lr 0.1\n",
      "Epoch 22. Loss: 8.065646, Time 00:01:40, lr 0.1\n",
      "Epoch 23. Loss: 7.857595, Time 00:01:36, lr 0.1\n",
      "Epoch 24. Loss: 7.609111, Time 00:01:35, lr 0.1\n",
      "Epoch 25. Loss: 7.301949, Time 00:01:36, lr 0.1\n",
      "Epoch 26. Loss: 8.480410, Time 00:01:32, lr 0.1\n",
      "Epoch 27. Loss: 10.746516, Time 00:01:33, lr 0.1\n",
      "Epoch 28. Loss: 10.635604, Time 00:01:34, lr 0.1\n",
      "Epoch 29. Loss: 10.483158, Time 00:01:33, lr 0.1\n",
      "Epoch 30. Loss: 10.336206, Time 00:01:33, lr 0.1\n",
      "Epoch 31. Loss: 10.220262, Time 00:01:33, lr 0.1\n",
      "Epoch 32. Loss: 10.077446, Time 00:01:35, lr 0.1\n",
      "Epoch 33. Loss: 9.966511, Time 00:01:37, lr 0.1\n",
      "Epoch 34. Loss: 9.884588, Time 00:01:35, lr 0.1\n",
      "Epoch 35. Loss: 9.702410, Time 00:01:37, lr 0.1\n",
      "Epoch 36. Loss: 9.243764, Time 00:01:31, lr 0.1\n",
      "Epoch 37. Loss: 8.604094, Time 00:01:34, lr 0.1\n",
      "Epoch 38. Loss: 8.305530, Time 00:01:32, lr 0.1\n",
      "Epoch 39. Loss: 7.505462, Time 00:01:33, lr 0.1\n",
      "Epoch 40. Loss: 7.304424, Time 00:01:33, lr 0.1\n",
      "Epoch 41. Loss: 7.168912, Time 00:01:36, lr 0.1\n",
      "Epoch 42. Loss: 7.082404, Time 00:01:33, lr 0.1\n",
      "Epoch 43. Loss: 6.999778, Time 00:01:32, lr 0.1\n",
      "Epoch 44. Loss: 6.948565, Time 00:01:31, lr 0.1\n",
      "Epoch 45. Loss: 6.900549, Time 00:01:31, lr 0.1\n",
      "Epoch 46. Loss: 6.693840, Time 00:01:30, lr 0.1\n",
      "Epoch 47. Loss: 6.589332, Time 00:01:33, lr 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48. Loss: 6.503257, Time 00:01:33, lr 0.1\n",
      "Epoch 49. Loss: 6.475366, Time 00:01:34, lr 0.1\n",
      "Epoch 50. Loss: 6.395730, Time 00:01:32, lr 0.1\n",
      "Epoch 51. Loss: 6.336353, Time 00:01:34, lr 0.1\n",
      "Epoch 52. Loss: 6.293529, Time 00:01:32, lr 0.1\n",
      "Epoch 53. Loss: 6.250013, Time 00:01:34, lr 0.1\n",
      "Epoch 54. Loss: 6.178223, Time 00:01:32, lr 0.1\n",
      "Epoch 55. Loss: 6.633957, Time 00:01:30, lr 0.1\n",
      "Epoch 56. Loss: 7.166979, Time 00:01:34, lr 0.1\n",
      "Epoch 57. Loss: 6.320814, Time 00:01:30, lr 0.1\n",
      "Epoch 58. Loss: 6.237299, Time 00:01:31, lr 0.1\n",
      "Epoch 59. Loss: 6.083760, Time 00:01:35, lr 0.1\n",
      "end training 2\n",
      "begin training 0\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 3.002946, Time 00:01:32, lr 0.1\n",
      "Epoch 1. Loss: 2.676504, Time 00:01:30, lr 0.1\n",
      "Epoch 2. Loss: 2.643167, Time 00:01:28, lr 0.1\n",
      "Epoch 3. Loss: 2.707390, Time 00:01:30, lr 0.1\n",
      "Epoch 4. Loss: 2.719664, Time 00:01:27, lr 0.1\n",
      "Epoch 5. Loss: 2.726743, Time 00:03:07, lr 0.1\n",
      "Epoch 6. Loss: 2.749880, Time 00:01:30, lr 0.1\n",
      "Epoch 7. Loss: 2.711694, Time 00:01:27, lr 0.1\n",
      "Epoch 8. Loss: 2.731961, Time 00:01:23, lr 0.1\n",
      "Epoch 9. Loss: 2.708356, Time 00:01:25, lr 0.1\n",
      "Epoch 10. Loss: 2.708443, Time 00:01:25, lr 0.1\n",
      "Epoch 11. Loss: 2.710345, Time 00:01:27, lr 0.1\n",
      "Epoch 12. Loss: 2.705704, Time 00:01:26, lr 0.1\n",
      "Epoch 13. Loss: 2.697417, Time 00:01:25, lr 0.1\n",
      "Epoch 14. Loss: 2.755475, Time 00:01:26, lr 0.1\n",
      "Epoch 15. Loss: 2.672146, Time 00:01:24, lr 0.1\n",
      "Epoch 16. Loss: 2.705747, Time 00:01:23, lr 0.1\n",
      "Epoch 17. Loss: 2.709189, Time 00:01:25, lr 0.1\n",
      "Epoch 18. Loss: 2.707777, Time 00:01:25, lr 0.1\n",
      "Epoch 19. Loss: 2.693502, Time 00:01:24, lr 0.1\n",
      "Epoch 20. Loss: 2.705764, Time 00:01:26, lr 0.1\n",
      "Epoch 21. Loss: 2.709610, Time 00:01:21, lr 0.1\n",
      "Epoch 22. Loss: 2.694992, Time 00:01:22, lr 0.1\n",
      "Epoch 23. Loss: 2.691779, Time 00:01:23, lr 0.1\n",
      "Epoch 24. Loss: 2.699669, Time 00:01:25, lr 0.1\n",
      "Epoch 25. Loss: 2.782856, Time 00:01:24, lr 0.1\n",
      "Epoch 26. Loss: 2.749464, Time 00:01:22, lr 0.1\n",
      "Epoch 27. Loss: 2.731241, Time 00:01:21, lr 0.1\n",
      "Epoch 28. Loss: 2.737354, Time 00:01:23, lr 0.1\n",
      "Epoch 29. Loss: 2.666960, Time 00:01:20, lr 0.1\n",
      "Epoch 30. Loss: 2.641401, Time 00:01:22, lr 0.1\n",
      "Epoch 31. Loss: 2.613961, Time 00:01:21, lr 0.1\n",
      "Epoch 32. Loss: 2.646090, Time 00:01:23, lr 0.1\n",
      "Epoch 33. Loss: 2.637207, Time 00:01:22, lr 0.1\n",
      "Epoch 34. Loss: 2.623140, Time 00:01:19, lr 0.1\n",
      "Epoch 35. Loss: 2.624454, Time 00:01:20, lr 0.1\n",
      "Epoch 36. Loss: 2.641561, Time 00:01:22, lr 0.1\n",
      "Epoch 37. Loss: 2.683330, Time 00:01:23, lr 0.1\n",
      "Epoch 38. Loss: 2.680775, Time 00:01:20, lr 0.1\n",
      "Epoch 39. Loss: 2.668208, Time 00:01:20, lr 0.1\n",
      "end training 0\n",
      "begin training 1\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 8.561008, Time 00:01:22, lr 0.1\n",
      "Epoch 1. Loss: 4.561329, Time 00:01:23, lr 0.1\n",
      "Epoch 2. Loss: 4.117127, Time 00:01:24, lr 0.1\n",
      "Epoch 3. Loss: 3.521687, Time 00:01:23, lr 0.1\n",
      "Epoch 4. Loss: 3.433825, Time 00:01:24, lr 0.1\n",
      "Epoch 5. Loss: 3.312117, Time 00:01:29, lr 0.1\n",
      "Epoch 6. Loss: 3.320349, Time 00:01:30, lr 0.1\n",
      "Epoch 7. Loss: 3.316569, Time 00:01:28, lr 0.1\n",
      "Epoch 8. Loss: 3.307839, Time 00:01:26, lr 0.1\n",
      "Epoch 9. Loss: 3.313621, Time 00:01:25, lr 0.1\n",
      "Epoch 10. Loss: 3.310327, Time 00:01:26, lr 0.1\n",
      "Epoch 11. Loss: 3.316978, Time 00:01:27, lr 0.1\n",
      "Epoch 12. Loss: 3.308309, Time 00:01:26, lr 0.1\n",
      "Epoch 13. Loss: 3.309992, Time 00:01:27, lr 0.1\n",
      "Epoch 14. Loss: 3.309597, Time 00:01:26, lr 0.1\n",
      "Epoch 15. Loss: 3.307119, Time 00:01:26, lr 0.1\n",
      "Epoch 16. Loss: 3.310296, Time 00:01:25, lr 0.1\n",
      "Epoch 17. Loss: 3.339662, Time 00:01:24, lr 0.1\n",
      "Epoch 18. Loss: 3.388274, Time 00:01:25, lr 0.1\n",
      "Epoch 19. Loss: 3.314186, Time 00:01:27, lr 0.1\n",
      "Epoch 20. Loss: 3.262415, Time 00:01:25, lr 0.1\n",
      "Epoch 21. Loss: 3.154014, Time 00:01:24, lr 0.1\n",
      "Epoch 22. Loss: 3.155824, Time 00:01:25, lr 0.1\n",
      "Epoch 23. Loss: 3.152324, Time 00:01:25, lr 0.1\n",
      "Epoch 24. Loss: 3.151376, Time 00:01:26, lr 0.1\n",
      "Epoch 25. Loss: 3.144860, Time 00:01:28, lr 0.1\n",
      "Epoch 26. Loss: 3.062268, Time 00:01:26, lr 0.1\n",
      "Epoch 27. Loss: 3.010684, Time 00:01:26, lr 0.1\n",
      "Epoch 28. Loss: 3.011278, Time 00:01:26, lr 0.1\n",
      "Epoch 29. Loss: 3.013309, Time 00:01:29, lr 0.1\n",
      "Epoch 30. Loss: 3.011394, Time 00:01:25, lr 0.1\n",
      "Epoch 31. Loss: 3.006822, Time 00:01:27, lr 0.1\n",
      "Epoch 32. Loss: 3.006045, Time 00:01:27, lr 0.1\n",
      "Epoch 33. Loss: 3.002961, Time 00:01:29, lr 0.1\n",
      "Epoch 34. Loss: 3.011128, Time 00:01:30, lr 0.1\n",
      "Epoch 35. Loss: 3.010829, Time 00:01:28, lr 0.1\n",
      "Epoch 36. Loss: 3.008903, Time 00:01:29, lr 0.1\n",
      "Epoch 37. Loss: 3.004663, Time 00:01:28, lr 0.1\n",
      "Epoch 38. Loss: 3.009573, Time 00:01:32, lr 0.1\n",
      "Epoch 39. Loss: 3.009036, Time 00:01:30, lr 0.1\n",
      "end training 1\n",
      "begin training 2\n",
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Loss: 10.003742, Time 00:01:33, lr 0.1\n",
      "Epoch 1. Loss: 9.834709, Time 00:01:32, lr 0.1\n",
      "Epoch 2. Loss: 9.825463, Time 00:01:34, lr 0.1\n",
      "Epoch 3. Loss: 9.819389, Time 00:01:35, lr 0.1\n",
      "Epoch 4. Loss: 9.790288, Time 00:01:30, lr 0.1\n",
      "Epoch 5. Loss: 9.796076, Time 00:01:34, lr 0.1\n",
      "Epoch 6. Loss: 9.772579, Time 00:01:35, lr 0.1\n",
      "Epoch 7. Loss: 9.769017, Time 00:01:34, lr 0.1\n",
      "Epoch 8. Loss: 9.774196, Time 00:01:31, lr 0.1\n",
      "Epoch 9. Loss: 9.688782, Time 00:01:38, lr 0.1\n",
      "Epoch 10. Loss: 9.428691, Time 00:01:37, lr 0.1\n",
      "Epoch 11. Loss: 9.047117, Time 00:01:37, lr 0.1\n",
      "Epoch 12. Loss: 8.894157, Time 00:01:33, lr 0.1\n",
      "Epoch 13. Loss: 8.770985, Time 00:01:36, lr 0.1\n",
      "Epoch 14. Loss: 8.706381, Time 00:01:34, lr 0.1\n",
      "Epoch 15. Loss: 8.657873, Time 00:01:33, lr 0.1\n",
      "Epoch 16. Loss: 8.567415, Time 00:01:36, lr 0.1\n",
      "Epoch 17. Loss: 8.504480, Time 00:01:37, lr 0.1\n",
      "Epoch 18. Loss: 8.477686, Time 00:01:35, lr 0.1\n",
      "Epoch 19. Loss: 8.304983, Time 00:01:37, lr 0.1\n",
      "Epoch 20. Loss: 8.113722, Time 00:01:33, lr 0.1\n",
      "Epoch 21. Loss: 8.029323, Time 00:01:34, lr 0.1\n",
      "Epoch 22. Loss: 8.006779, Time 00:01:37, lr 0.1\n",
      "Epoch 23. Loss: 7.951484, Time 00:01:33, lr 0.1\n",
      "Epoch 24. Loss: 7.806515, Time 00:01:39, lr 0.1\n",
      "Epoch 25. Loss: 7.766541, Time 00:01:38, lr 0.1\n",
      "Epoch 26. Loss: 7.697176, Time 00:01:35, lr 0.1\n",
      "Epoch 27. Loss: 7.639506, Time 00:01:37, lr 0.1\n",
      "Epoch 28. Loss: 7.586171, Time 00:01:36, lr 0.1\n",
      "Epoch 29. Loss: 7.524340, Time 00:01:36, lr 0.1\n",
      "Epoch 30. Loss: 7.439251, Time 00:01:36, lr 0.1\n",
      "Epoch 31. Loss: 7.371274, Time 00:01:37, lr 0.1\n",
      "Epoch 32. Loss: 7.328858, Time 00:01:37, lr 0.1\n",
      "Epoch 33. Loss: 7.291006, Time 00:01:39, lr 0.1\n",
      "Epoch 34. Loss: 7.230586, Time 00:01:35, lr 0.1\n",
      "Epoch 35. Loss: 7.148517, Time 00:01:37, lr 0.1\n",
      "Epoch 36. Loss: 7.052094, Time 00:01:39, lr 0.1\n",
      "Epoch 37. Loss: 6.918533, Time 00:01:34, lr 0.1\n",
      "Epoch 38. Loss: 6.731936, Time 00:01:36, lr 0.1\n",
      "Epoch 39. Loss: 6.603326, Time 00:01:38, lr 0.1\n",
      "end training 2\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1,0.1,0.01]\n",
    "steps = [60,40,100]\n",
    "net_tea = model.net\n",
    "loss_stu = cal_fsp\n",
    "for j in range(2):\n",
    "    lr = lrs[j]\n",
    "    step = steps[j]\n",
    "    for i,net_stu in enumerate([rs8.net1,rs8.net2,rs8.net3]):\n",
    "    #for i,net_stu in enumerate([rs8.net1]):\n",
    "        print(\"begin training %d\"%(i))\n",
    "        train2(net_stu,net_tea,train_data, loss_stu, ctx, num_epochs=step,layer=i+1,lr=lr )\n",
    "        print(\"end training %d\"%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最后的训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softCE(pred1,pred2,label):\n",
    "    loss = gluon.loss.SoftmaxCELoss()\n",
    "    return loss(pred1,label)\n",
    "\n",
    "def kl_hard_loss(pred1,pred2,label=None):\n",
    "    loss1 = gluon.loss.KLDivLoss()\n",
    "    loss2 = gluon.loss.SoftmaxCELoss()\n",
    "    \n",
    "    T = 8\n",
    "    lamda = 0.7\n",
    "    if label is None:\n",
    "        return loss1(nd.log_softmax(pred1/T),nd.softmax(pred2/T))*T*T*2 \n",
    "    return loss1(nd.log_softmax(pred1/T),nd.softmax(pred2/T))*T*T*2*lamda + loss2(pred1,label)*(1-lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = kl_hard_loss\n",
    "def train3(train_data, valid_data, net_tea, net_stu, num_epochs, lr, wd, ctx, lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net_stu.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "    print(\"Start training on \", ctx)\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    losses_all = []\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        if epoch == 60 or epoch == 150:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            bs = data.shape[0]\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net_stu(data)\n",
    "                output_tea = net_tea(data)\n",
    "                loss = criterion(output, output_tea, label)\n",
    "            loss.backward()\n",
    "            trainer.step(bs)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            correct += get_acc(output, label)\n",
    "            total += bs\n",
    "        #writer.add_scalars('loss', {'train': train_loss / len(train_data)}, epoch)\n",
    "        #writer.add_scalars('acc', {'train': correct / total}, epoch)\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_correct = 0\n",
    "            valid_total = 0\n",
    "            valid_loss = 0\n",
    "            for data, label in valid_data:\n",
    "                bs = data.shape[0]\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                output = net_stu(data)\n",
    "                loss = softCE(output, None, label)\n",
    "                valid_loss += nd.mean(loss).asscalar()\n",
    "                valid_correct += get_acc(output, label)\n",
    "                valid_total += bs\n",
    "            valid_acc = valid_correct / valid_total\n",
    "            #writer.add_scalars('loss', {'valid': valid_loss / len(valid_data)}, epoch)\n",
    "            #writer.add_scalars('acc', {'valid': valid_acc}, epoch)\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train acc %f, Valid Loss: %f, Valid acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            correct / total, valid_loss / len(valid_data), valid_acc))\n",
    "            train_accs.append(correct / total)\n",
    "            test_accs.append(valid_acc)\n",
    "            losses_all.append(train_loss / len(train_data))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            correct / total))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "        show = True\n",
    "    if show==True:\n",
    "        plt.plot(losses_all)\n",
    "        plt.plot(train_accs)\n",
    "        plt.plot(test_accs)\n",
    "        plt.legend(['loss','train','test'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Train Loss: 0.406188, Train acc 0.960267, Valid Loss: 0.417997, Valid acc 0.905400, Time 00:01:01, lr 0.01\n",
      "Epoch 1. Train Loss: 0.404267, Train acc 0.959489, Valid Loss: 0.412011, Valid acc 0.904800, Time 00:01:05, lr 0.01\n",
      "Epoch 2. Train Loss: 0.406399, Train acc 0.960867, Valid Loss: 0.424587, Valid acc 0.902200, Time 00:01:06, lr 0.01\n",
      "Epoch 3. Train Loss: 0.402762, Train acc 0.961489, Valid Loss: 0.417390, Valid acc 0.907200, Time 00:01:18, lr 0.01\n",
      "Epoch 4. Train Loss: 0.403489, Train acc 0.960467, Valid Loss: 0.421503, Valid acc 0.904400, Time 00:01:23, lr 0.01\n",
      "Epoch 5. Train Loss: 0.402214, Train acc 0.961178, Valid Loss: 0.423728, Valid acc 0.905200, Time 00:01:26, lr 0.01\n",
      "Epoch 6. Train Loss: 0.401868, Train acc 0.961844, Valid Loss: 0.428485, Valid acc 0.906400, Time 00:01:29, lr 0.01\n",
      "Epoch 7. Train Loss: 0.403190, Train acc 0.961933, Valid Loss: 0.418662, Valid acc 0.908000, Time 00:01:30, lr 0.01\n",
      "Epoch 8. Train Loss: 0.399416, Train acc 0.961622, Valid Loss: 0.429410, Valid acc 0.902600, Time 00:01:32, lr 0.01\n",
      "Epoch 9. Train Loss: 0.397992, Train acc 0.962044, Valid Loss: 0.421712, Valid acc 0.905400, Time 00:01:32, lr 0.01\n",
      "Epoch 10. Train Loss: 0.396938, Train acc 0.962444, Valid Loss: 0.420685, Valid acc 0.904000, Time 00:01:31, lr 0.01\n",
      "Epoch 11. Train Loss: 0.400184, Train acc 0.961222, Valid Loss: 0.416177, Valid acc 0.904800, Time 00:01:34, lr 0.01\n",
      "Epoch 12. Train Loss: 0.397636, Train acc 0.961956, Valid Loss: 0.409006, Valid acc 0.907000, Time 00:01:36, lr 0.01\n",
      "Epoch 13. Train Loss: 0.394790, Train acc 0.963378, Valid Loss: 0.426591, Valid acc 0.903800, Time 00:01:37, lr 0.01\n",
      "Epoch 14. Train Loss: 0.396803, Train acc 0.961822, Valid Loss: 0.420353, Valid acc 0.905000, Time 00:01:36, lr 0.01\n",
      "Epoch 15. Train Loss: 0.398042, Train acc 0.962911, Valid Loss: 0.419168, Valid acc 0.907800, Time 00:01:35, lr 0.01\n",
      "Epoch 16. Train Loss: 0.396603, Train acc 0.961844, Valid Loss: 0.429961, Valid acc 0.905200, Time 00:01:34, lr 0.01\n",
      "Epoch 17. Train Loss: 0.393590, Train acc 0.962400, Valid Loss: 0.422579, Valid acc 0.903600, Time 00:01:35, lr 0.01\n",
      "Epoch 18. Train Loss: 0.391547, Train acc 0.963667, Valid Loss: 0.424825, Valid acc 0.907600, Time 00:01:35, lr 0.01\n",
      "Epoch 19. Train Loss: 0.393896, Train acc 0.963800, Valid Loss: 0.425386, Valid acc 0.906600, Time 00:01:35, lr 0.01\n",
      "Epoch 20. Train Loss: 0.390904, Train acc 0.963133, Valid Loss: 0.422839, Valid acc 0.901800, Time 00:01:37, lr 0.01\n",
      "Epoch 21. Train Loss: 0.393606, Train acc 0.964156, Valid Loss: 0.426927, Valid acc 0.903600, Time 00:01:38, lr 0.01\n",
      "Epoch 22. Train Loss: 0.390393, Train acc 0.963756, Valid Loss: 0.419544, Valid acc 0.904800, Time 00:01:36, lr 0.01\n",
      "Epoch 23. Train Loss: 0.389454, Train acc 0.965467, Valid Loss: 0.428739, Valid acc 0.905000, Time 00:01:40, lr 0.01\n",
      "Epoch 24. Train Loss: 0.389403, Train acc 0.964422, Valid Loss: 0.430330, Valid acc 0.901200, Time 00:01:41, lr 0.01\n",
      "Epoch 25. Train Loss: 0.389944, Train acc 0.963733, Valid Loss: 0.430034, Valid acc 0.903400, Time 00:01:37, lr 0.01\n",
      "Epoch 26. Train Loss: 0.390882, Train acc 0.963356, Valid Loss: 0.420385, Valid acc 0.905200, Time 00:01:39, lr 0.01\n",
      "Epoch 27. Train Loss: 0.388587, Train acc 0.964689, Valid Loss: 0.420417, Valid acc 0.906200, Time 00:01:40, lr 0.01\n",
      "Epoch 28. Train Loss: 0.389981, Train acc 0.963556, Valid Loss: 0.429650, Valid acc 0.903600, Time 00:01:37, lr 0.01\n",
      "Epoch 29. Train Loss: 0.386440, Train acc 0.965178, Valid Loss: 0.431247, Valid acc 0.904800, Time 00:01:38, lr 0.01\n",
      "Epoch 30. Train Loss: 0.386563, Train acc 0.965556, Valid Loss: 0.427221, Valid acc 0.907800, Time 00:01:42, lr 0.01\n",
      "Epoch 31. Train Loss: 0.384278, Train acc 0.965000, Valid Loss: 0.423120, Valid acc 0.905000, Time 00:01:42, lr 0.01\n",
      "Epoch 32. Train Loss: 0.383457, Train acc 0.965778, Valid Loss: 0.423819, Valid acc 0.901200, Time 00:01:39, lr 0.01\n",
      "Epoch 33. Train Loss: 0.385518, Train acc 0.966311, Valid Loss: 0.421143, Valid acc 0.905800, Time 00:01:39, lr 0.01\n",
      "Epoch 34. Train Loss: 0.384476, Train acc 0.964578, Valid Loss: 0.419883, Valid acc 0.904200, Time 00:01:37, lr 0.01\n",
      "Epoch 35. Train Loss: 0.385393, Train acc 0.964444, Valid Loss: 0.423842, Valid acc 0.902200, Time 00:01:36, lr 0.01\n",
      "Epoch 36. Train Loss: 0.381951, Train acc 0.967044, Valid Loss: 0.430866, Valid acc 0.900800, Time 00:01:37, lr 0.01\n",
      "Epoch 37. Train Loss: 0.382137, Train acc 0.965622, Valid Loss: 0.417757, Valid acc 0.905000, Time 00:01:39, lr 0.01\n",
      "Epoch 38. Train Loss: 0.382779, Train acc 0.966133, Valid Loss: 0.431589, Valid acc 0.902600, Time 00:01:41, lr 0.01\n",
      "Epoch 39. Train Loss: 0.381697, Train acc 0.965511, Valid Loss: 0.412943, Valid acc 0.904000, Time 00:01:36, lr 0.01\n",
      "Epoch 40. Train Loss: 0.379577, Train acc 0.966400, Valid Loss: 0.426252, Valid acc 0.903000, Time 00:01:38, lr 0.01\n",
      "Epoch 41. Train Loss: 0.380098, Train acc 0.966289, Valid Loss: 0.425773, Valid acc 0.903800, Time 00:01:39, lr 0.01\n",
      "Epoch 42. Train Loss: 0.383025, Train acc 0.965933, Valid Loss: 0.433169, Valid acc 0.902000, Time 00:01:41, lr 0.01\n",
      "Epoch 43. Train Loss: 0.375959, Train acc 0.967467, Valid Loss: 0.419258, Valid acc 0.902600, Time 00:01:38, lr 0.01\n",
      "Epoch 44. Train Loss: 0.379856, Train acc 0.966022, Valid Loss: 0.415449, Valid acc 0.904600, Time 00:01:39, lr 0.01\n",
      "Epoch 45. Train Loss: 0.377794, Train acc 0.966067, Valid Loss: 0.426801, Valid acc 0.903800, Time 00:01:36, lr 0.01\n",
      "Epoch 46. Train Loss: 0.379056, Train acc 0.966933, Valid Loss: 0.408275, Valid acc 0.905400, Time 00:01:38, lr 0.01\n",
      "Epoch 47. Train Loss: 0.374575, Train acc 0.967756, Valid Loss: 0.418871, Valid acc 0.903400, Time 00:01:39, lr 0.01\n",
      "Epoch 48. Train Loss: 0.380447, Train acc 0.966489, Valid Loss: 0.415665, Valid acc 0.904200, Time 00:01:37, lr 0.01\n",
      "Epoch 49. Train Loss: 0.374119, Train acc 0.967933, Valid Loss: 0.435816, Valid acc 0.903000, Time 00:01:36, lr 0.01\n",
      "Epoch 50. Train Loss: 0.376529, Train acc 0.967178, Valid Loss: 0.429930, Valid acc 0.905800, Time 00:01:40, lr 0.01\n",
      "Epoch 51. Train Loss: 0.376357, Train acc 0.968622, Valid Loss: 0.424823, Valid acc 0.905800, Time 00:01:39, lr 0.01\n",
      "Epoch 52. Train Loss: 0.374596, Train acc 0.968844, Valid Loss: 0.429956, Valid acc 0.901600, Time 00:01:37, lr 0.01\n",
      "Epoch 53. Train Loss: 0.371692, Train acc 0.969444, Valid Loss: 0.424679, Valid acc 0.906400, Time 00:01:35, lr 0.01\n",
      "Epoch 54. Train Loss: 0.373144, Train acc 0.967756, Valid Loss: 0.414801, Valid acc 0.906200, Time 00:01:41, lr 0.01\n",
      "Epoch 55. Train Loss: 0.374559, Train acc 0.967444, Valid Loss: 0.430392, Valid acc 0.903000, Time 00:01:37, lr 0.01\n",
      "Epoch 56. Train Loss: 0.373150, Train acc 0.968089, Valid Loss: 0.421279, Valid acc 0.905200, Time 00:01:38, lr 0.01\n",
      "Epoch 57. Train Loss: 0.375071, Train acc 0.967444, Valid Loss: 0.421682, Valid acc 0.904800, Time 00:01:38, lr 0.01\n",
      "Epoch 58. Train Loss: 0.371242, Train acc 0.968800, Valid Loss: 0.409862, Valid acc 0.907600, Time 00:01:41, lr 0.01\n",
      "Epoch 59. Train Loss: 0.372115, Train acc 0.967911, Valid Loss: 0.420552, Valid acc 0.902200, Time 00:01:40, lr 0.01\n",
      "Epoch 60. Train Loss: 0.362727, Train acc 0.970356, Valid Loss: 0.407027, Valid acc 0.906800, Time 00:01:40, lr 0.001\n",
      "Epoch 61. Train Loss: 0.358316, Train acc 0.971933, Valid Loss: 0.409794, Valid acc 0.908800, Time 00:01:46, lr 0.001\n",
      "Epoch 62. Train Loss: 0.357078, Train acc 0.972200, Valid Loss: 0.412010, Valid acc 0.907000, Time 00:01:45, lr 0.001\n",
      "Epoch 63. Train Loss: 0.356417, Train acc 0.971822, Valid Loss: 0.413263, Valid acc 0.907600, Time 00:01:41, lr 0.001\n",
      "Epoch 64. Train Loss: 0.354673, Train acc 0.972022, Valid Loss: 0.408399, Valid acc 0.908000, Time 00:01:38, lr 0.001\n",
      "Epoch 65. Train Loss: 0.356367, Train acc 0.971356, Valid Loss: 0.410076, Valid acc 0.908600, Time 00:01:39, lr 0.001\n",
      "Epoch 66. Train Loss: 0.354648, Train acc 0.973089, Valid Loss: 0.414719, Valid acc 0.908000, Time 00:01:37, lr 0.001\n",
      "Epoch 67. Train Loss: 0.355052, Train acc 0.972156, Valid Loss: 0.415157, Valid acc 0.909200, Time 00:01:36, lr 0.001\n",
      "Epoch 68. Train Loss: 0.356855, Train acc 0.971044, Valid Loss: 0.412752, Valid acc 0.907200, Time 00:01:36, lr 0.001\n",
      "Epoch 69. Train Loss: 0.352991, Train acc 0.972689, Valid Loss: 0.411738, Valid acc 0.907800, Time 00:01:41, lr 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70. Train Loss: 0.353769, Train acc 0.972222, Valid Loss: 0.412427, Valid acc 0.906200, Time 00:01:41, lr 0.001\n",
      "Epoch 71. Train Loss: 0.353723, Train acc 0.972356, Valid Loss: 0.418104, Valid acc 0.906600, Time 00:01:40, lr 0.001\n",
      "Epoch 72. Train Loss: 0.352735, Train acc 0.972822, Valid Loss: 0.411494, Valid acc 0.908600, Time 00:01:39, lr 0.001\n",
      "Epoch 73. Train Loss: 0.355183, Train acc 0.973133, Valid Loss: 0.408538, Valid acc 0.907200, Time 00:01:39, lr 0.001\n",
      "Epoch 74. Train Loss: 0.354972, Train acc 0.972289, Valid Loss: 0.407518, Valid acc 0.907600, Time 00:01:38, lr 0.001\n",
      "Epoch 75. Train Loss: 0.354144, Train acc 0.972733, Valid Loss: 0.412593, Valid acc 0.907800, Time 00:01:40, lr 0.001\n",
      "Epoch 76. Train Loss: 0.352240, Train acc 0.972311, Valid Loss: 0.410196, Valid acc 0.909400, Time 00:01:39, lr 0.001\n",
      "Epoch 77. Train Loss: 0.353756, Train acc 0.973111, Valid Loss: 0.414278, Valid acc 0.907200, Time 00:01:39, lr 0.001\n",
      "Epoch 78. Train Loss: 0.352086, Train acc 0.972733, Valid Loss: 0.412479, Valid acc 0.910000, Time 00:01:37, lr 0.001\n",
      "Epoch 79. Train Loss: 0.354389, Train acc 0.973111, Valid Loss: 0.409729, Valid acc 0.907600, Time 00:01:38, lr 0.001\n",
      "Epoch 80. Train Loss: 0.350890, Train acc 0.973244, Valid Loss: 0.411308, Valid acc 0.905600, Time 00:01:38, lr 0.001\n",
      "Epoch 81. Train Loss: 0.354925, Train acc 0.972778, Valid Loss: 0.408911, Valid acc 0.907200, Time 00:01:40, lr 0.001\n",
      "Epoch 82. Train Loss: 0.351808, Train acc 0.971756, Valid Loss: 0.416582, Valid acc 0.905800, Time 00:01:41, lr 0.001\n",
      "Epoch 83. Train Loss: 0.351457, Train acc 0.972778, Valid Loss: 0.409531, Valid acc 0.907400, Time 00:01:42, lr 0.001\n",
      "Epoch 84. Train Loss: 0.351691, Train acc 0.971933, Valid Loss: 0.412302, Valid acc 0.906600, Time 00:01:40, lr 0.001\n",
      "Epoch 85. Train Loss: 0.350173, Train acc 0.972200, Valid Loss: 0.408233, Valid acc 0.907600, Time 00:01:42, lr 0.001\n",
      "Epoch 86. Train Loss: 0.353403, Train acc 0.972244, Valid Loss: 0.411644, Valid acc 0.908800, Time 00:01:38, lr 0.001\n",
      "Epoch 87. Train Loss: 0.349796, Train acc 0.973511, Valid Loss: 0.415026, Valid acc 0.906800, Time 00:01:39, lr 0.001\n",
      "Epoch 88. Train Loss: 0.353265, Train acc 0.972889, Valid Loss: 0.414828, Valid acc 0.905800, Time 00:01:39, lr 0.001\n",
      "Epoch 89. Train Loss: 0.350315, Train acc 0.973600, Valid Loss: 0.413614, Valid acc 0.905200, Time 00:01:41, lr 0.001\n",
      "Epoch 90. Train Loss: 0.350648, Train acc 0.973289, Valid Loss: 0.413261, Valid acc 0.906200, Time 00:01:39, lr 0.001\n",
      "Epoch 91. Train Loss: 0.353530, Train acc 0.973644, Valid Loss: 0.411439, Valid acc 0.906800, Time 00:01:37, lr 0.001\n",
      "Epoch 92. Train Loss: 0.350048, Train acc 0.974400, Valid Loss: 0.411446, Valid acc 0.908000, Time 00:01:40, lr 0.001\n",
      "Epoch 93. Train Loss: 0.350740, Train acc 0.973333, Valid Loss: 0.411841, Valid acc 0.906400, Time 00:01:38, lr 0.001\n",
      "Epoch 94. Train Loss: 0.350963, Train acc 0.972289, Valid Loss: 0.416508, Valid acc 0.907800, Time 00:01:38, lr 0.001\n",
      "Epoch 95. Train Loss: 0.351886, Train acc 0.972244, Valid Loss: 0.411201, Valid acc 0.907400, Time 00:01:42, lr 0.001\n",
      "Epoch 96. Train Loss: 0.354473, Train acc 0.972000, Valid Loss: 0.412106, Valid acc 0.906400, Time 00:01:36, lr 0.001\n",
      "Epoch 97. Train Loss: 0.350234, Train acc 0.974067, Valid Loss: 0.413684, Valid acc 0.908400, Time 00:01:39, lr 0.001\n",
      "Epoch 98. Train Loss: 0.349774, Train acc 0.973889, Valid Loss: 0.412768, Valid acc 0.906800, Time 00:01:38, lr 0.001\n",
      "Epoch 99. Train Loss: 0.350000, Train acc 0.972578, Valid Loss: 0.409663, Valid acc 0.907000, Time 00:01:38, lr 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAGkCAYAAABn8cJiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f728c420e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1\n",
    "net_tea = model.net\n",
    "train3(train_data, valid_data, net_tea, rs8.net, num_epochs, lr, wd, ctx, lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用kd法得出的结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.1\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1\n",
    "net_tea = model.net\n",
    "train3(train_data, valid_data, net_tea, rs8.net, num_epochs, lr, wd, ctx, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs8.save_params(\"./model_compression/rs8_kd_916.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: 初始化月份字符串出错\r\n",
      "-rw-rw-r-- 1 dragon 1244832 3鏈�22 11:30 ./model_compression/rs8_kd_916.params\r\n"
     ]
    }
   ],
   "source": [
    "ll ./model_compression/rs8_kd_916.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start training on ', gpu(0))\n",
      "Epoch 0. Train Loss: 2.649419, Train acc 0.434133, Valid Loss: 102.727097, Valid acc 0.561600, Time 00:01:10, lr 0.1\n",
      "Epoch 1. Train Loss: 1.883392, Train acc 0.612578, Valid Loss: 112.421202, Valid acc 0.644800, Time 00:01:12, lr 0.1\n",
      "Epoch 2. Train Loss: 1.553128, Train acc 0.686111, Valid Loss: 105.778873, Valid acc 0.638600, Time 00:01:13, lr 0.1\n",
      "Epoch 3. Train Loss: 1.360003, Train acc 0.730622, Valid Loss: 109.496164, Valid acc 0.648000, Time 00:01:13, lr 0.1\n",
      "Epoch 4. Train Loss: 1.203257, Train acc 0.763800, Valid Loss: 117.274612, Valid acc 0.754800, Time 00:01:13, lr 0.1\n",
      "Epoch 5. Train Loss: 1.075489, Train acc 0.791267, Valid Loss: 125.142658, Valid acc 0.769600, Time 00:01:11, lr 0.1\n",
      "Epoch 6. Train Loss: 0.990930, Train acc 0.811444, Valid Loss: 123.690585, Valid acc 0.782000, Time 00:01:11, lr 0.1\n",
      "Epoch 7. Train Loss: 0.915612, Train acc 0.826467, Valid Loss: 130.502892, Valid acc 0.810800, Time 00:01:12, lr 0.1\n",
      "Epoch 8. Train Loss: 0.856946, Train acc 0.838467, Valid Loss: 127.133155, Valid acc 0.817600, Time 00:01:11, lr 0.1\n",
      "Epoch 9. Train Loss: 0.826595, Train acc 0.844467, Valid Loss: 129.147331, Valid acc 0.824600, Time 00:01:13, lr 0.1\n",
      "Epoch 10. Train Loss: 0.780268, Train acc 0.852689, Valid Loss: 128.408917, Valid acc 0.814200, Time 00:01:12, lr 0.1\n",
      "Epoch 11. Train Loss: 0.740517, Train acc 0.862156, Valid Loss: 131.670794, Valid acc 0.781200, Time 00:01:11, lr 0.1\n",
      "Epoch 12. Train Loss: 0.712763, Train acc 0.868089, Valid Loss: 131.680114, Valid acc 0.838200, Time 00:01:12, lr 0.1\n",
      "Epoch 13. Train Loss: 0.687895, Train acc 0.874356, Valid Loss: 131.804333, Valid acc 0.845600, Time 00:01:12, lr 0.1\n",
      "Epoch 14. Train Loss: 0.665485, Train acc 0.877778, Valid Loss: 122.931750, Valid acc 0.837200, Time 00:01:11, lr 0.1\n",
      "Epoch 15. Train Loss: 0.641970, Train acc 0.884111, Valid Loss: 129.207870, Valid acc 0.828200, Time 00:01:09, lr 0.1\n",
      "Epoch 16. Train Loss: 0.629330, Train acc 0.885800, Valid Loss: 126.374892, Valid acc 0.819800, Time 00:01:12, lr 0.1\n",
      "Epoch 17. Train Loss: 0.610502, Train acc 0.890178, Valid Loss: 127.991470, Valid acc 0.855000, Time 00:01:11, lr 0.1\n",
      "Epoch 18. Train Loss: 0.595573, Train acc 0.894356, Valid Loss: 133.569060, Valid acc 0.855800, Time 00:01:12, lr 0.1\n",
      "Epoch 19. Train Loss: 0.582669, Train acc 0.897267, Valid Loss: 137.834289, Valid acc 0.836400, Time 00:01:12, lr 0.1\n",
      "Epoch 20. Train Loss: 0.571526, Train acc 0.900756, Valid Loss: 132.231577, Valid acc 0.858800, Time 00:01:12, lr 0.1\n",
      "Epoch 21. Train Loss: 0.550321, Train acc 0.902600, Valid Loss: 127.730190, Valid acc 0.828800, Time 00:01:09, lr 0.1\n",
      "Epoch 22. Train Loss: 0.538683, Train acc 0.906422, Valid Loss: 133.161398, Valid acc 0.859400, Time 00:01:12, lr 0.1\n",
      "Epoch 23. Train Loss: 0.541425, Train acc 0.907133, Valid Loss: 133.070310, Valid acc 0.864000, Time 00:01:13, lr 0.1\n",
      "Epoch 24. Train Loss: 0.519679, Train acc 0.910378, Valid Loss: 129.882143, Valid acc 0.869400, Time 00:01:12, lr 0.1\n",
      "Epoch 25. Train Loss: 0.524451, Train acc 0.911556, Valid Loss: 131.554775, Valid acc 0.834600, Time 00:01:12, lr 0.1\n",
      "Epoch 26. Train Loss: 0.516647, Train acc 0.912200, Valid Loss: 129.645330, Valid acc 0.833600, Time 00:01:13, lr 0.1\n",
      "Epoch 27. Train Loss: 0.499887, Train acc 0.916578, Valid Loss: 135.648193, Valid acc 0.836400, Time 00:01:12, lr 0.1\n",
      "Epoch 28. Train Loss: 0.492078, Train acc 0.917911, Valid Loss: 131.559507, Valid acc 0.845600, Time 00:01:12, lr 0.1\n",
      "Epoch 29. Train Loss: 0.486443, Train acc 0.919289, Valid Loss: 136.658987, Valid acc 0.849000, Time 00:01:12, lr 0.1\n",
      "Epoch 30. Train Loss: 0.476369, Train acc 0.921933, Valid Loss: 128.767234, Valid acc 0.866000, Time 00:01:13, lr 0.1\n",
      "Epoch 31. Train Loss: 0.474953, Train acc 0.921667, Valid Loss: 124.962035, Valid acc 0.845800, Time 00:01:12, lr 0.1\n",
      "Epoch 32. Train Loss: 0.470513, Train acc 0.922244, Valid Loss: 136.368931, Valid acc 0.879200, Time 00:01:12, lr 0.1\n",
      "Epoch 33. Train Loss: 0.459931, Train acc 0.926267, Valid Loss: 117.992081, Valid acc 0.842600, Time 00:01:12, lr 0.1\n",
      "Epoch 34. Train Loss: 0.461660, Train acc 0.924711, Valid Loss: 141.311665, Valid acc 0.830400, Time 00:01:12, lr 0.1\n",
      "Epoch 35. Train Loss: 0.451022, Train acc 0.928489, Valid Loss: 131.886850, Valid acc 0.865200, Time 00:01:12, lr 0.1\n",
      "Epoch 36. Train Loss: 0.446348, Train acc 0.929111, Valid Loss: 133.246285, Valid acc 0.863600, Time 00:01:12, lr 0.1\n",
      "Epoch 37. Train Loss: 0.446595, Train acc 0.928378, Valid Loss: 128.250593, Valid acc 0.874600, Time 00:01:12, lr 0.1\n",
      "Epoch 38. Train Loss: 0.442092, Train acc 0.929067, Valid Loss: 129.972292, Valid acc 0.849800, Time 00:01:11, lr 0.1\n",
      "Epoch 39. Train Loss: 0.437526, Train acc 0.930511, Valid Loss: 130.745315, Valid acc 0.883200, Time 00:01:11, lr 0.1\n",
      "Epoch 40. Train Loss: 0.429739, Train acc 0.931222, Valid Loss: 136.403530, Valid acc 0.835600, Time 00:01:11, lr 0.1\n",
      "Epoch 41. Train Loss: 0.422477, Train acc 0.934733, Valid Loss: 136.463073, Valid acc 0.859400, Time 00:01:12, lr 0.1\n",
      "Epoch 42. Train Loss: 0.421211, Train acc 0.936400, Valid Loss: 133.888326, Valid acc 0.860400, Time 00:01:13, lr 0.1\n",
      "Epoch 43. Train Loss: 0.421165, Train acc 0.934844, Valid Loss: 132.833509, Valid acc 0.853400, Time 00:01:12, lr 0.1\n",
      "Epoch 44. Train Loss: 0.418711, Train acc 0.935222, Valid Loss: 129.050785, Valid acc 0.841600, Time 00:01:12, lr 0.1\n",
      "Epoch 45. Train Loss: 0.413197, Train acc 0.936867, Valid Loss: 134.348957, Valid acc 0.869800, Time 00:01:07, lr 0.1\n",
      "Epoch 46. Train Loss: 0.412511, Train acc 0.938156, Valid Loss: 140.355360, Valid acc 0.868800, Time 00:01:09, lr 0.1\n",
      "Epoch 47. Train Loss: 0.412077, Train acc 0.935889, Valid Loss: 130.384880, Valid acc 0.867400, Time 00:01:13, lr 0.1\n",
      "Epoch 48. Train Loss: 0.409261, Train acc 0.937889, Valid Loss: 130.769328, Valid acc 0.875600, Time 00:01:13, lr 0.1\n",
      "Epoch 49. Train Loss: 0.402566, Train acc 0.939889, Valid Loss: 131.389258, Valid acc 0.881400, Time 00:01:13, lr 0.1\n",
      "Epoch 50. Train Loss: 0.398114, Train acc 0.941022, Valid Loss: 136.138948, Valid acc 0.878200, Time 00:01:11, lr 0.1\n",
      "Epoch 51. Train Loss: 0.394052, Train acc 0.941911, Valid Loss: 137.254845, Valid acc 0.879200, Time 00:01:13, lr 0.1\n",
      "Epoch 52. Train Loss: 0.392616, Train acc 0.942578, Valid Loss: 136.590462, Valid acc 0.881200, Time 00:01:12, lr 0.1\n",
      "Epoch 53. Train Loss: 0.391451, Train acc 0.942711, Valid Loss: 128.053605, Valid acc 0.862000, Time 00:01:12, lr 0.1\n",
      "Epoch 54. Train Loss: 0.400398, Train acc 0.939711, Valid Loss: 134.625637, Valid acc 0.888000, Time 00:01:12, lr 0.1\n",
      "Epoch 57. Train Loss: 0.386733, Train acc 0.943156, Valid Loss: 126.618863, Valid acc 0.848400, Time 00:01:10, lr 0.1\n",
      "Epoch 58. Train Loss: 0.381438, Train acc 0.944467, Valid Loss: 128.153082, Valid acc 0.870400, Time 00:01:11, lr 0.1\n",
      "Epoch 59. Train Loss: 0.374459, Train acc 0.945578, Valid Loss: 131.087206, Valid acc 0.867400, Time 00:01:09, lr 0.1\n",
      "Epoch 60. Train Loss: 0.378653, Train acc 0.946267, Valid Loss: 135.198374, Valid acc 0.858000, Time 00:01:09, lr 0.1\n",
      "Epoch 61. Train Loss: 0.377641, Train acc 0.945444, Valid Loss: 137.053565, Valid acc 0.845600, Time 00:01:08, lr 0.1\n",
      "Epoch 62. Train Loss: 0.372776, Train acc 0.947622, Valid Loss: 132.533905, Valid acc 0.860200, Time 00:01:10, lr 0.1\n",
      "Epoch 63. Train Loss: 0.372473, Train acc 0.947667, Valid Loss: 131.277017, Valid acc 0.863400, Time 00:01:08, lr 0.1\n",
      "Epoch 66. Train Loss: 0.371604, Train acc 0.947689, Valid Loss: 132.628941, Valid acc 0.865600, Time 00:01:09, lr 0.1\n",
      "Epoch 67. Train Loss: 0.363677, Train acc 0.949044, Valid Loss: 132.091268, Valid acc 0.840400, Time 00:01:11, lr 0.1\n",
      "Epoch 68. Train Loss: 0.363575, Train acc 0.950200, Valid Loss: 136.416031, Valid acc 0.856400, Time 00:01:11, lr 0.1\n",
      "Epoch 69. Train Loss: 0.358487, Train acc 0.950933, Valid Loss: 134.052211, Valid acc 0.872400, Time 00:01:10, lr 0.1\n",
      "Epoch 70. Train Loss: 0.364992, Train acc 0.949022, Valid Loss: 135.580575, Valid acc 0.877600, Time 00:01:12, lr 0.1\n",
      "Epoch 71. Train Loss: 0.366933, Train acc 0.947133, Valid Loss: 133.200797, Valid acc 0.860600, Time 00:01:08, lr 0.1\n",
      "Epoch 72. Train Loss: 0.363113, Train acc 0.949378, Valid Loss: 134.625897, Valid acc 0.833800, Time 00:01:11, lr 0.1\n",
      "Epoch 73. Train Loss: 0.357877, Train acc 0.950333, Valid Loss: 131.149219, Valid acc 0.873000, Time 00:01:06, lr 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74. Train Loss: 0.360285, Train acc 0.949756, Valid Loss: 132.321304, Valid acc 0.865000, Time 00:01:10, lr 0.1\n",
      "Epoch 75. Train Loss: 0.359434, Train acc 0.950467, Valid Loss: 128.457849, Valid acc 0.871800, Time 00:01:12, lr 0.1\n",
      "Epoch 76. Train Loss: 0.349274, Train acc 0.953044, Valid Loss: 131.468816, Valid acc 0.880000, Time 00:01:12, lr 0.1\n",
      "Epoch 77. Train Loss: 0.351334, Train acc 0.952711, Valid Loss: 132.905311, Valid acc 0.864000, Time 00:01:12, lr 0.1\n",
      "Epoch 78. Train Loss: 0.341745, Train acc 0.955156, Valid Loss: 134.539066, Valid acc 0.858800, Time 00:01:12, lr 0.1\n",
      "Epoch 79. Train Loss: 0.357052, Train acc 0.951578, Valid Loss: 122.268816, Valid acc 0.854600, Time 00:01:08, lr 0.1\n",
      "Epoch 80. Train Loss: 0.307888, Train acc 0.964200, Valid Loss: 134.881367, Valid acc 0.909200, Time 00:01:06, lr 0.01\n",
      "Epoch 81. Train Loss: 0.260774, Train acc 0.975067, Valid Loss: 134.838368, Valid acc 0.911800, Time 00:01:11, lr 0.01\n",
      "Epoch 82. Train Loss: 0.250817, Train acc 0.976889, Valid Loss: 134.671402, Valid acc 0.912400, Time 00:01:09, lr 0.01\n",
      "Epoch 85. Train Loss: 0.237732, Train acc 0.980911, Valid Loss: 134.553416, Valid acc 0.915400, Time 00:01:11, lr 0.01\n",
      "Epoch 86. Train Loss: 0.234611, Train acc 0.981356, Valid Loss: 135.079776, Valid acc 0.915000, Time 00:01:13, lr 0.01\n",
      "Epoch 87. Train Loss: 0.232969, Train acc 0.981156, Valid Loss: 135.192737, Valid acc 0.913800, Time 00:01:13, lr 0.01\n",
      "Epoch 88. Train Loss: 0.230403, Train acc 0.981822, Valid Loss: 135.760497, Valid acc 0.916600, Time 00:01:14, lr 0.01\n",
      "Epoch 89. Train Loss: 0.229677, Train acc 0.981933, Valid Loss: 135.204516, Valid acc 0.916000, Time 00:01:12, lr 0.01\n",
      "Epoch 90. Train Loss: 0.226974, Train acc 0.983667, Valid Loss: 134.519032, Valid acc 0.916200, Time 00:01:12, lr 0.01\n",
      "Epoch 91. Train Loss: 0.225873, Train acc 0.983600, Valid Loss: 134.513718, Valid acc 0.912800, Time 00:01:13, lr 0.01\n",
      "Epoch 92. Train Loss: 0.224882, Train acc 0.984444, Valid Loss: 135.321507, Valid acc 0.914800, Time 00:01:11, lr 0.01\n",
      "Epoch 93. Train Loss: 0.222701, Train acc 0.984200, Valid Loss: 135.016612, Valid acc 0.909200, Time 00:01:12, lr 0.01\n",
      "Epoch 94. Train Loss: 0.222537, Train acc 0.984422, Valid Loss: 133.850970, Valid acc 0.915000, Time 00:01:08, lr 0.01\n",
      "Epoch 95. Train Loss: 0.220384, Train acc 0.984978, Valid Loss: 134.543115, Valid acc 0.916200, Time 00:01:09, lr 0.01\n",
      "Epoch 96. Train Loss: 0.220416, Train acc 0.984778, Valid Loss: 135.942181, Valid acc 0.916600, Time 00:01:05, lr 0.01\n",
      "Epoch 97. Train Loss: 0.217750, Train acc 0.985289, Valid Loss: 134.556583, Valid acc 0.913600, Time 00:01:11, lr 0.01\n",
      "Epoch 98. Train Loss: 0.218793, Train acc 0.985400, Valid Loss: 134.474989, Valid acc 0.912800, Time 00:01:12, lr 0.01\n",
      "Epoch 99. Train Loss: 0.215722, Train acc 0.984533, Valid Loss: 134.434279, Valid acc 0.910200, Time 00:01:13, lr 0.01\n",
      "Epoch 100. Train Loss: 0.216150, Train acc 0.986156, Valid Loss: 134.860740, Valid acc 0.910600, Time 00:01:13, lr 0.01\n",
      "Epoch 101. Train Loss: 0.214339, Train acc 0.986244, Valid Loss: 134.947934, Valid acc 0.915000, Time 00:01:12, lr 0.01\n",
      "Epoch 104. Train Loss: 0.212760, Train acc 0.986956, Valid Loss: 135.075790, Valid acc 0.912600, Time 00:01:12, lr 0.01\n",
      "Epoch 105. Train Loss: 0.211228, Train acc 0.987489, Valid Loss: 134.537452, Valid acc 0.912200, Time 00:01:10, lr 0.01\n",
      "Epoch 106. Train Loss: 0.210700, Train acc 0.987089, Valid Loss: 134.540919, Valid acc 0.912600, Time 00:01:09, lr 0.01\n",
      "Epoch 107. Train Loss: 0.210654, Train acc 0.987356, Valid Loss: 135.000504, Valid acc 0.913400, Time 00:01:09, lr 0.01\n",
      "Epoch 108. Train Loss: 0.210021, Train acc 0.986600, Valid Loss: 134.927142, Valid acc 0.914200, Time 00:01:09, lr 0.01\n",
      "Epoch 109. Train Loss: 0.208381, Train acc 0.988067, Valid Loss: 135.254156, Valid acc 0.914800, Time 00:01:10, lr 0.01\n",
      "Epoch 110. Train Loss: 0.209678, Train acc 0.987489, Valid Loss: 135.016717, Valid acc 0.912600, Time 00:01:08, lr 0.01\n",
      "Epoch 111. Train Loss: 0.209137, Train acc 0.987200, Valid Loss: 134.985406, Valid acc 0.914000, Time 00:01:09, lr 0.01\n",
      "Epoch 112. Train Loss: 0.208525, Train acc 0.987422, Valid Loss: 135.132922, Valid acc 0.915600, Time 00:01:08, lr 0.01\n",
      "Epoch 113. Train Loss: 0.207575, Train acc 0.987467, Valid Loss: 134.196294, Valid acc 0.916600, Time 00:01:11, lr 0.01\n",
      "Epoch 114. Train Loss: 0.205810, Train acc 0.988600, Valid Loss: 134.670222, Valid acc 0.913800, Time 00:01:13, lr 0.01\n",
      "Epoch 115. Train Loss: 0.206159, Train acc 0.988378, Valid Loss: 134.321084, Valid acc 0.914600, Time 00:01:12, lr 0.01\n",
      "Epoch 116. Train Loss: 0.206279, Train acc 0.988822, Valid Loss: 134.638117, Valid acc 0.915200, Time 00:01:11, lr 0.01\n",
      "Epoch 117. Train Loss: 0.205801, Train acc 0.988200, Valid Loss: 135.332539, Valid acc 0.915000, Time 00:01:10, lr 0.01\n",
      "Epoch 118. Train Loss: 0.205565, Train acc 0.987733, Valid Loss: 135.133188, Valid acc 0.914800, Time 00:01:09, lr 0.01\n",
      "Epoch 119. Train Loss: 0.205341, Train acc 0.988156, Valid Loss: 134.788620, Valid acc 0.917000, Time 00:01:11, lr 0.01\n",
      "Epoch 120. Train Loss: 0.204216, Train acc 0.989133, Valid Loss: 134.111281, Valid acc 0.915400, Time 00:01:09, lr 0.01\n",
      "Epoch 121. Train Loss: 0.204360, Train acc 0.988800, Valid Loss: 134.989977, Valid acc 0.913800, Time 00:01:11, lr 0.01\n",
      "Epoch 122. Train Loss: 0.201782, Train acc 0.988711, Valid Loss: 134.397192, Valid acc 0.913600, Time 00:01:09, lr 0.01\n",
      "Epoch 123. Train Loss: 0.202272, Train acc 0.989556, Valid Loss: 135.072131, Valid acc 0.917200, Time 00:01:07, lr 0.01\n",
      "Epoch 124. Train Loss: 0.201909, Train acc 0.989689, Valid Loss: 135.331238, Valid acc 0.913800, Time 00:01:10, lr 0.01\n",
      "Epoch 125. Train Loss: 0.201838, Train acc 0.989911, Valid Loss: 135.140196, Valid acc 0.914400, Time 00:01:11, lr 0.01\n",
      "Epoch 126. Train Loss: 0.200878, Train acc 0.988756, Valid Loss: 134.603180, Valid acc 0.915200, Time 00:01:13, lr 0.01\n",
      "Epoch 127. Train Loss: 0.199982, Train acc 0.989800, Valid Loss: 134.848303, Valid acc 0.914400, Time 00:01:12, lr 0.01\n",
      "Epoch 128. Train Loss: 0.200252, Train acc 0.989822, Valid Loss: 135.222746, Valid acc 0.917600, Time 00:01:12, lr 0.01\n",
      "Epoch 129. Train Loss: 0.200947, Train acc 0.989111, Valid Loss: 134.476277, Valid acc 0.913600, Time 00:01:14, lr 0.01\n",
      "Epoch 130. Train Loss: 0.199326, Train acc 0.989222, Valid Loss: 133.711222, Valid acc 0.914000, Time 00:01:13, lr 0.01\n",
      "Epoch 131. Train Loss: 0.200094, Train acc 0.989844, Valid Loss: 135.035045, Valid acc 0.912000, Time 00:01:11, lr 0.01\n",
      "Epoch 132. Train Loss: 0.199511, Train acc 0.989356, Valid Loss: 134.818229, Valid acc 0.913800, Time 00:01:12, lr 0.01\n",
      "Epoch 133. Train Loss: 0.198933, Train acc 0.989756, Valid Loss: 134.188750, Valid acc 0.912200, Time 00:01:12, lr 0.01\n",
      "Epoch 134. Train Loss: 0.198987, Train acc 0.990000, Valid Loss: 133.975862, Valid acc 0.915400, Time 00:01:12, lr 0.01\n",
      "Epoch 135. Train Loss: 0.197438, Train acc 0.990289, Valid Loss: 134.913377, Valid acc 0.912200, Time 00:01:10, lr 0.01\n",
      "Epoch 136. Train Loss: 0.197433, Train acc 0.989956, Valid Loss: 135.175833, Valid acc 0.912000, Time 00:01:11, lr 0.01\n",
      "Epoch 137. Train Loss: 0.196824, Train acc 0.989400, Valid Loss: 134.124564, Valid acc 0.915800, Time 00:01:10, lr 0.01\n",
      "Epoch 138. Train Loss: 0.198059, Train acc 0.990089, Valid Loss: 135.010998, Valid acc 0.915400, Time 00:01:12, lr 0.01\n",
      "Epoch 139. Train Loss: 0.196778, Train acc 0.989733, Valid Loss: 135.107227, Valid acc 0.913600, Time 00:01:12, lr 0.01\n",
      "Epoch 140. Train Loss: 0.197906, Train acc 0.989533, Valid Loss: 134.294353, Valid acc 0.915800, Time 00:01:08, lr 0.01\n",
      "Epoch 141. Train Loss: 0.196028, Train acc 0.990178, Valid Loss: 135.267756, Valid acc 0.912800, Time 00:01:12, lr 0.01\n",
      "Epoch 142. Train Loss: 0.195294, Train acc 0.991000, Valid Loss: 134.376061, Valid acc 0.916200, Time 00:01:08, lr 0.01\n",
      "Epoch 143. Train Loss: 0.194216, Train acc 0.990622, Valid Loss: 134.444080, Valid acc 0.914600, Time 00:01:09, lr 0.01\n",
      "Epoch 144. Train Loss: 0.193135, Train acc 0.990822, Valid Loss: 134.821821, Valid acc 0.915000, Time 00:01:07, lr 0.01\n",
      "Epoch 145. Train Loss: 0.193933, Train acc 0.990200, Valid Loss: 134.950362, Valid acc 0.912400, Time 00:01:13, lr 0.01\n",
      "Epoch 146. Train Loss: 0.191866, Train acc 0.991089, Valid Loss: 134.967452, Valid acc 0.916200, Time 00:01:12, lr 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147. Train Loss: 0.194562, Train acc 0.990756, Valid Loss: 134.938135, Valid acc 0.914000, Time 00:01:10, lr 0.01\n",
      "Epoch 148. Train Loss: 0.192886, Train acc 0.990778, Valid Loss: 133.870513, Valid acc 0.915200, Time 00:01:12, lr 0.01\n",
      "Epoch 149. Train Loss: 0.192657, Train acc 0.990956, Valid Loss: 134.390115, Valid acc 0.914600, Time 00:01:13, lr 0.01\n",
      "Epoch 150. Train Loss: 0.192895, Train acc 0.991156, Valid Loss: 134.444393, Valid acc 0.913800, Time 00:01:12, lr 0.01\n",
      "Epoch 151. Train Loss: 0.192731, Train acc 0.990689, Valid Loss: 133.891526, Valid acc 0.914600, Time 00:01:13, lr 0.01\n",
      "Epoch 152. Train Loss: 0.190249, Train acc 0.992311, Valid Loss: 134.998227, Valid acc 0.913400, Time 00:01:13, lr 0.01\n",
      "Epoch 153. Train Loss: 0.190434, Train acc 0.990644, Valid Loss: 134.895196, Valid acc 0.918000, Time 00:01:10, lr 0.01\n",
      "Epoch 154. Train Loss: 0.191604, Train acc 0.991489, Valid Loss: 134.259409, Valid acc 0.912200, Time 00:01:13, lr 0.01\n",
      "Epoch 155. Train Loss: 0.191639, Train acc 0.990689, Valid Loss: 134.045573, Valid acc 0.913800, Time 00:01:12, lr 0.01\n",
      "Epoch 156. Train Loss: 0.191593, Train acc 0.990756, Valid Loss: 134.107574, Valid acc 0.913400, Time 00:01:13, lr 0.01\n",
      "Epoch 159. Train Loss: 0.190428, Train acc 0.991911, Valid Loss: 134.088803, Valid acc 0.911600, Time 00:01:10, lr 0.01\n",
      "Epoch 160. Train Loss: 0.190488, Train acc 0.991022, Valid Loss: 133.997585, Valid acc 0.914800, Time 00:01:12, lr 0.01\n",
      "Epoch 161. Train Loss: 0.188832, Train acc 0.991578, Valid Loss: 135.227662, Valid acc 0.913200, Time 00:01:12, lr 0.01\n",
      "Epoch 162. Train Loss: 0.190344, Train acc 0.991511, Valid Loss: 133.023138, Valid acc 0.916000, Time 00:01:10, lr 0.01\n",
      "Epoch 163. Train Loss: 0.189172, Train acc 0.991711, Valid Loss: 135.036282, Valid acc 0.915200, Time 00:01:11, lr 0.01\n",
      "Epoch 164. Train Loss: 0.187729, Train acc 0.991978, Valid Loss: 134.002157, Valid acc 0.914200, Time 00:01:10, lr 0.01\n",
      "Epoch 165. Train Loss: 0.187897, Train acc 0.992244, Valid Loss: 135.660564, Valid acc 0.914200, Time 00:01:12, lr 0.01\n",
      "Epoch 166. Train Loss: 0.189988, Train acc 0.990822, Valid Loss: 134.576436, Valid acc 0.917200, Time 00:01:12, lr 0.01\n",
      "Epoch 167. Train Loss: 0.187434, Train acc 0.991822, Valid Loss: 135.657552, Valid acc 0.911600, Time 00:01:10, lr 0.01\n",
      "Epoch 168. Train Loss: 0.188002, Train acc 0.991911, Valid Loss: 135.289736, Valid acc 0.910400, Time 00:01:10, lr 0.01\n",
      "Epoch 169. Train Loss: 0.187584, Train acc 0.991644, Valid Loss: 134.399811, Valid acc 0.912200, Time 00:01:08, lr 0.01\n",
      "Epoch 170. Train Loss: 0.188446, Train acc 0.991622, Valid Loss: 134.697124, Valid acc 0.915400, Time 00:01:12, lr 0.01\n",
      "Epoch 171. Train Loss: 0.186639, Train acc 0.992178, Valid Loss: 135.388766, Valid acc 0.915400, Time 00:01:12, lr 0.01\n",
      "Epoch 172. Train Loss: 0.187679, Train acc 0.991600, Valid Loss: 134.341275, Valid acc 0.913200, Time 00:01:13, lr 0.01\n",
      "Epoch 173. Train Loss: 0.186570, Train acc 0.991578, Valid Loss: 134.486168, Valid acc 0.914600, Time 00:01:12, lr 0.01\n",
      "Epoch 174. Train Loss: 0.186918, Train acc 0.992089, Valid Loss: 134.992910, Valid acc 0.911800, Time 00:01:12, lr 0.01\n",
      "Epoch 175. Train Loss: 0.187639, Train acc 0.992222, Valid Loss: 134.738226, Valid acc 0.913400, Time 00:01:11, lr 0.01\n",
      "Epoch 176. Train Loss: 0.187244, Train acc 0.992333, Valid Loss: 135.151221, Valid acc 0.917200, Time 00:01:11, lr 0.01\n",
      "Epoch 177. Train Loss: 0.187153, Train acc 0.991822, Valid Loss: 133.734538, Valid acc 0.913200, Time 00:01:09, lr 0.01\n",
      "Epoch 178. Train Loss: 0.185746, Train acc 0.992822, Valid Loss: 133.618102, Valid acc 0.917000, Time 00:01:01, lr 0.01\n",
      "Epoch 179. Train Loss: 0.185730, Train acc 0.992289, Valid Loss: 133.629700, Valid acc 0.914000, Time 00:01:08, lr 0.01\n",
      "Epoch 180. Train Loss: 0.185399, Train acc 0.992356, Valid Loss: 133.491392, Valid acc 0.915000, Time 00:01:08, lr 0.01\n",
      "Epoch 181. Train Loss: 0.183295, Train acc 0.992911, Valid Loss: 133.494276, Valid acc 0.912400, Time 00:01:09, lr 0.01\n",
      "Epoch 182. Train Loss: 0.184165, Train acc 0.992978, Valid Loss: 133.920845, Valid acc 0.913400, Time 00:01:12, lr 0.01\n",
      "Epoch 183. Train Loss: 0.183550, Train acc 0.992378, Valid Loss: 134.888765, Valid acc 0.910600, Time 00:01:12, lr 0.01\n",
      "Epoch 184. Train Loss: 0.185356, Train acc 0.992333, Valid Loss: 134.006369, Valid acc 0.912600, Time 00:01:12, lr 0.01\n",
      "Epoch 185. Train Loss: 0.186648, Train acc 0.992200, Valid Loss: 134.704166, Valid acc 0.913800, Time 00:01:12, lr 0.01\n",
      "Epoch 186. Train Loss: 0.183894, Train acc 0.992667, Valid Loss: 134.249508, Valid acc 0.910800, Time 00:01:12, lr 0.01\n",
      "Epoch 187. Train Loss: 0.184521, Train acc 0.992178, Valid Loss: 133.888443, Valid acc 0.915800, Time 00:01:11, lr 0.01\n",
      "Epoch 188. Train Loss: 0.182442, Train acc 0.992800, Valid Loss: 134.322558, Valid acc 0.915200, Time 00:01:11, lr 0.01\n",
      "Epoch 191. Train Loss: 0.183214, Train acc 0.992956, Valid Loss: 135.058801, Valid acc 0.915200, Time 00:01:12, lr 0.01\n",
      "Epoch 192. Train Loss: 0.181567, Train acc 0.992822, Valid Loss: 134.462606, Valid acc 0.915200, Time 00:01:13, lr 0.01\n",
      "Epoch 193. Train Loss: 0.182485, Train acc 0.992156, Valid Loss: 133.642434, Valid acc 0.912800, Time 00:01:13, lr 0.01\n",
      "Epoch 194. Train Loss: 0.182071, Train acc 0.992933, Valid Loss: 134.264561, Valid acc 0.911600, Time 00:01:13, lr 0.01\n",
      "Epoch 195. Train Loss: 0.181472, Train acc 0.993400, Valid Loss: 134.006089, Valid acc 0.909800, Time 00:01:10, lr 0.01\n",
      "Epoch 196. Train Loss: 0.181394, Train acc 0.993533, Valid Loss: 134.960727, Valid acc 0.914400, Time 00:01:13, lr 0.01\n",
      "Epoch 197. Train Loss: 0.181955, Train acc 0.992889, Valid Loss: 134.567147, Valid acc 0.915200, Time 00:01:13, lr 0.01\n",
      "Epoch 198. Train Loss: 0.182176, Train acc 0.992556, Valid Loss: 133.480672, Valid acc 0.912000, Time 00:01:12, lr 0.01\n",
      "Epoch 199. Train Loss: 0.181748, Train acc 0.992978, Valid Loss: 134.204078, Valid acc 0.912400, Time 00:01:12, lr 0.01\n",
      "Epoch 200. Train Loss: 0.177815, Train acc 0.993844, Valid Loss: 134.562858, Valid acc 0.913000, Time 00:01:12, lr 0.001\n",
      "Epoch 201. Train Loss: 0.175097, Train acc 0.994378, Valid Loss: 134.770348, Valid acc 0.912200, Time 00:01:12, lr 0.001\n",
      "Epoch 202. Train Loss: 0.174861, Train acc 0.993978, Valid Loss: 134.285367, Valid acc 0.914600, Time 00:01:12, lr 0.001\n",
      "Epoch 203. Train Loss: 0.174197, Train acc 0.993956, Valid Loss: 133.901160, Valid acc 0.914400, Time 00:01:12, lr 0.001\n",
      "Epoch 204. Train Loss: 0.173245, Train acc 0.994867, Valid Loss: 134.285243, Valid acc 0.914800, Time 00:01:12, lr 0.001\n",
      "Epoch 205. Train Loss: 0.174937, Train acc 0.994356, Valid Loss: 134.583960, Valid acc 0.915000, Time 00:01:13, lr 0.001\n",
      "Epoch 206. Train Loss: 0.173510, Train acc 0.994467, Valid Loss: 134.002771, Valid acc 0.913800, Time 00:01:13, lr 0.001\n",
      "Epoch 207. Train Loss: 0.172378, Train acc 0.994378, Valid Loss: 134.365524, Valid acc 0.912800, Time 00:01:10, lr 0.001\n",
      "Epoch 208. Train Loss: 0.173855, Train acc 0.994511, Valid Loss: 134.171777, Valid acc 0.913600, Time 00:01:11, lr 0.001\n",
      "Epoch 211. Train Loss: 0.172601, Train acc 0.995044, Valid Loss: 134.631647, Valid acc 0.913800, Time 00:01:11, lr 0.001\n",
      "Epoch 212. Train Loss: 0.173450, Train acc 0.994289, Valid Loss: 134.518414, Valid acc 0.914800, Time 00:01:08, lr 0.001\n",
      "Epoch 213. Train Loss: 0.172873, Train acc 0.994711, Valid Loss: 134.677914, Valid acc 0.913000, Time 00:01:08, lr 0.001\n",
      "Epoch 214. Train Loss: 0.172633, Train acc 0.994022, Valid Loss: 134.608826, Valid acc 0.912800, Time 00:01:10, lr 0.001\n",
      "Epoch 215. Train Loss: 0.173024, Train acc 0.994244, Valid Loss: 134.577516, Valid acc 0.914200, Time 00:01:10, lr 0.001\n",
      "Epoch 216. Train Loss: 0.172416, Train acc 0.995178, Valid Loss: 134.634272, Valid acc 0.915000, Time 00:01:06, lr 0.001\n",
      "Epoch 217. Train Loss: 0.172919, Train acc 0.994778, Valid Loss: 134.657384, Valid acc 0.914200, Time 00:01:10, lr 0.001\n",
      "Epoch 218. Train Loss: 0.173012, Train acc 0.994467, Valid Loss: 134.610413, Valid acc 0.914200, Time 00:01:10, lr 0.001\n",
      "Epoch 219. Train Loss: 0.171440, Train acc 0.994311, Valid Loss: 134.182850, Valid acc 0.913600, Time 00:01:09, lr 0.001\n",
      "Epoch 220. Train Loss: 0.172155, Train acc 0.994956, Valid Loss: 134.467317, Valid acc 0.913200, Time 00:01:09, lr 0.001\n",
      "Epoch 221. Train Loss: 0.172281, Train acc 0.994222, Valid Loss: 134.526897, Valid acc 0.913400, Time 00:01:07, lr 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222. Train Loss: 0.172029, Train acc 0.994822, Valid Loss: 134.361674, Valid acc 0.913600, Time 00:01:08, lr 0.001\n",
      "Epoch 223. Train Loss: 0.174218, Train acc 0.994000, Valid Loss: 134.582973, Valid acc 0.914400, Time 00:01:10, lr 0.001\n",
      "Epoch 224. Train Loss: 0.172892, Train acc 0.994600, Valid Loss: 133.996674, Valid acc 0.915200, Time 00:01:09, lr 0.001\n",
      "Epoch 225. Train Loss: 0.172021, Train acc 0.994400, Valid Loss: 134.366277, Valid acc 0.915400, Time 00:01:08, lr 0.001\n",
      "Epoch 226. Train Loss: 0.172553, Train acc 0.994089, Valid Loss: 134.050806, Valid acc 0.915200, Time 00:01:12, lr 0.001\n",
      "Epoch 227. Train Loss: 0.172417, Train acc 0.994511, Valid Loss: 134.560164, Valid acc 0.914200, Time 00:01:13, lr 0.001\n",
      "Epoch 228. Train Loss: 0.171565, Train acc 0.994822, Valid Loss: 134.446181, Valid acc 0.914000, Time 00:01:12, lr 0.001\n",
      "Epoch 229. Train Loss: 0.171871, Train acc 0.995067, Valid Loss: 134.207635, Valid acc 0.915400, Time 00:01:11, lr 0.001\n",
      "Epoch 230. Train Loss: 0.173317, Train acc 0.993644, Valid Loss: 134.361697, Valid acc 0.914000, Time 00:01:12, lr 0.001\n",
      "Epoch 231. Train Loss: 0.171067, Train acc 0.994644, Valid Loss: 134.492079, Valid acc 0.914200, Time 00:01:12, lr 0.001\n",
      "Epoch 232. Train Loss: 0.171466, Train acc 0.994600, Valid Loss: 134.606509, Valid acc 0.914800, Time 00:01:12, lr 0.001\n",
      "Epoch 233. Train Loss: 0.172190, Train acc 0.994556, Valid Loss: 134.236307, Valid acc 0.914800, Time 00:01:13, lr 0.001\n",
      "Epoch 234. Train Loss: 0.171008, Train acc 0.994378, Valid Loss: 134.560092, Valid acc 0.913400, Time 00:01:13, lr 0.001\n",
      "Epoch 235. Train Loss: 0.172539, Train acc 0.995022, Valid Loss: 134.392392, Valid acc 0.912800, Time 00:01:13, lr 0.001\n",
      "Epoch 236. Train Loss: 0.169730, Train acc 0.995356, Valid Loss: 134.360897, Valid acc 0.914200, Time 00:01:12, lr 0.001\n",
      "Epoch 237. Train Loss: 0.171369, Train acc 0.994600, Valid Loss: 134.170880, Valid acc 0.914600, Time 00:01:12, lr 0.001\n",
      "Epoch 238. Train Loss: 0.172131, Train acc 0.994578, Valid Loss: 134.251493, Valid acc 0.912800, Time 00:01:13, lr 0.001\n",
      "Epoch 241. Train Loss: 0.171863, Train acc 0.994667, Valid Loss: 133.950164, Valid acc 0.912800, Time 00:01:07, lr 0.001\n",
      "Epoch 242. Train Loss: 0.171840, Train acc 0.994711, Valid Loss: 133.842838, Valid acc 0.914000, Time 00:01:11, lr 0.001\n",
      "Epoch 243. Train Loss: 0.170976, Train acc 0.994711, Valid Loss: 134.200372, Valid acc 0.913600, Time 00:01:11, lr 0.001\n",
      "Epoch 244. Train Loss: 0.172003, Train acc 0.994844, Valid Loss: 134.303588, Valid acc 0.914800, Time 00:01:12, lr 0.001\n",
      "Epoch 245. Train Loss: 0.170344, Train acc 0.994667, Valid Loss: 134.414170, Valid acc 0.912000, Time 00:01:12, lr 0.001\n",
      "Epoch 246. Train Loss: 0.171301, Train acc 0.994733, Valid Loss: 134.426117, Valid acc 0.913800, Time 00:01:12, lr 0.001\n",
      "Epoch 247. Train Loss: 0.171958, Train acc 0.994756, Valid Loss: 134.478155, Valid acc 0.913200, Time 00:01:12, lr 0.001\n",
      "Epoch 248. Train Loss: 0.171011, Train acc 0.994978, Valid Loss: 134.283608, Valid acc 0.913200, Time 00:01:12, lr 0.001\n",
      "Epoch 249. Train Loss: 0.169830, Train acc 0.994333, Valid Loss: 134.662128, Valid acc 0.914200, Time 00:01:12, lr 0.001\n",
      "Epoch 250. Train Loss: 0.171263, Train acc 0.994933, Valid Loss: 134.477474, Valid acc 0.914800, Time 00:01:12, lr 0.001\n",
      "Epoch 251. Train Loss: 0.170739, Train acc 0.994244, Valid Loss: 134.098342, Valid acc 0.914600, Time 00:01:11, lr 0.001\n",
      "Epoch 252. Train Loss: 0.171729, Train acc 0.994756, Valid Loss: 134.394606, Valid acc 0.913400, Time 00:01:08, lr 0.001\n",
      "Epoch 253. Train Loss: 0.170935, Train acc 0.994622, Valid Loss: 133.888921, Valid acc 0.914400, Time 00:01:09, lr 0.001\n",
      "Epoch 254. Train Loss: 0.170951, Train acc 0.995333, Valid Loss: 134.647982, Valid acc 0.912000, Time 00:01:11, lr 0.001\n",
      "Epoch 255. Train Loss: 0.170124, Train acc 0.995156, Valid Loss: 134.261828, Valid acc 0.914200, Time 00:01:11, lr 0.001\n",
      "Epoch 256. Train Loss: 0.173013, Train acc 0.994333, Valid Loss: 134.315974, Valid acc 0.913800, Time 00:01:10, lr 0.001\n",
      "Epoch 257. Train Loss: 0.170937, Train acc 0.994956, Valid Loss: 134.440953, Valid acc 0.912800, Time 00:01:12, lr 0.001\n",
      "Epoch 258. Train Loss: 0.171888, Train acc 0.994578, Valid Loss: 134.352740, Valid acc 0.913200, Time 00:01:12, lr 0.001\n",
      "Epoch 259. Train Loss: 0.170273, Train acc 0.995133, Valid Loss: 134.573994, Valid acc 0.914600, Time 00:01:12, lr 0.001\n",
      "Epoch 262. Train Loss: 0.171484, Train acc 0.994689, Valid Loss: 134.279720, Valid acc 0.914400, Time 00:01:12, lr 0.001\n",
      "Epoch 263. Train Loss: 0.169689, Train acc 0.995489, Valid Loss: 134.193297, Valid acc 0.913600, Time 00:01:13, lr 0.001\n"
     ]
    }
   ],
   "source": [
    "# rs8 = Resnet8(10)\n",
    "# ctx = try_gpu()\n",
    "# rs8.initialize(ctx=ctx, init=mx.initializer.Xavier())\n",
    "# rs8.hybridize()\n",
    "\n",
    "\n",
    "num_epochs = 300\n",
    "lr = 0.1\n",
    "wd = 1e-4\n",
    "lr_decay = 0.1\n",
    "net_tea = model.net\n",
    "train3(train_data, valid_data, net_tea, rs8.net, num_epochs, lr, wd, ctx, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs8.save_params('./model_compression/stu_rs4_kd73.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 134.386126, Valid acc 0.916000Time 00:00:03\n"
     ]
    }
   ],
   "source": [
    "test(rs8,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
